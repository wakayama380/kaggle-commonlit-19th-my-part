{"cells":[{"cell_type":"markdown","metadata":{"id":"7aa1693d"},"source":["# About this notebook\n","- This notebook is a modified version of the PyTorch pipeline from Y.Nakama's starter NLP notebook from Feedback Prize 3 competition [here](https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train). Don't forget to upvote his work!\n","- Inference notebook is [here](https://www.kaggle.com/mohammad2012191/debertav3-pytorch-baseline-inference-cv-0-467)"],"id":"7aa1693d"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1693415866607,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"VAH4GU3udQLE","outputId":"02848ec3-69e7-40c7-ed91-cd43d72f5d27"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Aug 30 17:17:45 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    25W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"],"id":"VAH4GU3udQLE"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27945,"status":"ok","timestamp":1693415894544,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"y7YWu2B1dPO_","outputId":"ca89c0d9-3b0f-4e50-a620-6dbe742df0f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"y7YWu2B1dPO_"},{"cell_type":"code","execution_count":3,"metadata":{"id":"QniqU23EOe1O","executionInfo":{"status":"ok","timestamp":1693415894546,"user_tz":-540,"elapsed":8,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["from google.colab import runtime\n","\n"],"id":"QniqU23EOe1O"},{"cell_type":"code","execution_count":3,"metadata":{"id":"16c51a23","executionInfo":{"status":"ok","timestamp":1693415894546,"user_tz":-540,"elapsed":7,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"16c51a23"},{"cell_type":"markdown","metadata":{"id":"d2e3dae0"},"source":["# CFG"],"id":"d2e3dae0"},{"cell_type":"code","execution_count":4,"metadata":{"id":"d22dfc09","executionInfo":{"status":"ok","timestamp":1693415894547,"user_tz":-540,"elapsed":8,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    exp='exp049'\n","    is_exp=False\n","    wandb=False\n","    competition='FB3'\n","    _wandb_kernel='nakama'\n","    debug=False\n","    apex=True\n","    print_freq=20\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-large\"\n","    gradient_checkpointing=True\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps_rate=0.1\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.98)\n","    batch_size=8\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    target_cols=['content', 'wording']\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    awp=False\n","    nth_awp_start_epoch= 3\n","    adv_lr = 1e-4\n","    adv_eps = 1e-2\n","    eval_steps = 150\n","    save_strategy='step'\n","    pooling='WeightedLayerPooling'\n","    freeze=True\n","    freeze_top_num_layer=10\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"],"id":"d22dfc09"},{"cell_type":"markdown","metadata":{"id":"NhFDBpBR3vGg"},"source":["# Directory settings"],"id":"NhFDBpBR3vGg"},{"cell_type":"code","execution_count":5,"metadata":{"id":"NJYVrhufgVPh","executionInfo":{"status":"ok","timestamp":1693415897780,"user_tz":-540,"elapsed":3240,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# Directory settings\n","# ====================================================\n","import os\n","\n","OUTPUT_DIR = f'/content/drive/MyDrive/Kaggle/outputs/{CFG.exp}/'\n","\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n"],"id":"NJYVrhufgVPh"},{"cell_type":"code","execution_count":6,"metadata":{"id":"eedc45a5","executionInfo":{"status":"ok","timestamp":1693415897781,"user_tz":-540,"elapsed":7,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","\n","    import wandb\n","\n","    try:\n","        from kaggle_secrets import UserSecretsClient\n","        user_secrets = UserSecretsClient()\n","        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        wandb.login(key=secret_value_0)\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project='FB3-Public',\n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=CFG.model,\n","                     job_type=\"train\",\n","                     anonymous=anony)"],"id":"eedc45a5"},{"cell_type":"markdown","metadata":{"id":"bec24bf5"},"source":["# Library"],"id":"bec24bf5"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f72fdd29","executionInfo":{"status":"ok","timestamp":1693415943587,"user_tz":-540,"elapsed":45812,"user":{"displayName":"たかいです","userId":"08363226705441905685"}},"outputId":"6ad63c80-2963-447a-cf60-de3b33ef7762"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.31.0\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.31.0)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.31.0)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.31.0\n","Requirement already satisfied: tokenizers==0.13.3 in /usr/local/lib/python3.10/dist-packages (0.13.3)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","tokenizers.__version__: 0.13.3\n","transformers.__version__: 4.31.0\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","os.system('pip install iterative-stratification==0.1.7')\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","#os.system('pip install -q transformers')\n","!pip install transformers==4.31.0\n","os.system('pip install -q tokenizers')\n","!pip install tokenizers==0.13.3\n","!pip install sentencepiece\n","\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"id":"f72fdd29"},{"cell_type":"markdown","metadata":{"id":"179b542c"},"source":["# Utils"],"id":"179b542c"},{"cell_type":"code","execution_count":8,"metadata":{"id":"f9795dd2","executionInfo":{"status":"ok","timestamp":1693415943588,"user_tz":-540,"elapsed":22,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=42)"],"id":"f9795dd2"},{"cell_type":"markdown","metadata":{"id":"fac79d7b"},"source":["# Data Loading"],"id":"fac79d7b"},{"cell_type":"code","execution_count":9,"metadata":{"id":"add36693","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1693415946392,"user_tz":-540,"elapsed":2823,"user":{"displayName":"たかいです","userId":"08363226705441905685"}},"outputId":"f7fa7cf4-4fcd-44d0-d82a-f191666035e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["train.shape: (7165, 8)\n"]},{"output_type":"display_data","data":{"text/plain":["     student_id prompt_id                                               text   content   wording                                    prompt_question               prompt_title                                        prompt_text\n","0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...  0.205683  0.380538  Summarize how the Third Wave developed over su...             The Third Wave  Background \\r\\nThe Third Wave experiment took ...\n","1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme... -0.548304  0.506755  Summarize the various ways the factory would u...    Excerpt from The Jungle  With one member trimming beef in a cannery, an...\n","2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...  3.128928  4.231226  In complete sentences, summarize the structure...  Egyptian Social Structure  Egyptian society was structured like a pyramid...\n","3  005ab0199905    3b9047  The highest class was Pharaohs these people we... -0.210614 -0.471415  In complete sentences, summarize the structure...  Egyptian Social Structure  Egyptian society was structured like a pyramid...\n","4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...  3.272894  3.219757  Summarize how the Third Wave developed over su...             The Third Wave  Background \\r\\nThe Third Wave experiment took ..."],"text/html":["\n","  <div id=\"df-5129cbbd-cb64-45f2-9405-af3a5bfe040c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000e8c3c7ddb</td>\n","      <td>814d6b</td>\n","      <td>The third wave was an experimentto see how peo...</td>\n","      <td>0.205683</td>\n","      <td>0.380538</td>\n","      <td>Summarize how the Third Wave developed over su...</td>\n","      <td>The Third Wave</td>\n","      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0020ae56ffbf</td>\n","      <td>ebad26</td>\n","      <td>They would rub it up with soda to make the sme...</td>\n","      <td>-0.548304</td>\n","      <td>0.506755</td>\n","      <td>Summarize the various ways the factory would u...</td>\n","      <td>Excerpt from The Jungle</td>\n","      <td>With one member trimming beef in a cannery, an...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>004e978e639e</td>\n","      <td>3b9047</td>\n","      <td>In Egypt, there were many occupations and soci...</td>\n","      <td>3.128928</td>\n","      <td>4.231226</td>\n","      <td>In complete sentences, summarize the structure...</td>\n","      <td>Egyptian Social Structure</td>\n","      <td>Egyptian society was structured like a pyramid...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>005ab0199905</td>\n","      <td>3b9047</td>\n","      <td>The highest class was Pharaohs these people we...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","      <td>In complete sentences, summarize the structure...</td>\n","      <td>Egyptian Social Structure</td>\n","      <td>Egyptian society was structured like a pyramid...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0070c9e7af47</td>\n","      <td>814d6b</td>\n","      <td>The Third Wave developed  rapidly because the ...</td>\n","      <td>3.272894</td>\n","      <td>3.219757</td>\n","      <td>Summarize how the Third Wave developed over su...</td>\n","      <td>The Third Wave</td>\n","      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5129cbbd-cb64-45f2-9405-af3a5bfe040c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5129cbbd-cb64-45f2-9405-af3a5bfe040c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5129cbbd-cb64-45f2-9405-af3a5bfe040c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6849ea17-def3-4798-89bf-e300406d3071\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6849ea17-def3-4798-89bf-e300406d3071')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6849ea17-def3-4798-89bf-e300406d3071 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["test.shape: (4, 6)\n"]},{"output_type":"display_data","data":{"text/plain":["     student_id prompt_id            text prompt_question     prompt_title       prompt_text\n","0  000000ffffff    abc123  Example text 1    Summarize...  Example Title 1  Heading\\nText...\n","1  111111eeeeee    def789  Example text 2    Summarize...  Example Title 2  Heading\\nText...\n","2  222222cccccc    abc123  Example text 3    Summarize...  Example Title 1  Heading\\nText...\n","3  333333dddddd    def789  Example text 4    Summarize...  Example Title 2  Heading\\nText..."],"text/html":["\n","  <div id=\"df-bcf7b7c2-0ded-4474-965c-fbbff74b52f4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>abc123</td>\n","      <td>Example text 1</td>\n","      <td>Summarize...</td>\n","      <td>Example Title 1</td>\n","      <td>Heading\\nText...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>def789</td>\n","      <td>Example text 2</td>\n","      <td>Summarize...</td>\n","      <td>Example Title 2</td>\n","      <td>Heading\\nText...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>abc123</td>\n","      <td>Example text 3</td>\n","      <td>Summarize...</td>\n","      <td>Example Title 1</td>\n","      <td>Heading\\nText...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>def789</td>\n","      <td>Example text 4</td>\n","      <td>Summarize...</td>\n","      <td>Example Title 2</td>\n","      <td>Heading\\nText...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcf7b7c2-0ded-4474-965c-fbbff74b52f4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bcf7b7c2-0ded-4474-965c-fbbff74b52f4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bcf7b7c2-0ded-4474-965c-fbbff74b52f4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["submission.shape: (4, 3)\n"]},{"output_type":"display_data","data":{"text/plain":["     student_id  content  wording\n","0  000000ffffff      0.0      0.0\n","1  111111eeeeee      0.0      0.0\n","2  222222cccccc      0.0      0.0\n","3  333333dddddd      0.0      0.0"],"text/html":["\n","  <div id=\"df-046dff6d-c065-45bc-a3a0-c6157af13d93\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-046dff6d-c065-45bc-a3a0-c6157af13d93')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-046dff6d-c065-45bc-a3a0-c6157af13d93 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-046dff6d-c065-45bc-a3a0-c6157af13d93');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","input_path = '/content/drive/MyDrive/Kaggle/inputs/'\n","train = pd.read_csv(input_path+'summaries_train.csv')\n","test = pd.read_csv(input_path+'summaries_test.csv')\n","submission = pd.read_csv(input_path+'sample_submission.csv')\n","prompt_train = pd.read_csv(input_path+'prompts_train.csv')\n","prompt_test = pd.read_csv(input_path+'prompts_test.csv')\n","train = pd.merge(train,prompt_train,how='left',on='prompt_id')\n","test = pd.merge(test,prompt_test,how='left',on='prompt_id')\n","print(f\"train.shape: {train.shape}\")\n","display(train.head())\n","print(f\"test.shape: {test.shape}\")\n","display(test.head())\n","print(f\"submission.shape: {submission.shape}\")\n","display(submission.head())"],"id":"add36693"},{"cell_type":"code","execution_count":10,"metadata":{"id":"2KzAhY4R3zRK","executionInfo":{"status":"ok","timestamp":1693415946393,"user_tz":-540,"elapsed":31,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# oof_df=pd.read_pickle(input_path+'oof_df.pkl')"],"id":"2KzAhY4R3zRK"},{"cell_type":"code","execution_count":11,"metadata":{"id":"a37a56e4","executionInfo":{"status":"ok","timestamp":1693415946394,"user_tz":-540,"elapsed":31,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["train['text'] =  train['prompt_question'] + ' [SEP] ' + train['text']\n","test['text'] =  test['prompt_question'] + '[SEP]' + test['text']\n","\n","\n","#################################################\n","# prompt_textも\n","#################################################\n","\n","# # \"text\"列の長さを計算して新しい列\"length\"に追加\n","# train['length'] = train['text'].apply(len)\n","# # \"text\"列の先頭に\"length\"列の値を結合\n","# train['text'] = train['length'].astype(str) + '[SEP]' + train['prompt_question'] + '[SEP]' +train['prompt_title'] + 'summary(' + train['text'] +') [SEP] source of summary('+train['prompt_text']+')'\n","\n","# # \"text\"列の長さを計算して新しい列\"length\"に追加\n","# test['length'] = test['text'].apply(len)\n","# # \"text\"列の先頭に\"length\"列の値を結合\n","# test['text'] = test['length'].astype(str) + '[SEP]' + test['prompt_question'] + '[SEP]' +test['prompt_title'] + 'summary(' + test['text'] +') [SEP] source of summary('+test['prompt_text']+')'\n"],"id":"a37a56e4"},{"cell_type":"code","source":[],"metadata":{"id":"OTjtOHdZERdZ","executionInfo":{"status":"ok","timestamp":1693415946395,"user_tz":-540,"elapsed":31,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"id":"OTjtOHdZERdZ","execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bfcf2f21"},"source":["# CV split"],"id":"bfcf2f21"},{"cell_type":"code","execution_count":12,"metadata":{"id":"fe773f94","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1693415946396,"user_tz":-540,"elapsed":31,"user":{"displayName":"たかいです","userId":"08363226705441905685"}},"outputId":"a39b8a93-6f74-443f-bb53-5c6db8820705"},"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    1103\n","1    2057\n","2    2009\n","3    1996\n","dtype: int64"]},"metadata":{}}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","# Fold = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_cols])):\n","#     train.loc[val_index, 'fold'] = int(n)\n","id2fold = {\n","    \"814d6b\": 0,\n","    \"39c16e\": 1,\n","    \"3b9047\": 2,\n","    \"ebad26\": 3,\n","}\n","\n","train[\"fold\"] = train[\"prompt_id\"].map(id2fold)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"],"id":"fe773f94"},{"cell_type":"code","execution_count":13,"metadata":{"id":"26ece1cd","executionInfo":{"status":"ok","timestamp":1693415946397,"user_tz":-540,"elapsed":29,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=3000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"],"id":"26ece1cd"},{"cell_type":"markdown","metadata":{"id":"478fb80d"},"source":["# tokenizer"],"id":"478fb80d"},{"cell_type":"code","execution_count":14,"metadata":{"id":"GLyHNCkSh0CG","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1693415946398,"user_tz":-540,"elapsed":30,"user":{"displayName":"たかいです","userId":"08363226705441905685"}},"outputId":"20dc09c4-b880-4c31-bcca-084b74ae71c2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'microsoft/deberta-v3-large'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["CFG.model"],"id":"GLyHNCkSh0CG"},{"cell_type":"code","execution_count":15,"metadata":{"id":"1a9ff4aa","colab":{"base_uri":"https://localhost:8080/","height":253,"referenced_widgets":["970d8c5b78dc4076be3d91210070b429","6b693e8b01404caaafd4a593c55a3f5e","f2401886a7aa4d289069b31733da362b","4100b4c4a589455d8452f5d04e2f5a9b","b27b10311ef84260856401cb78513b27","f2c26584d1a64a98ab6b8e74e834c100","a66373e5a04343faaddc2370c49e0888","2161f31626834a48a98e0e481a171fbf","9b6658a042d443e4ab22975c05f6223c","e823013101bd41d58b471eae7ec64ac0","c652c3e57ce0491da727b113559ac56e","824ecf25aa3f4821a6a030e87b77d078","1bf6f15204fa475abccef37cf3bbfce4","5416efcd5f424f769f838bec59fdaa96","cadb7617ad8848b0a6d691427aa662da","4c4529e05bda4fcaac9bc576fb90c41b","a08eedc3d5b047cc9751344f2327d0e0","4be09f4c339c41d6a00045939b4c97b0","550f62cbb327447e88ff3df1fc532b0e","d9634e9011ad457ba7d79edc7f6ddb60","d7975e9f7da5488ab04f22cf81efa487","73637274def04540b5b29f1fd1954df3","df2bebecf8a342f4b2410c95e34f2a7c","fcabfa77050e41c2be39bf5ca6a5a0ab","fb614279031f429487ff938324463804","7b7c215743a741348a666431dc69af5c","9a51ff9a9a764a708ee256deca6a7395","a2d9d8a45bea4613b38bc131b221ffe6","358f112dc2e6485f97a849d1a2e51038","4b59a417aa3d48f0a4d9df8e5f5f8168","0a2d95e2253f4f20a2d810502a57a72c","73340313eb5d4fb0b43c7731108ce90c","f5c25e16c58a46a6b0e7f7eceaf7f4f5"]},"executionInfo":{"status":"ok","timestamp":1693415949988,"user_tz":-540,"elapsed":3615,"user":{"displayName":"たかいです","userId":"08363226705441905685"}},"outputId":"3fa87bfd-6390-482c-e8ea-4156cb91529c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"970d8c5b78dc4076be3d91210070b429"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"824ecf25aa3f4821a6a030e87b77d078"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df2bebecf8a342f4b2410c95e34f2a7c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"id":"1a9ff4aa"},{"cell_type":"code","source":["train['text'].iloc[8]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"cQZWV8VaE0xO","executionInfo":{"status":"ok","timestamp":1693415949989,"user_tz":-540,"elapsed":17,"user":{"displayName":"たかいです","userId":"08363226705441905685"}},"outputId":"254e0738-a202-4b99-9f78-107da5da3091"},"id":"cQZWV8VaE0xO","execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Summarize at least 3 elements of an ideal tragedy, as described by Aristotle. [SEP] 1 element of an ideal tragedy is that it should be arranged on a complex plan.  Another element of an ideal tragedy is that it should only have one main issue. The last element of an ideal tragedy is that it should have a double thread plot and an opposite catastrophe for both good and bad.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# テキストをエンコード\n","text = 'unnko'\n","encoded = tokenizer(text, return_tensors='pt')\n","\n","# デコードして元のテキストを取得\n","\n","decoded_tokens = tokenizer.convert_ids_to_tokens(encoded['input_ids'][0])\n","decoded_text = \" \".join(decoded_tokens)\n","\n","print(f\"Original text: {text}\")\n","print(f\"Encoded: {encoded}\")\n","print(f\"Decoded text: {decoded_text}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"36zvorT0EVVA","executionInfo":{"status":"ok","timestamp":1693415949989,"user_tz":-540,"elapsed":14,"user":{"displayName":"たかいです","userId":"08363226705441905685"}},"outputId":"b8642a9b-52b7-45e6-bccc-f8de0f6527bf"},"id":"36zvorT0EVVA","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Original text: unnko\n","Encoded: {'input_ids': tensor([[   1, 1655,  673, 4712,    2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n","Decoded text: [CLS] ▁un n ko [SEP]\n"]}]},{"cell_type":"markdown","metadata":{"id":"0e4568b4"},"source":["# Dataset"],"id":"0e4568b4"},{"cell_type":"code","execution_count":18,"metadata":{"id":"5d1060ed","colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["e42cfbe8031149d7be4706d6c79d341a","b5492217d3e740d8adb79bbe0d8b5fb7","187bc0145bd2401bb070ec61a2036108","309870e0369846a4987e81fc45ff567b","e1282c70acee4f4081bef6c1a9adfb59","15ff975eef914f8b865fc09e350e864a","590a2db7e98742af80e471777df78bf2","4602034f95b34b0a92fd46ffd0b58691","479cb19f52d148ffa240d25e1e1eaa8a","3652fb1849804b0b975b317e5bf0c717","2179ce3c34d44799b2477159e8b655a6"]},"executionInfo":{"status":"ok","timestamp":1693415953944,"user_tz":-540,"elapsed":3967,"user":{"displayName":"たかいです","userId":"08363226705441905685"}},"outputId":"44fbcd89-e14c-4677-e766-a46f775df745"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/7165 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e42cfbe8031149d7be4706d6c79d341a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_len: 854\n","INFO:__main__:max_len: 854\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['text'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 2 # cls & sep\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"],"id":"5d1060ed"},{"cell_type":"code","execution_count":19,"metadata":{"id":"2bd231fe","executionInfo":{"status":"ok","timestamp":1693415953945,"user_tz":-540,"elapsed":7,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text,\n","        return_tensors=None,\n","        add_special_tokens=True,\n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df[cfg.target_cols].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs"],"id":"2bd231fe"},{"cell_type":"markdown","metadata":{"id":"694f45ea"},"source":["# Model"],"id":"694f45ea"},{"cell_type":"code","execution_count":20,"metadata":{"id":"be0cf2ca","executionInfo":{"status":"ok","timestamp":1693415953946,"user_tz":-540,"elapsed":8,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["#ref:https://github.com/shu421/kagglib/blob/main/nlp/model.py\n","# ====================================================\n","# Model\n","# ====================================================\n","\n","def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","\n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","# =====================================================\n","# Pooling\n","# =====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","\n","\n","class AttentionPooling(nn.Module):\n","    \"\"\"\n","    Usage:\n","        self.pool = AttentionPooling(self.config.hidden_size)\n","    \"\"\"\n","    def __init__(self, in_dim):\n","        super().__init__()\n","        self.attention = nn.Sequential(\n","            nn.Linear(in_dim, in_dim),\n","            nn.LayerNorm(in_dim),\n","            nn.GELU(),\n","            nn.Linear(in_dim, 1),\n","        )\n","\n","        self._init_weights(self.attention)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        w = self.attention(last_hidden_state).float()\n","        w[attention_mask == 0] = float(\"-inf\")\n","        w = torch.softmax(w, 1)\n","        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n","        return attention_embeddings\n","\n","\n","\n","class WeightedLayerPooling(nn.Module):\n","    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights=None):\n","        super(WeightedLayerPooling, self).__init__()\n","        self.layer_start = layer_start\n","        self.num_hidden_layers = num_hidden_layers\n","        self.layer_weights = layer_weights if layer_weights is not None \\\n","            else nn.Parameter(\n","            torch.tensor([1] * (num_hidden_layers + 1 - layer_start), dtype=torch.float)\n","        )\n","\n","    def forward(self, all_hidden_states):\n","        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n","        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n","        weighted_average = (weight_factor * all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n","        return weighted_average[:, 0]\n","\n","class LSTMPooling(nn.Module):\n","    def __init__(self, num_layers, hidden_size, hiddendim_lstm, dropout_rate, is_lstm=True):\n","        super(LSTMPooling, self).__init__()\n","        self.num_hidden_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.hiddendim_lstm = hiddendim_lstm\n","\n","        if is_lstm:\n","            self.lstm = nn.LSTM(self.hidden_size, self.hiddendim_lstm, batch_first=True)\n","        else:\n","            self.lstm = nn.GRU(self.hidden_size, self.hiddendim_lstm, batch_first=True, bidirectional=True)\n","\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","    def forward(self, all_hidden_states):\n","        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n","                                     for layer_i in range(1, self.num_hidden_layers + 1)], dim=-1)\n","        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n","        out, _ = self.lstm(hidden_states, None)\n","        out = self.dropout(out[:, -1, :])\n","        return out\n","\n","class ConcatPooling(nn.Module):\n","    def __init__(self, n_layers=4):\n","        super(ConcatPooling, self, ).__init__()\n","\n","        self.n_layers = n_layers\n","\n","    def forward(self, all_hidden_states):\n","        concatenate_pooling = torch.cat([all_hidden_states[-(i + 1)] for i in range(self.n_layers)], -1)\n","        concatenate_pooling = concatenate_pooling[:, 0]\n","        return concatenate_pooling\n","\n","# GeM\n","class GeMText(nn.Module):\n","    def __init__(self, dim=1, cfg=None, p=3, eps=1e-6):\n","        super(GeMText, self).__init__()\n","        self.dim = dim\n","        self.p = Parameter(torch.ones(1) * p)\n","        self.eps = eps\n","        self.feat_mult = 1\n","        # x seeems last hidden state\n","\n","    def forward(self, x, attention_mask):\n","        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(x.shape)\n","        x = (x.clamp(min=self.eps) * attention_mask_expanded).pow(self.p).sum(self.dim)\n","        ret = x / attention_mask_expanded.sum(self.dim).clip(min=self.eps)\n","        ret = ret.pow(1 / self.p)\n","        return ret\n","\n","# ===========================================\n","# custom Model\n","# ===========================================\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        if cfg.pooling =='LSTMPooling':\n","            self.pool =  LSTMPooling(self.config.num_hidden_layers,\n","                                       self.config.hidden_size,\n","                                       self.cfg.hidden_size,\n","                                       0.1,\n","                                       is_lstm=True\n","                           )\n","            self.fc = nn.Linear(self.cfg.hidden_size, 2)\n","        elif cfg.pooling == \"GeM\":\n","            self.pool = GeMText()\n","            self.fc = nn.Linear(self.config.hidden_size, 2)\n","        elif cfg.pooling=='ConcatPooling':\n","            self.pool = ConcatPooling(n_layers=cfg.n_layers)\n","            self.fc = nn.Linear(cfg.n_layers*self.config.hidden_size, 2)\n","        elif cfg.pooling=='WeightedLayerPooling':\n","            self.pool = WeightedLayerPooling(self.config.num_hidden_layers)\n","            self.fc = nn.Linear(self.config.hidden_size, 2)\n","\n","\n","        self._init_weights(self.fc)\n","\n","\n","        # Freeze\n","        if self.cfg.freeze:\n","            freeze(self.model.encoder.layer[:self.cfg.freeze_top_num_layer])\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        if self.cfg.pooling=='MeanPooling':\n","          feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        elif self.cfg.pooling in ['GRUPooling', 'LSTMPooling']:\n","            all_hidden_states = torch.stack(outputs[1])\n","            feature = self.pool(all_hidden_states)\n","        elif self.cfg.pooling=='GeM':\n","          feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        elif self.cfg.pooling == 'ConcatPooling':\n","            all_hidden_states = torch.stack(outputs[1])\n","            feature = self.pool(all_hidden_states)\n","        elif self.cfg.pooling == 'WeightedLayerPooling':\n","            all_hidden_states = torch.stack(outputs[1])\n","            feature = self.pool(all_hidden_states)\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output\n","\n","\n","# initialize layer\n","def reinit_bert(model):\n","    \"\"\"_summary_\n","\n","    Args:\n","        model (AutoModel): _description_\n","\n","    Returns:\n","        model (AutoModel): _description_\n","\n","    Usage:\n","        model = reinit_bert(model)\n","    \"\"\"\n","    for layer in model.model.encoder.layer[-1:]:\n","        for module in layer.modules():\n","            if isinstance(module, nn.Linear):\n","                module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                if module.bias is not None:\n","                    module.bias.data.zero_()\n","            elif isinstance(module, nn.Embedding):\n","                module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                if module.padding_idx is not None:\n","                    module.weight.data[module.padding_idx].zero_()\n","            elif isinstance(module, nn.LayerNorm):\n","                module.bias.data.zero_()\n","                module.weight.data.fill_(1.0)\n","    return model"],"id":"be0cf2ca"},{"cell_type":"markdown","metadata":{"id":"31b35d08"},"source":["# Loss"],"id":"31b35d08"},{"cell_type":"code","execution_count":21,"metadata":{"id":"ac3909be","executionInfo":{"status":"ok","timestamp":1693415966562,"user_tz":-540,"elapsed":12622,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# Loss\n","# ====================================================\n","class RMSELoss(nn.Module):\n","    def __init__(self, reduction='mean', eps=1e-9):\n","        super().__init__()\n","        self.mse = nn.MSELoss(reduction='none')\n","        self.reduction = reduction\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true):\n","        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss\n","\n","\n","\n","class WeightedSmoothL1Loss(nn.Module):\n","    def __init__(self,weights = torch.tensor([0.5, 1.2], device = device )):\n","        super(WeightedSmoothL1Loss, self).__init__()\n","        self.weights=weights\n","\n","    def forward(self, inputs, targets):\n","        \"\"\"\n","        inputs: ネットワークの出力 (予測値)\n","        targets: 正解ラベル\n","        weights: 各サンプルに対する重み\n","        \"\"\"\n","        # Smooth L1 損失を計算\n","        loss = nn.SmoothL1Loss(reduction='none')(inputs, targets)\n","\n","        # 重みを適用して損失を計算\n","        weighted_loss = torch.mean(loss * self.weights)\n","\n","        return weighted_loss\n","\n","\n","class MCRMSELoss(nn.Module):\n","    def __init__(self):\n","        super(MCRMSELoss, self).__init__()\n","\n","    def forward(self, y_true, y_pred):\n","        colwise_mse = torch.mean(torch.square(y_true - y_pred), dim=0)\n","        return torch.mean(torch.sqrt(colwise_mse), dim=0)"],"id":"ac3909be"},{"cell_type":"markdown","metadata":{"id":"lKO48EXzL8mV"},"source":["# AWP"],"id":"lKO48EXzL8mV"},{"cell_type":"code","execution_count":22,"metadata":{"id":"1zMdI9u5L-HP","executionInfo":{"status":"ok","timestamp":1693415966563,"user_tz":-540,"elapsed":8,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["from torch import Tensor\n","from torch.nn import Module\n","from torch.optim import Optimizer\n","from torch.nn.modules.loss import _Loss\n","\n","class AWP:\n","    def __init__(\n","        self,\n","        model: Module,\n","        criterion: _Loss,\n","        optimizer: Optimizer,\n","        apex: bool,\n","        adv_param: str=\"weight\",\n","        adv_lr: float=1.0,\n","        adv_eps: float=0.01\n","    ) -> None:\n","        self.model = model\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.apex = apex\n","        self.backup = {}\n","        self.backup_eps = {}\n","\n","    def attack_backward(self, inputs: dict, label: Tensor) -> Tensor:\n","        with torch.cuda.amp.autocast(enabled=self.apex):\n","            self._save()\n","            self._attack_step() # モデルを近傍の悪い方へ改変\n","            y_preds = self.model(inputs)\n","            adv_loss = self.criterion(\n","                y_preds.view(-1, 1), label.view(-1, 1))\n","            mask = (label.view(-1, 1) != -1)\n","            adv_loss = torch.masked_select(adv_loss, mask).mean()\n","            self.optimizer.zero_grad()\n","        return adv_loss\n","\n","    def _attack_step(self) -> None:\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                norm1 = torch.norm(param.grad)\n","                norm2 = torch.norm(param.data.detach())\n","                if norm1 != 0 and not torch.isnan(norm1):\n","                    # 直前に損失関数に通してパラメータの勾配を取得できるようにしておく必要あり\n","                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n","                    param.data.add_(r_at)\n","                    param.data = torch.min(\n","                        torch.max(\n","                            param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n","                    )\n","\n","    def _save(self) -> None:\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.data.clone()\n","                    grad_eps = self.adv_eps * param.abs().detach()\n","                    self.backup_eps[name] = (\n","                        self.backup[name] - grad_eps,\n","                        self.backup[name] + grad_eps,\n","                    )\n","\n","    def _restore(self) -> None:\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data = self.backup[name]\n","        self.backup = {}\n","        self.backup_eps = {}"],"id":"1zMdI9u5L-HP"},{"cell_type":"markdown","metadata":{"id":"d6344760"},"source":["# Helpler functions"],"id":"d6344760"},{"cell_type":"code","execution_count":23,"metadata":{"id":"978896ec","executionInfo":{"status":"ok","timestamp":1693415966563,"user_tz":-540,"elapsed":7,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","\n","    if CFG.awp and epoch+1 >= CFG.nth_awp_start_epoch:\n","        LOGGER.info(f'AWP training with epoch {epoch+1}')\n","    model.train()\n","    awp = AWP(\n","            model,\n","            criterion,\n","            optimizer,\n","            CFG.apex,\n","            adv_lr=CFG.adv_lr,\n","            adv_eps=CFG.adv_eps\n","        )\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if CFG.awp and CFG.nth_awp_start_epoch <= epoch+1:\n","            loss = awp.attack_backward(inputs, labels)\n","            scaler.scale(loss).backward()\n","            awp._restore()\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader),\n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions\n","\n","\n","\n","\n","\n","# def train_fn_by_step(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, now_step):\n","\n","#     # if CFG.awp and epoch+1 >= CFG.nth_awp_start_epoch:\n","#     #     LOGGER.info(f'AWP training with epoch {epoch+1}')\n","#     model.train()\n","#     # awp = AWP(\n","#     #         model,\n","#     #         criterion,\n","#     #         optimizer,\n","#     #         CFG.apex,\n","#     #         adv_lr=CFG.adv_lr,\n","#     #         adv_eps=CFG.adv_eps\n","#     #     )\n","#     if now_step==0:\n","#       scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","#       losses = AverageMeter()\n","#       start = end = time.time()\n","#       global_step = 0\n","#     for step, (inputs, labels) in enumerate(train_loader):\n","#         if now_step>step:\n","#           continue\n","#         inputs = collate(inputs)\n","#         for k, v in inputs.items():\n","#             inputs[k] = v.to(device)\n","#         labels = labels.to(device)\n","#         batch_size = labels.size(0)\n","#         with torch.cuda.amp.autocast(enabled=CFG.apex):\n","#             y_preds = model(inputs)\n","#             loss = criterion(y_preds, labels)\n","#         if CFG.gradient_accumulation_steps > 1:\n","#             loss = loss / CFG.gradient_accumulation_steps\n","#         losses.update(loss.item(), batch_size)\n","#         scaler.scale(loss).backward()\n","#         grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","#         # if CFG.awp and CFG.nth_awp_start_epoch <= epoch+1:\n","#         #     loss = awp.attack_backward(inputs, labels)\n","#         #     scaler.scale(loss).backward()\n","#         #     awp._restore()\n","\n","#         if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","#             scaler.step(optimizer)\n","#             scaler.update()\n","#             optimizer.zero_grad()\n","#             global_step += 1\n","#             if CFG.batch_scheduler:\n","#                 scheduler.step()\n","#         end = time.time()\n","#         if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","#             print('Epoch: [{0}][{1}/{2}] '\n","#                   'Elapsed {remain:s} '\n","#                   'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","#                   'Grad: {grad_norm:.4f}  '\n","#                   'LR: {lr:.8f}  '\n","#                   .format(epoch+1, step, len(train_loader),\n","#                           remain=timeSince(start, float(step+1)/len(train_loader)),\n","#                           loss=losses,\n","#                           grad_norm=grad_norm,\n","#                           lr=scheduler.get_lr()[0]))\n","\n","#         if CFG.wandb:\n","#             wandb.log({f\"[fold{fold}] loss\": losses.val,\n","#                        f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","#         if step%CFG.eval_steps==0:\n","#           return losses.avg, step+1 ,epoch\n","\n","#     return losses.avg, step+1 ,epoch+1\n","\n","\n"],"id":"978896ec"},{"cell_type":"markdown","metadata":{"id":"fdb6b5d6"},"source":["# train loop"],"id":"fdb6b5d6"},{"cell_type":"code","execution_count":24,"metadata":{"id":"9088253a","executionInfo":{"status":"ok","timestamp":1693415966563,"user_tz":-540,"elapsed":7,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size * 2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr,\n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=int(cfg.num_warmup_steps_rate*num_train_steps), num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=int(cfg.num_warmup_steps_rate*num_train_steps), num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = MCRMSELoss()\n","    #nn.SmoothL1Loss(reduction='mean')\n","    # WeightedSmoothL1Loss(reduction='mean') #\n","\n","    best_score = np.inf\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","\n","        # scoring\n","        score, scores = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1,\n","                       f\"[fold{fold}] avg_train_loss\": avg_loss,\n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","\n","        if best_score > score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# ====================================================\n","# train loop by steps\n","# ====================================================\n","def train_loop_steps(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size * 2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr,\n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=int(cfg.num_warmup_steps_rate*num_train_steps), num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=int(cfg.num_warmup_steps_rate*num_train_steps), num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = MCRMSELoss()\n","    #nn.SmoothL1Loss(reduction='mean')\n","    # WeightedSmoothL1Loss(reduction='mean') #\n","\n","    best_score = np.inf\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        model.train()\n","        scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","        losses = AverageMeter()\n","        start = end = time.time()\n","        global_step = 0\n","        for step, (inputs, labels) in enumerate(train_loader):\n","\n","            inputs = collate(inputs)\n","            for k, v in inputs.items():\n","                inputs[k] = v.to(device)\n","            labels = labels.to(device)\n","            batch_size = labels.size(0)\n","            with torch.cuda.amp.autocast(enabled=CFG.apex):\n","                y_preds = model(inputs)\n","                loss = criterion(y_preds, labels)\n","            if CFG.gradient_accumulation_steps > 1:\n","                loss = loss / CFG.gradient_accumulation_steps\n","            losses.update(loss.item(), batch_size)\n","            scaler.scale(loss).backward()\n","            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","                global_step += 1\n","                if CFG.batch_scheduler:\n","                    scheduler.step()\n","            end = time.time()\n","            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","                print('Epoch: [{0}][{1}/{2}] '\n","                      'Elapsed {remain:s} '\n","                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                      'Grad: {grad_norm:.4f}  '\n","                      'LR: {lr:.8f}  '\n","                      .format(epoch+1, step, len(train_loader),\n","                              remain=timeSince(start, float(step+1)/len(train_loader)),\n","                              loss=losses,\n","                              grad_norm=grad_norm,\n","                              lr=scheduler.get_lr()[0]))\n","            if CFG.wandb:\n","                wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                          f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","\n","            if (step % CFG.eval_steps==0 and step!=0) or step == (len(train_loader)-1):\n","\n","                  # valid\n","                  losses_val = AverageMeter()\n","                  model.eval()\n","                  preds = []\n","\n","                  for val_step, (inputs, labels) in enumerate(valid_loader):\n","\n","                      inputs = collate(inputs)\n","                      for k, v in inputs.items():\n","                          inputs[k] = v.to(device)\n","                      labels = labels.to(device)\n","                      batch_size = labels.size(0)\n","                      with torch.no_grad():\n","                          y_preds = model(inputs)\n","                          loss = criterion(y_preds, labels)\n","                      if CFG.gradient_accumulation_steps > 1:\n","                          loss = loss / CFG.gradient_accumulation_steps\n","                      losses_val.update(loss.item(), batch_size)\n","                      preds.append(y_preds.to('cpu').numpy())\n","\n","                      if val_step % CFG.print_freq == 0 or val_step == (len(valid_loader)-1):\n","                          print('EVAL: [{0}/{1}] '\n","                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                                .format(val_step, len(valid_loader),\n","                                        loss=losses_val))\n","                  predictions = np.concatenate(preds)\n","\n","                  # scoring\n","                  score, scores = get_score(valid_labels, predictions)\n","\n","                  elapsed = time.time() - start_time\n","\n","\n","\n","                  if best_score > score:\n","                      best_score = score\n","                      LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","                      torch.save({'model': model.state_dict(),\n","                                  'predictions': predictions},\n","                                  OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","\n","                  LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {losses.avg:.4f}  avg_val_loss: {losses_val.avg:.4f}')\n","                  LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","                  # if CFG.wandb:\n","                  #     wandb.log({f\"[fold{fold}] epoch\": epoch+1,\n","                  #                f\"[fold{fold}] avg_train_loss\": avg_loss,\n","                  #                f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                  #                f\"[fold{fold}] score\": score})\n","                  model.train()\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds\n"],"id":"9088253a"},{"cell_type":"code","execution_count":25,"metadata":{"id":"fde1c8af","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["92dc721976cf4affb90482e46fe3ce8f","f8ace65c55af453d88e70a3d0724cbea","cf9c4ab0d5f34e4ab17e777ce2f2da19","8ef20d7c436f435ea320768acc81e166","8433d5c02ee34dab9647a1e7c825ab2e","abb5171e19454e9ba593470fe9ca7cc2","7ee3947ad13c43639df1d72b255cf2b7","41e0608784a6414196dfe07f5e5907a5","2820e38bcd654b509c44172ad30529d7","3058ef9afc334329b737e551c3e4181a","dfc044c84f8544fcb434c2efa9e90b1f"]},"outputId":"af5c299c-974e-4302-a2a9-9873fb95fef4","executionInfo":{"status":"ok","timestamp":1693422465382,"user_tz":-540,"elapsed":6498826,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92dc721976cf4affb90482e46fe3ce8f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/757] Elapsed 0m 4s (remain 53m 37s) Loss: 1.1463(1.1463) Grad: 63597.6680  LR: 0.00000007  \n","Epoch: [1][20/757] Elapsed 0m 9s (remain 5m 20s) Loss: 0.8650(0.8809) Grad: 27126.3691  LR: 0.00000139  \n","Epoch: [1][40/757] Elapsed 0m 13s (remain 4m 4s) Loss: 0.9485(0.9176) Grad: 32774.6211  LR: 0.00000271  \n","Epoch: [1][60/757] Elapsed 0m 19s (remain 3m 47s) Loss: 0.8111(0.9158) Grad: 30405.8652  LR: 0.00000403  \n","Epoch: [1][80/757] Elapsed 0m 25s (remain 3m 32s) Loss: 1.0701(0.9456) Grad: 112035.7812  LR: 0.00000535  \n","Epoch: [1][100/757] Elapsed 0m 30s (remain 3m 15s) Loss: 0.6550(0.9227) Grad: 83293.9453  LR: 0.00000667  \n","Epoch: [1][120/757] Elapsed 0m 36s (remain 3m 10s) Loss: 0.7023(0.9001) Grad: 203740.5469  LR: 0.00000799  \n","Epoch: [1][140/757] Elapsed 0m 42s (remain 3m 4s) Loss: 0.6583(0.8723) Grad: 323125.2812  LR: 0.00000931  \n","EVAL: [0/69] Loss: 0.9941(0.9941) \n","EVAL: [20/69] Loss: 0.7428(0.8712) \n","EVAL: [40/69] Loss: 0.7343(0.8366) \n","EVAL: [60/69] Loss: 0.7729(0.8378) \n","EVAL: [68/69] Loss: 1.1393(0.8533) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.8690 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.8690 Model\n","Epoch 1 - avg_train_loss: 0.8613  avg_val_loss: 0.8533\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.8613  avg_val_loss: 0.8533\n","Epoch 1 - Score: 0.8690  Scores: [0.7164752783966943, 1.021437404239216]\n","INFO:__main__:Epoch 1 - Score: 0.8690  Scores: [0.7164752783966943, 1.021437404239216]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][160/757] Elapsed 1m 22s (remain 5m 5s) Loss: 0.5790(0.8443) Grad: 367940.5312  LR: 0.00001063  \n","Epoch: [1][180/757] Elapsed 1m 28s (remain 4m 42s) Loss: 0.7998(0.8251) Grad: 182253.2812  LR: 0.00001195  \n","Epoch: [1][200/757] Elapsed 1m 34s (remain 4m 22s) Loss: 0.4624(0.7951) Grad: 198299.7500  LR: 0.00001327  \n","Epoch: [1][220/757] Elapsed 1m 45s (remain 4m 15s) Loss: 0.6800(0.7743) Grad: 223041.1250  LR: 0.00001459  \n","Epoch: [1][240/757] Elapsed 1m 51s (remain 3m 59s) Loss: 0.4729(0.7620) Grad: 127046.5391  LR: 0.00001591  \n","Epoch: [1][260/757] Elapsed 1m 59s (remain 3m 47s) Loss: 0.4593(0.7460) Grad: 448137.5000  LR: 0.00001723  \n","Epoch: [1][280/757] Elapsed 2m 4s (remain 3m 31s) Loss: 0.8430(0.7287) Grad: 238456.4844  LR: 0.00001855  \n","Epoch: [1][300/757] Elapsed 2m 11s (remain 3m 19s) Loss: 0.6211(0.7158) Grad: 387751.3750  LR: 0.00001987  \n","EVAL: [0/69] Loss: 0.8970(0.8970) \n","EVAL: [20/69] Loss: 0.6133(0.7030) \n","EVAL: [40/69] Loss: 0.5894(0.6819) \n","EVAL: [60/69] Loss: 0.5718(0.6787) \n","EVAL: [68/69] Loss: 0.9572(0.6891) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.7048 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7048 Model\n","Epoch 1 - avg_train_loss: 0.7158  avg_val_loss: 0.6891\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.7158  avg_val_loss: 0.6891\n","Epoch 1 - Score: 0.7048  Scores: [0.5332546108952564, 0.8763199725511567]\n","INFO:__main__:Epoch 1 - Score: 0.7048  Scores: [0.5332546108952564, 0.8763199725511567]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][320/757] Elapsed 2m 43s (remain 3m 42s) Loss: 0.4216(0.7030) Grad: 397181.9062  LR: 0.00002000  \n","Epoch: [1][340/757] Elapsed 2m 51s (remain 3m 29s) Loss: 1.0218(0.6956) Grad: 411840.2188  LR: 0.00001999  \n","Epoch: [1][360/757] Elapsed 2m 58s (remain 3m 15s) Loss: 0.4491(0.6886) Grad: 186960.3281  LR: 0.00001998  \n","Epoch: [1][380/757] Elapsed 3m 5s (remain 3m 2s) Loss: 0.5659(0.6791) Grad: 234192.1250  LR: 0.00001996  \n","Epoch: [1][400/757] Elapsed 3m 11s (remain 2m 50s) Loss: 0.4269(0.6712) Grad: 48446.5938  LR: 0.00001994  \n","Epoch: [1][420/757] Elapsed 3m 18s (remain 2m 38s) Loss: 0.5390(0.6647) Grad: 152273.2031  LR: 0.00001991  \n","Epoch: [1][440/757] Elapsed 3m 24s (remain 2m 26s) Loss: 0.5173(0.6584) Grad: 124573.8828  LR: 0.00001987  \n","EVAL: [0/69] Loss: 0.9203(0.9203) \n","EVAL: [20/69] Loss: 0.6490(0.7187) \n","EVAL: [40/69] Loss: 0.6612(0.6980) \n","EVAL: [60/69] Loss: 0.5700(0.6927) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6559  avg_val_loss: 0.6995\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6559  avg_val_loss: 0.6995\n","Epoch 1 - Score: 0.7150  Scores: [0.557217551190583, 0.8727893331819139]\n","INFO:__main__:Epoch 1 - Score: 0.7150  Scores: [0.557217551190583, 0.8727893331819139]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.9315(0.6995) \n","Epoch: [1][460/757] Elapsed 3m 49s (remain 2m 27s) Loss: 0.4435(0.6528) Grad: 95535.1875  LR: 0.00001983  \n","Epoch: [1][480/757] Elapsed 3m 56s (remain 2m 15s) Loss: 0.5903(0.6494) Grad: 67998.7266  LR: 0.00001979  \n","Epoch: [1][500/757] Elapsed 4m 1s (remain 2m 3s) Loss: 0.4139(0.6419) Grad: 137358.8438  LR: 0.00001974  \n","Epoch: [1][520/757] Elapsed 4m 6s (remain 1m 51s) Loss: 0.3883(0.6375) Grad: 45082.9336  LR: 0.00001969  \n","Epoch: [1][540/757] Elapsed 4m 13s (remain 1m 41s) Loss: 0.4675(0.6333) Grad: 64361.7695  LR: 0.00001963  \n","Epoch: [1][560/757] Elapsed 4m 18s (remain 1m 30s) Loss: 0.5416(0.6297) Grad: 84999.8203  LR: 0.00001956  \n","Epoch: [1][580/757] Elapsed 4m 25s (remain 1m 20s) Loss: 0.3925(0.6233) Grad: 72841.7969  LR: 0.00001949  \n","Epoch: [1][600/757] Elapsed 4m 30s (remain 1m 10s) Loss: 0.4730(0.6173) Grad: 42709.4922  LR: 0.00001942  \n","EVAL: [0/69] Loss: 0.8978(0.8978) \n","EVAL: [20/69] Loss: 0.6306(0.7256) \n","EVAL: [40/69] Loss: 0.6586(0.6986) \n","EVAL: [60/69] Loss: 0.5491(0.6954) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6173  avg_val_loss: 0.7053\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6173  avg_val_loss: 0.7053\n","Epoch 1 - Score: 0.7223  Scores: [0.657672807866929, 0.786906371699982]\n","INFO:__main__:Epoch 1 - Score: 0.7223  Scores: [0.657672807866929, 0.786906371699982]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.9778(0.7053) \n","Epoch: [1][620/757] Elapsed 4m 55s (remain 1m 4s) Loss: 0.6993(0.6131) Grad: 112384.2734  LR: 0.00001934  \n","Epoch: [1][640/757] Elapsed 5m 1s (remain 0m 54s) Loss: 0.4373(0.6112) Grad: 66444.7656  LR: 0.00001925  \n","Epoch: [1][660/757] Elapsed 5m 6s (remain 0m 44s) Loss: 0.4395(0.6074) Grad: 64340.5312  LR: 0.00001916  \n","Epoch: [1][680/757] Elapsed 5m 12s (remain 0m 34s) Loss: 0.4791(0.6034) Grad: 71523.1406  LR: 0.00001907  \n","Epoch: [1][700/757] Elapsed 5m 18s (remain 0m 25s) Loss: 0.4242(0.6002) Grad: 57264.7500  LR: 0.00001897  \n","Epoch: [1][720/757] Elapsed 5m 23s (remain 0m 16s) Loss: 0.2573(0.5973) Grad: 46940.9297  LR: 0.00001886  \n","Epoch: [1][740/757] Elapsed 5m 29s (remain 0m 7s) Loss: 0.5277(0.5950) Grad: 153766.0625  LR: 0.00001875  \n","EVAL: [0/69] Loss: 0.8735(0.8735) \n","EVAL: [20/69] Loss: 0.5162(0.6261) \n","EVAL: [40/69] Loss: 0.5701(0.6049) \n","EVAL: [60/69] Loss: 0.5013(0.6058) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.6315 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6315 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8068(0.6156) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.5936  avg_val_loss: 0.6156\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5936  avg_val_loss: 0.6156\n","Epoch 1 - Score: 0.6315  Scores: [0.5526865118427391, 0.7103367321414578]\n","INFO:__main__:Epoch 1 - Score: 0.6315  Scores: [0.5526865118427391, 0.7103367321414578]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][756/757] Elapsed 6m 0s (remain 0m 0s) Loss: 0.5058(0.5930) Grad: 126659.8203  LR: 0.00001866  \n","EVAL: [0/69] Loss: 0.8573(0.8573) \n","EVAL: [20/69] Loss: 0.4841(0.5885) \n","EVAL: [40/69] Loss: 0.5443(0.5690) \n","EVAL: [60/69] Loss: 0.4686(0.5698) \n","EVAL: [68/69] Loss: 0.7782(0.5788) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.5969 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5969 Model\n","Epoch 1 - avg_train_loss: 0.5930  avg_val_loss: 0.5788\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.5930  avg_val_loss: 0.5788\n","Epoch 1 - Score: 0.5969  Scores: [0.49988321645878453, 0.6938940400432257]\n","INFO:__main__:Epoch 1 - Score: 0.5969  Scores: [0.49988321645878453, 0.6938940400432257]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/757] Elapsed 0m 0s (remain 6m 27s) Loss: 0.5168(0.5168) Grad: 252402.4062  LR: 0.00001866  \n","Epoch: [2][20/757] Elapsed 0m 6s (remain 3m 33s) Loss: 0.7902(0.4990) Grad: 218653.1250  LR: 0.00001854  \n","Epoch: [2][40/757] Elapsed 0m 12s (remain 3m 38s) Loss: 0.2702(0.4841) Grad: 109572.5312  LR: 0.00001842  \n","Epoch: [2][60/757] Elapsed 0m 18s (remain 3m 31s) Loss: 0.6805(0.4807) Grad: 145643.5469  LR: 0.00001829  \n","Epoch: [2][80/757] Elapsed 0m 27s (remain 3m 49s) Loss: 0.4192(0.4792) Grad: 156166.3906  LR: 0.00001816  \n","Epoch: [2][100/757] Elapsed 0m 34s (remain 3m 43s) Loss: 0.5348(0.4720) Grad: 107061.0859  LR: 0.00001803  \n","Epoch: [2][120/757] Elapsed 0m 41s (remain 3m 39s) Loss: 0.3716(0.4717) Grad: 138717.3281  LR: 0.00001789  \n","Epoch: [2][140/757] Elapsed 0m 47s (remain 3m 27s) Loss: 0.5357(0.4679) Grad: 246114.0000  LR: 0.00001774  \n","EVAL: [0/69] Loss: 0.8977(0.8977) \n","EVAL: [20/69] Loss: 0.6353(0.7435) \n","EVAL: [40/69] Loss: 0.7180(0.7139) \n","EVAL: [60/69] Loss: 0.6100(0.7160) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4693  avg_val_loss: 0.7276\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4693  avg_val_loss: 0.7276\n","Epoch 2 - Score: 0.7447  Scores: [0.6509311623050532, 0.8384382097800415]\n","INFO:__main__:Epoch 2 - Score: 0.7447  Scores: [0.6509311623050532, 0.8384382097800415]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 1.0272(0.7276) \n","Epoch: [2][160/757] Elapsed 1m 12s (remain 4m 26s) Loss: 0.4273(0.4681) Grad: 185303.0312  LR: 0.00001760  \n","Epoch: [2][180/757] Elapsed 1m 17s (remain 4m 7s) Loss: 0.3382(0.4642) Grad: 84453.6953  LR: 0.00001744  \n","Epoch: [2][200/757] Elapsed 1m 22s (remain 3m 49s) Loss: 0.4029(0.4606) Grad: 156454.4062  LR: 0.00001729  \n","Epoch: [2][220/757] Elapsed 1m 28s (remain 3m 35s) Loss: 0.4611(0.4585) Grad: 127112.4766  LR: 0.00001713  \n","Epoch: [2][240/757] Elapsed 1m 35s (remain 3m 24s) Loss: 0.5075(0.4595) Grad: 159133.7188  LR: 0.00001696  \n","Epoch: [2][260/757] Elapsed 1m 40s (remain 3m 11s) Loss: 0.4472(0.4582) Grad: 177394.1719  LR: 0.00001680  \n","Epoch: [2][280/757] Elapsed 1m 47s (remain 3m 1s) Loss: 0.5129(0.4577) Grad: 200536.4219  LR: 0.00001663  \n","Epoch: [2][300/757] Elapsed 1m 52s (remain 2m 50s) Loss: 0.4704(0.4554) Grad: 121457.0547  LR: 0.00001645  \n","EVAL: [0/69] Loss: 0.8437(0.8437) \n","EVAL: [20/69] Loss: 0.5372(0.6563) \n","EVAL: [40/69] Loss: 0.6367(0.6271) \n","EVAL: [60/69] Loss: 0.5300(0.6286) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4554  avg_val_loss: 0.6400\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4554  avg_val_loss: 0.6400\n","Epoch 2 - Score: 0.6566  Scores: [0.6007101621551143, 0.7125052335895963]\n","INFO:__main__:Epoch 2 - Score: 0.6566  Scores: [0.6007101621551143, 0.7125052335895963]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8967(0.6400) \n","Epoch: [2][320/757] Elapsed 2m 18s (remain 3m 8s) Loss: 0.4078(0.4571) Grad: 127105.8203  LR: 0.00001627  \n","Epoch: [2][340/757] Elapsed 2m 24s (remain 2m 56s) Loss: 0.3483(0.4540) Grad: 100574.4375  LR: 0.00001609  \n","Epoch: [2][360/757] Elapsed 2m 30s (remain 2m 44s) Loss: 0.3291(0.4520) Grad: 148442.5469  LR: 0.00001591  \n","Epoch: [2][380/757] Elapsed 2m 36s (remain 2m 34s) Loss: 0.4409(0.4532) Grad: 182757.1406  LR: 0.00001572  \n","Epoch: [2][400/757] Elapsed 2m 41s (remain 2m 23s) Loss: 0.3983(0.4515) Grad: 100152.1250  LR: 0.00001553  \n","Epoch: [2][420/757] Elapsed 2m 47s (remain 2m 13s) Loss: 0.5747(0.4514) Grad: 238634.9062  LR: 0.00001534  \n","Epoch: [2][440/757] Elapsed 2m 53s (remain 2m 4s) Loss: 0.5018(0.4508) Grad: 153275.0156  LR: 0.00001514  \n","EVAL: [0/69] Loss: 0.8902(0.8902) \n","EVAL: [20/69] Loss: 0.5203(0.6302) \n","EVAL: [40/69] Loss: 0.5615(0.6007) \n","EVAL: [60/69] Loss: 0.4478(0.5996) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4511  avg_val_loss: 0.6067\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4511  avg_val_loss: 0.6067\n","Epoch 2 - Score: 0.6260  Scores: [0.5321503569386071, 0.7197927748846576]\n","INFO:__main__:Epoch 2 - Score: 0.6260  Scores: [0.5321503569386071, 0.7197927748846576]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8251(0.6067) \n","Epoch: [2][460/757] Elapsed 3m 18s (remain 2m 7s) Loss: 0.6044(0.4515) Grad: 165401.6094  LR: 0.00001494  \n","Epoch: [2][480/757] Elapsed 3m 24s (remain 1m 57s) Loss: 0.6539(0.4521) Grad: 234470.4688  LR: 0.00001474  \n","Epoch: [2][500/757] Elapsed 3m 29s (remain 1m 47s) Loss: 0.3905(0.4520) Grad: 137631.3906  LR: 0.00001454  \n","Epoch: [2][520/757] Elapsed 3m 34s (remain 1m 37s) Loss: 0.3380(0.4496) Grad: 153667.1250  LR: 0.00001433  \n","Epoch: [2][540/757] Elapsed 3m 40s (remain 1m 28s) Loss: 0.5073(0.4501) Grad: 201833.6406  LR: 0.00001412  \n","Epoch: [2][560/757] Elapsed 3m 46s (remain 1m 19s) Loss: 0.5699(0.4492) Grad: 143436.4688  LR: 0.00001391  \n","Epoch: [2][580/757] Elapsed 3m 51s (remain 1m 10s) Loss: 0.2996(0.4488) Grad: 92488.0078  LR: 0.00001370  \n","Epoch: [2][600/757] Elapsed 3m 57s (remain 1m 1s) Loss: 0.5210(0.4478) Grad: 124086.3281  LR: 0.00001348  \n","EVAL: [0/69] Loss: 0.8667(0.8667) \n","EVAL: [20/69] Loss: 0.5532(0.6348) \n","EVAL: [40/69] Loss: 0.6033(0.6108) \n","EVAL: [60/69] Loss: 0.4567(0.6073) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4478  avg_val_loss: 0.6155\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4478  avg_val_loss: 0.6155\n","Epoch 2 - Score: 0.6331  Scores: [0.52738674741329, 0.7387341434565343]\n","INFO:__main__:Epoch 2 - Score: 0.6331  Scores: [0.52738674741329, 0.7387341434565343]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8427(0.6155) \n","Epoch: [2][620/757] Elapsed 4m 24s (remain 0m 57s) Loss: 0.3002(0.4472) Grad: 97043.0703  LR: 0.00001327  \n","Epoch: [2][640/757] Elapsed 4m 30s (remain 0m 48s) Loss: 0.3871(0.4472) Grad: 114645.1172  LR: 0.00001305  \n","Epoch: [2][660/757] Elapsed 4m 35s (remain 0m 40s) Loss: 0.6687(0.4480) Grad: 148150.3438  LR: 0.00001283  \n","Epoch: [2][680/757] Elapsed 4m 41s (remain 0m 31s) Loss: 0.4918(0.4475) Grad: 126665.8125  LR: 0.00001261  \n","Epoch: [2][700/757] Elapsed 4m 47s (remain 0m 22s) Loss: 0.4502(0.4467) Grad: 87920.9531  LR: 0.00001238  \n","Epoch: [2][720/757] Elapsed 4m 52s (remain 0m 14s) Loss: 0.3317(0.4458) Grad: 87959.8750  LR: 0.00001216  \n","Epoch: [2][740/757] Elapsed 4m 57s (remain 0m 6s) Loss: 0.4132(0.4452) Grad: 293203.0938  LR: 0.00001193  \n","EVAL: [0/69] Loss: 0.8524(0.8524) \n","EVAL: [20/69] Loss: 0.4303(0.5670) \n","EVAL: [40/69] Loss: 0.5525(0.5452) \n","EVAL: [60/69] Loss: 0.4466(0.5476) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Save Best Score: 0.5735 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5735 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.7247(0.5543) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4454  avg_val_loss: 0.5543\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4454  avg_val_loss: 0.5543\n","Epoch 2 - Score: 0.5735  Scores: [0.48149582321810896, 0.665427150938156]\n","INFO:__main__:Epoch 2 - Score: 0.5735  Scores: [0.48149582321810896, 0.665427150938156]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][756/757] Elapsed 5m 30s (remain 0m 0s) Loss: 0.4215(0.4456) Grad: 113171.6719  LR: 0.00001175  \n","EVAL: [0/69] Loss: 0.8515(0.8515) \n","EVAL: [20/69] Loss: 0.4767(0.6024) \n","EVAL: [40/69] Loss: 0.5963(0.5787) \n","EVAL: [60/69] Loss: 0.4679(0.5801) \n","EVAL: [68/69] Loss: 0.8038(0.5880) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4456  avg_val_loss: 0.5880\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4456  avg_val_loss: 0.5880\n","Epoch 2 - Score: 0.6065  Scores: [0.5433626891665906, 0.6697079869767975]\n","INFO:__main__:Epoch 2 - Score: 0.6065  Scores: [0.5433626891665906, 0.6697079869767975]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/757] Elapsed 0m 0s (remain 10m 58s) Loss: 0.5786(0.5786) Grad: 339134.4375  LR: 0.00001174  \n","Epoch: [3][20/757] Elapsed 0m 6s (remain 3m 52s) Loss: 0.2466(0.3940) Grad: 172336.0000  LR: 0.00001151  \n","Epoch: [3][40/757] Elapsed 0m 12s (remain 3m 44s) Loss: 0.3134(0.4042) Grad: 109751.8672  LR: 0.00001129  \n","Epoch: [3][60/757] Elapsed 0m 19s (remain 3m 41s) Loss: 0.2735(0.4073) Grad: 79562.0938  LR: 0.00001106  \n","Epoch: [3][80/757] Elapsed 0m 25s (remain 3m 29s) Loss: 0.4766(0.3992) Grad: 150773.6875  LR: 0.00001083  \n","Epoch: [3][100/757] Elapsed 0m 31s (remain 3m 22s) Loss: 0.4796(0.4014) Grad: 151170.9531  LR: 0.00001060  \n","Epoch: [3][120/757] Elapsed 0m 37s (remain 3m 16s) Loss: 0.3967(0.4000) Grad: 135905.3438  LR: 0.00001037  \n","Epoch: [3][140/757] Elapsed 0m 44s (remain 3m 15s) Loss: 0.6618(0.3993) Grad: 412600.9375  LR: 0.00001014  \n","EVAL: [0/69] Loss: 0.8352(0.8352) \n","EVAL: [20/69] Loss: 0.5002(0.6103) \n","EVAL: [40/69] Loss: 0.5807(0.5909) \n","EVAL: [60/69] Loss: 0.4572(0.5908) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3973  avg_val_loss: 0.5995\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3973  avg_val_loss: 0.5995\n","Epoch 3 - Score: 0.6177  Scores: [0.5486011501720685, 0.6867976726337676]\n","INFO:__main__:Epoch 3 - Score: 0.6177  Scores: [0.5486011501720685, 0.6867976726337676]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8161(0.5995) \n","Epoch: [3][160/757] Elapsed 1m 9s (remain 4m 18s) Loss: 0.5755(0.3980) Grad: 129712.7188  LR: 0.00000991  \n","Epoch: [3][180/757] Elapsed 1m 15s (remain 3m 59s) Loss: 0.4653(0.3967) Grad: 474109.5938  LR: 0.00000968  \n","Epoch: [3][200/757] Elapsed 1m 21s (remain 3m 45s) Loss: 0.3906(0.3941) Grad: 173653.3594  LR: 0.00000945  \n","Epoch: [3][220/757] Elapsed 1m 26s (remain 3m 30s) Loss: 0.3747(0.3920) Grad: 149967.1562  LR: 0.00000922  \n","Epoch: [3][240/757] Elapsed 1m 32s (remain 3m 17s) Loss: 0.2871(0.3898) Grad: 194153.4062  LR: 0.00000899  \n","Epoch: [3][260/757] Elapsed 1m 38s (remain 3m 7s) Loss: 0.4090(0.3879) Grad: 184306.6719  LR: 0.00000876  \n","Epoch: [3][280/757] Elapsed 1m 44s (remain 2m 57s) Loss: 0.4058(0.3858) Grad: 241695.6094  LR: 0.00000853  \n","Epoch: [3][300/757] Elapsed 1m 51s (remain 2m 48s) Loss: 0.4964(0.3876) Grad: 176862.4688  LR: 0.00000830  \n","EVAL: [0/69] Loss: 0.8736(0.8736) \n","EVAL: [20/69] Loss: 0.5573(0.6509) \n","EVAL: [40/69] Loss: 0.6280(0.6263) \n","EVAL: [60/69] Loss: 0.4869(0.6254) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3876  avg_val_loss: 0.6353\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3876  avg_val_loss: 0.6353\n","Epoch 3 - Score: 0.6534  Scores: [0.5925759252795179, 0.7142130073101776]\n","INFO:__main__:Epoch 3 - Score: 0.6534  Scores: [0.5925759252795179, 0.7142130073101776]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8800(0.6353) \n","Epoch: [3][320/757] Elapsed 2m 15s (remain 3m 3s) Loss: 0.2408(0.3878) Grad: 113969.5547  LR: 0.00000808  \n","Epoch: [3][340/757] Elapsed 2m 20s (remain 2m 51s) Loss: 0.2583(0.3851) Grad: 170670.9375  LR: 0.00000785  \n","Epoch: [3][360/757] Elapsed 2m 26s (remain 2m 41s) Loss: 0.4507(0.3864) Grad: 117525.0547  LR: 0.00000763  \n","Epoch: [3][380/757] Elapsed 2m 32s (remain 2m 30s) Loss: 0.5017(0.3882) Grad: 200107.5625  LR: 0.00000740  \n","Epoch: [3][400/757] Elapsed 2m 37s (remain 2m 20s) Loss: 0.2290(0.3872) Grad: 138535.7812  LR: 0.00000718  \n","Epoch: [3][420/757] Elapsed 2m 43s (remain 2m 10s) Loss: 0.5199(0.3861) Grad: 123822.4688  LR: 0.00000696  \n","Epoch: [3][440/757] Elapsed 2m 48s (remain 2m 0s) Loss: 0.3246(0.3853) Grad: 156654.2031  LR: 0.00000674  \n","EVAL: [0/69] Loss: 0.8646(0.8646) \n","EVAL: [20/69] Loss: 0.5065(0.6199) \n","EVAL: [40/69] Loss: 0.6078(0.5945) \n","EVAL: [60/69] Loss: 0.4763(0.5968) \n","EVAL: [68/69] Loss: 0.8149(0.6059) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3849  avg_val_loss: 0.6059\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3849  avg_val_loss: 0.6059\n","Epoch 3 - Score: 0.6250  Scores: [0.5817075410654944, 0.6682111679234529]\n","INFO:__main__:Epoch 3 - Score: 0.6250  Scores: [0.5817075410654944, 0.6682111679234529]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][460/757] Elapsed 3m 14s (remain 2m 4s) Loss: 0.3956(0.3844) Grad: 105348.7656  LR: 0.00000653  \n","Epoch: [3][480/757] Elapsed 3m 20s (remain 1m 54s) Loss: 0.4242(0.3837) Grad: 154085.8125  LR: 0.00000631  \n","Epoch: [3][500/757] Elapsed 3m 25s (remain 1m 45s) Loss: 0.3580(0.3823) Grad: 128526.1172  LR: 0.00000610  \n","Epoch: [3][520/757] Elapsed 3m 31s (remain 1m 35s) Loss: 0.4069(0.3810) Grad: 157958.9688  LR: 0.00000589  \n","Epoch: [3][540/757] Elapsed 3m 36s (remain 1m 26s) Loss: 0.2831(0.3804) Grad: 144651.5938  LR: 0.00000568  \n","Epoch: [3][560/757] Elapsed 3m 42s (remain 1m 17s) Loss: 0.2990(0.3802) Grad: 151354.7031  LR: 0.00000547  \n","Epoch: [3][580/757] Elapsed 3m 48s (remain 1m 9s) Loss: 0.4997(0.3802) Grad: 162887.8750  LR: 0.00000527  \n","Epoch: [3][600/757] Elapsed 3m 53s (remain 1m 0s) Loss: 0.4555(0.3808) Grad: 166189.7656  LR: 0.00000507  \n","EVAL: [0/69] Loss: 0.8854(0.8854) \n","EVAL: [20/69] Loss: 0.5386(0.6525) \n","EVAL: [40/69] Loss: 0.6387(0.6233) \n","EVAL: [60/69] Loss: 0.5105(0.6252) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3808  avg_val_loss: 0.6354\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3808  avg_val_loss: 0.6354\n","Epoch 3 - Score: 0.6543  Scores: [0.6230523658492573, 0.6854740534541637]\n","INFO:__main__:Epoch 3 - Score: 0.6543  Scores: [0.6230523658492573, 0.6854740534541637]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8807(0.6354) \n","Epoch: [3][620/757] Elapsed 4m 18s (remain 0m 56s) Loss: 0.2325(0.3805) Grad: 183335.2031  LR: 0.00000487  \n","Epoch: [3][640/757] Elapsed 4m 23s (remain 0m 47s) Loss: 0.4265(0.3792) Grad: 169185.0781  LR: 0.00000467  \n","Epoch: [3][660/757] Elapsed 4m 30s (remain 0m 39s) Loss: 0.3994(0.3781) Grad: 136020.7344  LR: 0.00000448  \n","Epoch: [3][680/757] Elapsed 4m 36s (remain 0m 30s) Loss: 0.1988(0.3777) Grad: 189989.2500  LR: 0.00000429  \n","Epoch: [3][700/757] Elapsed 4m 41s (remain 0m 22s) Loss: 0.4531(0.3769) Grad: 153663.7188  LR: 0.00000410  \n","Epoch: [3][720/757] Elapsed 4m 47s (remain 0m 14s) Loss: 0.4405(0.3763) Grad: 178934.9844  LR: 0.00000392  \n","Epoch: [3][740/757] Elapsed 4m 54s (remain 0m 6s) Loss: 0.5770(0.3760) Grad: 145105.5312  LR: 0.00000373  \n","EVAL: [0/69] Loss: 0.8693(0.8693) \n","EVAL: [20/69] Loss: 0.4964(0.6147) \n","EVAL: [40/69] Loss: 0.6034(0.5854) \n","EVAL: [60/69] Loss: 0.4845(0.5894) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3762  avg_val_loss: 0.5990\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3762  avg_val_loss: 0.5990\n","Epoch 3 - Score: 0.6183  Scores: [0.5756407668369824, 0.6609564631348109]\n","INFO:__main__:Epoch 3 - Score: 0.6183  Scores: [0.5756407668369824, 0.6609564631348109]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8173(0.5990) \n","Epoch: [3][756/757] Elapsed 5m 17s (remain 0m 0s) Loss: 0.4010(0.3761) Grad: 109989.9297  LR: 0.00000359  \n","EVAL: [0/69] Loss: 0.8705(0.8705) \n","EVAL: [20/69] Loss: 0.4883(0.6068) \n","EVAL: [40/69] Loss: 0.5950(0.5777) \n","EVAL: [60/69] Loss: 0.4839(0.5825) \n","EVAL: [68/69] Loss: 0.7991(0.5916) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3761  avg_val_loss: 0.5916\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3761  avg_val_loss: 0.5916\n","Epoch 3 - Score: 0.6111  Scores: [0.5663952180658962, 0.6557326096125788]\n","INFO:__main__:Epoch 3 - Score: 0.6111  Scores: [0.5663952180658962, 0.6557326096125788]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/757] Elapsed 0m 0s (remain 9m 32s) Loss: 0.2129(0.2129) Grad: 247868.8281  LR: 0.00000358  \n","Epoch: [4][20/757] Elapsed 0m 6s (remain 3m 50s) Loss: 0.2966(0.3191) Grad: 126021.3906  LR: 0.00000341  \n","Epoch: [4][40/757] Elapsed 0m 11s (remain 3m 29s) Loss: 0.3091(0.3124) Grad: 167833.4219  LR: 0.00000324  \n","Epoch: [4][60/757] Elapsed 0m 17s (remain 3m 21s) Loss: 0.2387(0.3115) Grad: 113496.2109  LR: 0.00000307  \n","Epoch: [4][80/757] Elapsed 0m 23s (remain 3m 20s) Loss: 0.2322(0.3145) Grad: 135509.0625  LR: 0.00000290  \n","Epoch: [4][100/757] Elapsed 0m 28s (remain 3m 8s) Loss: 0.4040(0.3169) Grad: 127746.9297  LR: 0.00000274  \n","Epoch: [4][120/757] Elapsed 0m 35s (remain 3m 4s) Loss: 0.3910(0.3196) Grad: 127493.5078  LR: 0.00000259  \n","Epoch: [4][140/757] Elapsed 0m 40s (remain 2m 57s) Loss: 0.1775(0.3222) Grad: 111982.0156  LR: 0.00000243  \n","EVAL: [0/69] Loss: 0.8802(0.8802) \n","EVAL: [20/69] Loss: 0.5212(0.6383) \n","EVAL: [40/69] Loss: 0.6342(0.6078) \n","EVAL: [60/69] Loss: 0.5052(0.6121) \n","EVAL: [68/69] Loss: 0.8545(0.6223) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3217  avg_val_loss: 0.6223\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3217  avg_val_loss: 0.6223\n","Epoch 4 - Score: 0.6416  Scores: [0.611837781000285, 0.6714403949999157]\n","INFO:__main__:Epoch 4 - Score: 0.6416  Scores: [0.611837781000285, 0.6714403949999157]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][160/757] Elapsed 1m 6s (remain 4m 6s) Loss: 0.4825(0.3231) Grad: 656421.0625  LR: 0.00000229  \n","Epoch: [4][180/757] Elapsed 1m 12s (remain 3m 50s) Loss: 0.4013(0.3226) Grad: 199242.2344  LR: 0.00000214  \n","Epoch: [4][200/757] Elapsed 1m 18s (remain 3m 36s) Loss: 0.3052(0.3219) Grad: 147404.0781  LR: 0.00000200  \n","Epoch: [4][220/757] Elapsed 1m 24s (remain 3m 24s) Loss: 0.2941(0.3196) Grad: 125048.2812  LR: 0.00000187  \n","Epoch: [4][240/757] Elapsed 1m 29s (remain 3m 10s) Loss: 0.3679(0.3174) Grad: 146572.4531  LR: 0.00000173  \n","Epoch: [4][260/757] Elapsed 1m 35s (remain 3m 0s) Loss: 0.2815(0.3176) Grad: 185021.3281  LR: 0.00000161  \n","Epoch: [4][280/757] Elapsed 1m 41s (remain 2m 51s) Loss: 0.3473(0.3174) Grad: 122989.6641  LR: 0.00000148  \n","Epoch: [4][300/757] Elapsed 1m 46s (remain 2m 41s) Loss: 0.3238(0.3153) Grad: 164093.4531  LR: 0.00000136  \n","EVAL: [0/69] Loss: 0.8608(0.8608) \n","EVAL: [20/69] Loss: 0.4965(0.6124) \n","EVAL: [40/69] Loss: 0.6034(0.5836) \n","EVAL: [60/69] Loss: 0.4676(0.5873) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3153  avg_val_loss: 0.5978\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3153  avg_val_loss: 0.5978\n","Epoch 4 - Score: 0.6174  Scores: [0.5681581826828506, 0.6667076324511186]\n","INFO:__main__:Epoch 4 - Score: 0.6174  Scores: [0.5681581826828506, 0.6667076324511186]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8293(0.5978) \n","Epoch: [4][320/757] Elapsed 2m 11s (remain 2m 59s) Loss: 0.2555(0.3139) Grad: 149636.2500  LR: 0.00000125  \n","Epoch: [4][340/757] Elapsed 2m 17s (remain 2m 47s) Loss: 0.2657(0.3130) Grad: 152974.7500  LR: 0.00000114  \n","Epoch: [4][360/757] Elapsed 2m 22s (remain 2m 36s) Loss: 0.4055(0.3115) Grad: 357484.6875  LR: 0.00000104  \n","Epoch: [4][380/757] Elapsed 2m 28s (remain 2m 26s) Loss: 0.3296(0.3137) Grad: 174717.3594  LR: 0.00000094  \n","Epoch: [4][400/757] Elapsed 2m 33s (remain 2m 16s) Loss: 0.5152(0.3138) Grad: 262084.8750  LR: 0.00000084  \n","Epoch: [4][420/757] Elapsed 2m 39s (remain 2m 7s) Loss: 0.3570(0.3150) Grad: 166546.8750  LR: 0.00000075  \n","Epoch: [4][440/757] Elapsed 2m 45s (remain 1m 58s) Loss: 0.3233(0.3163) Grad: 142850.5312  LR: 0.00000067  \n","EVAL: [0/69] Loss: 0.8667(0.8667) \n","EVAL: [20/69] Loss: 0.5056(0.6159) \n","EVAL: [40/69] Loss: 0.6061(0.5866) \n","EVAL: [60/69] Loss: 0.4768(0.5905) \n","EVAL: [68/69] Loss: 0.8242(0.6006) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3156  avg_val_loss: 0.6006\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3156  avg_val_loss: 0.6006\n","Epoch 4 - Score: 0.6200  Scores: [0.5805037609241446, 0.6595112559119941]\n","INFO:__main__:Epoch 4 - Score: 0.6200  Scores: [0.5805037609241446, 0.6595112559119941]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][460/757] Elapsed 3m 12s (remain 2m 3s) Loss: 0.2534(0.3164) Grad: 154021.9375  LR: 0.00000059  \n","Epoch: [4][480/757] Elapsed 3m 18s (remain 1m 53s) Loss: 0.3260(0.3172) Grad: 168818.4531  LR: 0.00000051  \n","Epoch: [4][500/757] Elapsed 3m 23s (remain 1m 43s) Loss: 0.4190(0.3180) Grad: 231219.3594  LR: 0.00000044  \n","Epoch: [4][520/757] Elapsed 3m 28s (remain 1m 34s) Loss: 0.3746(0.3183) Grad: 152433.1406  LR: 0.00000038  \n","Epoch: [4][540/757] Elapsed 3m 34s (remain 1m 25s) Loss: 0.3192(0.3182) Grad: 123543.2578  LR: 0.00000032  \n","Epoch: [4][560/757] Elapsed 3m 39s (remain 1m 16s) Loss: 0.3071(0.3184) Grad: 194678.6250  LR: 0.00000026  \n","Epoch: [4][580/757] Elapsed 3m 45s (remain 1m 8s) Loss: 0.4569(0.3172) Grad: 209729.5312  LR: 0.00000021  \n","Epoch: [4][600/757] Elapsed 3m 50s (remain 0m 59s) Loss: 0.2223(0.3161) Grad: 167224.8594  LR: 0.00000017  \n","EVAL: [0/69] Loss: 0.8678(0.8678) \n","EVAL: [20/69] Loss: 0.5015(0.6095) \n","EVAL: [40/69] Loss: 0.5960(0.5805) \n","EVAL: [60/69] Loss: 0.4738(0.5849) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3161  avg_val_loss: 0.5946\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3161  avg_val_loss: 0.5946\n","Epoch 4 - Score: 0.6142  Scores: [0.5718562468382759, 0.6565676950234491]\n","INFO:__main__:Epoch 4 - Score: 0.6142  Scores: [0.5718562468382759, 0.6565676950234491]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8109(0.5946) \n","Epoch: [4][620/757] Elapsed 4m 16s (remain 0m 56s) Loss: 0.3904(0.3168) Grad: 155934.4531  LR: 0.00000013  \n","Epoch: [4][640/757] Elapsed 4m 22s (remain 0m 47s) Loss: 0.3869(0.3166) Grad: 145376.3906  LR: 0.00000009  \n","Epoch: [4][660/757] Elapsed 4m 27s (remain 0m 38s) Loss: 0.2782(0.3174) Grad: 130140.5078  LR: 0.00000006  \n","Epoch: [4][680/757] Elapsed 4m 33s (remain 0m 30s) Loss: 0.3283(0.3177) Grad: 268085.9062  LR: 0.00000004  \n","Epoch: [4][700/757] Elapsed 4m 39s (remain 0m 22s) Loss: 0.1847(0.3175) Grad: 101461.4453  LR: 0.00000002  \n","Epoch: [4][720/757] Elapsed 4m 44s (remain 0m 14s) Loss: 0.3006(0.3178) Grad: 145512.4688  LR: 0.00000001  \n","Epoch: [4][740/757] Elapsed 4m 50s (remain 0m 6s) Loss: 0.2712(0.3164) Grad: 144805.3281  LR: 0.00000000  \n","EVAL: [0/69] Loss: 0.8657(0.8657) \n","EVAL: [20/69] Loss: 0.4966(0.6061) \n","EVAL: [40/69] Loss: 0.5928(0.5772) \n","EVAL: [60/69] Loss: 0.4714(0.5817) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3161  avg_val_loss: 0.5914\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3161  avg_val_loss: 0.5914\n","Epoch 4 - Score: 0.6111  Scores: [0.5669719201489786, 0.6551370311846765]\n","INFO:__main__:Epoch 4 - Score: 0.6111  Scores: [0.5669719201489786, 0.6551370311846765]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8060(0.5914) \n","Epoch: [4][756/757] Elapsed 5m 14s (remain 0m 0s) Loss: 0.3663(0.3159) Grad: 270550.5938  LR: 0.00000000  \n","EVAL: [0/69] Loss: 0.8657(0.8657) \n","EVAL: [20/69] Loss: 0.4966(0.6061) \n","EVAL: [40/69] Loss: 0.5928(0.5772) \n","EVAL: [60/69] Loss: 0.4714(0.5817) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3159  avg_val_loss: 0.5914\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3159  avg_val_loss: 0.5914\n","Epoch 4 - Score: 0.6111  Scores: [0.5669721989815152, 0.6551371839573391]\n","INFO:__main__:Epoch 4 - Score: 0.6111  Scores: [0.5669721989815152, 0.6551371839573391]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Loss: 0.8060(0.5914) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.5735  Scores: [0.48149582321810896, 0.665427150938156]\n","INFO:__main__:Score: 0.5735  Scores: [0.48149582321810896, 0.665427150938156]\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/638] Elapsed 0m 0s (remain 6m 9s) Loss: 0.6775(0.6775) Grad: 147021.8281  LR: 0.00000008  \n","Epoch: [1][20/638] Elapsed 0m 6s (remain 3m 18s) Loss: 0.9411(1.0478) Grad: 72253.2422  LR: 0.00000165  \n","Epoch: [1][40/638] Elapsed 0m 12s (remain 2m 58s) Loss: 1.1893(1.0262) Grad: 19641.7539  LR: 0.00000322  \n","Epoch: [1][60/638] Elapsed 0m 17s (remain 2m 43s) Loss: 1.2682(1.0201) Grad: 75572.5000  LR: 0.00000478  \n","Epoch: [1][80/638] Elapsed 0m 23s (remain 2m 38s) Loss: 0.9728(0.9785) Grad: 95628.6562  LR: 0.00000635  \n","Epoch: [1][100/638] Elapsed 0m 28s (remain 2m 33s) Loss: 0.5084(0.9385) Grad: 94973.8281  LR: 0.00000792  \n","Epoch: [1][120/638] Elapsed 0m 34s (remain 2m 25s) Loss: 0.7229(0.8997) Grad: 587409.1250  LR: 0.00000949  \n","Epoch: [1][140/638] Elapsed 0m 40s (remain 2m 21s) Loss: 0.5457(0.8647) Grad: 352663.9375  LR: 0.00001106  \n","EVAL: [0/129] Loss: 0.6024(0.6024) \n","EVAL: [20/129] Loss: 0.6840(0.7461) \n","EVAL: [40/129] Loss: 0.5859(0.7225) \n","EVAL: [60/129] Loss: 0.7697(0.7231) \n","EVAL: [80/129] Loss: 0.6726(0.7220) \n","EVAL: [100/129] Loss: 0.9351(0.7215) \n","EVAL: [120/129] Loss: 0.5924(0.7229) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.7371 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7371 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.6908(0.7238) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.8527  avg_val_loss: 0.7238\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.8527  avg_val_loss: 0.7238\n","Epoch 1 - Score: 0.7371  Scores: [0.6864722394306362, 0.7877491185828133]\n","INFO:__main__:Epoch 1 - Score: 0.7371  Scores: [0.6864722394306362, 0.7877491185828133]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][160/638] Elapsed 1m 27s (remain 4m 20s) Loss: 0.6406(0.8445) Grad: 242621.5781  LR: 0.00001263  \n","Epoch: [1][180/638] Elapsed 1m 33s (remain 3m 56s) Loss: 0.7017(0.8176) Grad: 302763.4062  LR: 0.00001420  \n","Epoch: [1][200/638] Elapsed 1m 40s (remain 3m 37s) Loss: 0.8017(0.7991) Grad: 110477.0781  LR: 0.00001576  \n","Epoch: [1][220/638] Elapsed 1m 47s (remain 3m 23s) Loss: 0.6986(0.7826) Grad: 233782.7969  LR: 0.00001733  \n","Epoch: [1][240/638] Elapsed 1m 53s (remain 3m 6s) Loss: 0.4189(0.7691) Grad: 145487.5625  LR: 0.00001890  \n","Epoch: [1][260/638] Elapsed 1m 59s (remain 2m 53s) Loss: 0.6130(0.7546) Grad: 516895.3125  LR: 0.00002000  \n","Epoch: [1][280/638] Elapsed 2m 8s (remain 2m 43s) Loss: 0.6912(0.7446) Grad: 247200.9219  LR: 0.00001999  \n","Epoch: [1][300/638] Elapsed 2m 13s (remain 2m 29s) Loss: 0.9458(0.7329) Grad: 229191.2188  LR: 0.00001998  \n","EVAL: [0/129] Loss: 0.5332(0.5332) \n","EVAL: [20/129] Loss: 0.5322(0.5756) \n","EVAL: [40/129] Loss: 0.4938(0.5580) \n","EVAL: [60/129] Loss: 0.6248(0.5679) \n","EVAL: [80/129] Loss: 0.5275(0.5604) \n","EVAL: [100/129] Loss: 0.7993(0.5604) \n","EVAL: [120/129] Loss: 0.5009(0.5605) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.5744 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5744 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.4902(0.5596) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.7329  avg_val_loss: 0.5596\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.7329  avg_val_loss: 0.5596\n","Epoch 1 - Score: 0.5744  Scores: [0.4936912689480149, 0.6550251393895062]\n","INFO:__main__:Epoch 1 - Score: 0.5744  Scores: [0.4936912689480149, 0.6550251393895062]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][320/638] Elapsed 3m 7s (remain 3m 5s) Loss: 0.7598(0.7241) Grad: 270268.2812  LR: 0.00001996  \n","Epoch: [1][340/638] Elapsed 3m 14s (remain 2m 49s) Loss: 0.6789(0.7161) Grad: 151466.8594  LR: 0.00001993  \n","Epoch: [1][360/638] Elapsed 3m 21s (remain 2m 34s) Loss: 0.6825(0.7053) Grad: 209933.7031  LR: 0.00001990  \n","Epoch: [1][380/638] Elapsed 3m 28s (remain 2m 20s) Loss: 0.4352(0.6978) Grad: 81251.7188  LR: 0.00001985  \n","Epoch: [1][400/638] Elapsed 3m 35s (remain 2m 7s) Loss: 0.6023(0.6913) Grad: 104986.4297  LR: 0.00001980  \n","Epoch: [1][420/638] Elapsed 3m 41s (remain 1m 54s) Loss: 0.3102(0.6844) Grad: 106813.9297  LR: 0.00001974  \n","Epoch: [1][440/638] Elapsed 3m 47s (remain 1m 41s) Loss: 0.5456(0.6786) Grad: 81691.2188  LR: 0.00001968  \n","EVAL: [0/129] Loss: 0.4139(0.4139) \n","EVAL: [20/129] Loss: 0.4502(0.5232) \n","EVAL: [40/129] Loss: 0.4906(0.5197) \n","EVAL: [60/129] Loss: 0.5828(0.5240) \n","EVAL: [80/129] Loss: 0.5378(0.5225) \n","EVAL: [100/129] Loss: 0.6880(0.5221) \n","EVAL: [120/129] Loss: 0.4223(0.5205) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.5328 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5328 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.5208(0.5208) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6764  avg_val_loss: 0.5208\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6764  avg_val_loss: 0.5208\n","Epoch 1 - Score: 0.5328  Scores: [0.4780260093060706, 0.5875738861273226]\n","INFO:__main__:Epoch 1 - Score: 0.5328  Scores: [0.4780260093060706, 0.5875738861273226]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][460/638] Elapsed 4m 37s (remain 1m 46s) Loss: 0.6057(0.6749) Grad: 51261.7383  LR: 0.00001961  \n","Epoch: [1][480/638] Elapsed 4m 42s (remain 1m 32s) Loss: 0.7168(0.6679) Grad: 92056.6719  LR: 0.00001953  \n","Epoch: [1][500/638] Elapsed 4m 49s (remain 1m 19s) Loss: 0.5427(0.6649) Grad: 163647.7031  LR: 0.00001944  \n","Epoch: [1][520/638] Elapsed 4m 56s (remain 1m 6s) Loss: 0.8488(0.6605) Grad: 85479.9453  LR: 0.00001935  \n","Epoch: [1][540/638] Elapsed 5m 3s (remain 0m 54s) Loss: 0.3713(0.6562) Grad: 74429.5938  LR: 0.00001925  \n","Epoch: [1][560/638] Elapsed 5m 11s (remain 0m 42s) Loss: 0.4850(0.6508) Grad: 49721.9609  LR: 0.00001914  \n","Epoch: [1][580/638] Elapsed 5m 17s (remain 0m 31s) Loss: 0.4894(0.6464) Grad: 50928.0117  LR: 0.00001902  \n","Epoch: [1][600/638] Elapsed 5m 22s (remain 0m 19s) Loss: 0.6669(0.6418) Grad: 95922.6875  LR: 0.00001890  \n","EVAL: [0/129] Loss: 0.4008(0.4008) \n","EVAL: [20/129] Loss: 0.4241(0.5043) \n","EVAL: [40/129] Loss: 0.4740(0.4951) \n","EVAL: [60/129] Loss: 0.5007(0.5032) \n","EVAL: [80/129] Loss: 0.5580(0.5005) \n","EVAL: [100/129] Loss: 0.5872(0.4970) \n","EVAL: [120/129] Loss: 0.4320(0.4965) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.5041 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5041 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.5066(0.4955) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6418  avg_val_loss: 0.4955\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6418  avg_val_loss: 0.4955\n","Epoch 1 - Score: 0.5041  Scores: [0.46104722392494013, 0.5471469172099651]\n","INFO:__main__:Epoch 1 - Score: 0.5041  Scores: [0.46104722392494013, 0.5471469172099651]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][620/638] Elapsed 6m 13s (remain 0m 10s) Loss: 0.5813(0.6378) Grad: 121123.4688  LR: 0.00001878  \n","Epoch: [1][637/638] Elapsed 6m 19s (remain 0m 0s) Loss: 0.5091(0.6346) Grad: 92996.1875  LR: 0.00001866  \n","EVAL: [0/129] Loss: 0.4941(0.4941) \n","EVAL: [20/129] Loss: 0.4874(0.5250) \n","EVAL: [40/129] Loss: 0.4491(0.5172) \n","EVAL: [60/129] Loss: 0.6167(0.5248) \n","EVAL: [80/129] Loss: 0.5059(0.5212) \n","EVAL: [100/129] Loss: 0.6901(0.5200) \n","EVAL: [120/129] Loss: 0.4858(0.5187) \n","EVAL: [128/129] Loss: 0.4818(0.5176) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6346  avg_val_loss: 0.5176\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6346  avg_val_loss: 0.5176\n","Epoch 1 - Score: 0.5271  Scores: [0.44828072669875557, 0.6059563521759793]\n","INFO:__main__:Epoch 1 - Score: 0.5271  Scores: [0.44828072669875557, 0.6059563521759793]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/638] Elapsed 0m 0s (remain 8m 22s) Loss: 0.4588(0.4588) Grad: 350737.4375  LR: 0.00001865  \n","Epoch: [2][20/638] Elapsed 0m 6s (remain 3m 11s) Loss: 0.5544(0.4940) Grad: 220267.4688  LR: 0.00001851  \n","Epoch: [2][40/638] Elapsed 0m 12s (remain 2m 57s) Loss: 0.4142(0.4840) Grad: 131000.0547  LR: 0.00001837  \n","Epoch: [2][60/638] Elapsed 0m 18s (remain 2m 51s) Loss: 0.4467(0.4717) Grad: 114609.1641  LR: 0.00001822  \n","Epoch: [2][80/638] Elapsed 0m 23s (remain 2m 42s) Loss: 0.3320(0.4713) Grad: 135880.6875  LR: 0.00001806  \n","Epoch: [2][100/638] Elapsed 0m 28s (remain 2m 32s) Loss: 0.3098(0.4637) Grad: 188596.6719  LR: 0.00001789  \n","Epoch: [2][120/638] Elapsed 0m 34s (remain 2m 28s) Loss: 0.5461(0.4620) Grad: 122437.0156  LR: 0.00001772  \n","Epoch: [2][140/638] Elapsed 0m 39s (remain 2m 20s) Loss: 0.3404(0.4630) Grad: 123306.0859  LR: 0.00001754  \n","EVAL: [0/129] Loss: 0.4305(0.4305) \n","EVAL: [20/129] Loss: 0.4365(0.4992) \n","EVAL: [40/129] Loss: 0.4723(0.4905) \n","EVAL: [60/129] Loss: 0.5450(0.4968) \n","EVAL: [80/129] Loss: 0.5099(0.4942) \n","EVAL: [100/129] Loss: 0.6240(0.4925) \n","EVAL: [120/129] Loss: 0.4418(0.4902) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Save Best Score: 0.4976 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4976 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.5180(0.4890) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4672  avg_val_loss: 0.4890\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4672  avg_val_loss: 0.4890\n","Epoch 2 - Score: 0.4976  Scores: [0.42638081006111916, 0.568764498140797]\n","INFO:__main__:Epoch 2 - Score: 0.4976  Scores: [0.42638081006111916, 0.568764498140797]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][160/638] Elapsed 1m 26s (remain 4m 16s) Loss: 0.5139(0.4699) Grad: 247886.8750  LR: 0.00001736  \n","Epoch: [2][180/638] Elapsed 1m 31s (remain 3m 51s) Loss: 0.3947(0.4699) Grad: 193003.0781  LR: 0.00001717  \n","Epoch: [2][200/638] Elapsed 1m 38s (remain 3m 34s) Loss: 0.5742(0.4699) Grad: 188708.4844  LR: 0.00001698  \n","Epoch: [2][220/638] Elapsed 1m 44s (remain 3m 17s) Loss: 0.3945(0.4758) Grad: 97916.3750  LR: 0.00001678  \n","Epoch: [2][240/638] Elapsed 1m 51s (remain 3m 2s) Loss: 0.3921(0.4716) Grad: 144493.7344  LR: 0.00001658  \n","Epoch: [2][260/638] Elapsed 1m 58s (remain 2m 51s) Loss: 0.3868(0.4710) Grad: 145768.9531  LR: 0.00001637  \n","Epoch: [2][280/638] Elapsed 2m 4s (remain 2m 38s) Loss: 0.3005(0.4703) Grad: 270416.7188  LR: 0.00001616  \n","Epoch: [2][300/638] Elapsed 2m 11s (remain 2m 26s) Loss: 0.5052(0.4740) Grad: 85277.2891  LR: 0.00001594  \n","EVAL: [0/129] Loss: 0.4507(0.4507) \n","EVAL: [20/129] Loss: 0.4459(0.4858) \n","EVAL: [40/129] Loss: 0.4613(0.4787) \n","EVAL: [60/129] Loss: 0.5570(0.4872) \n","EVAL: [80/129] Loss: 0.4800(0.4824) \n","EVAL: [100/129] Loss: 0.6371(0.4810) \n","EVAL: [120/129] Loss: 0.3755(0.4783) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Save Best Score: 0.4868 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4868 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.4492(0.4764) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4740  avg_val_loss: 0.4764\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4740  avg_val_loss: 0.4764\n","Epoch 2 - Score: 0.4868  Scores: [0.4261700899997922, 0.5474447428497093]\n","INFO:__main__:Epoch 2 - Score: 0.4868  Scores: [0.4261700899997922, 0.5474447428497093]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][320/638] Elapsed 3m 6s (remain 3m 4s) Loss: 0.4836(0.4757) Grad: 216677.2031  LR: 0.00001572  \n","Epoch: [2][340/638] Elapsed 3m 14s (remain 2m 49s) Loss: 0.4070(0.4751) Grad: 234769.1875  LR: 0.00001549  \n","Epoch: [2][360/638] Elapsed 3m 20s (remain 2m 33s) Loss: 0.7158(0.4729) Grad: 181476.4219  LR: 0.00001526  \n","Epoch: [2][380/638] Elapsed 3m 27s (remain 2m 19s) Loss: 0.4417(0.4715) Grad: 190014.5000  LR: 0.00001503  \n","Epoch: [2][400/638] Elapsed 3m 34s (remain 2m 7s) Loss: 0.5246(0.4709) Grad: 230400.3125  LR: 0.00001479  \n","Epoch: [2][420/638] Elapsed 3m 41s (remain 1m 54s) Loss: 0.5235(0.4683) Grad: 219708.0312  LR: 0.00001455  \n","Epoch: [2][440/638] Elapsed 3m 47s (remain 1m 41s) Loss: 0.6409(0.4683) Grad: 214898.1875  LR: 0.00001430  \n","EVAL: [0/129] Loss: 0.4228(0.4228) \n","EVAL: [20/129] Loss: 0.4413(0.4785) \n","EVAL: [40/129] Loss: 0.4816(0.4720) \n","EVAL: [60/129] Loss: 0.4766(0.4779) \n","EVAL: [80/129] Loss: 0.5057(0.4719) \n","EVAL: [100/129] Loss: 0.5999(0.4693) \n","EVAL: [120/129] Loss: 0.3673(0.4677) \n","EVAL: [128/129] Loss: 0.4697(0.4665) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Save Best Score: 0.4764 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4764 Model\n","Epoch 2 - avg_train_loss: 0.4694  avg_val_loss: 0.4665\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4694  avg_val_loss: 0.4665\n","Epoch 2 - Score: 0.4764  Scores: [0.4071460568919797, 0.5457197065874293]\n","INFO:__main__:Epoch 2 - Score: 0.4764  Scores: [0.4071460568919797, 0.5457197065874293]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][460/638] Elapsed 4m 35s (remain 1m 45s) Loss: 0.5208(0.4684) Grad: 152564.4844  LR: 0.00001405  \n","Epoch: [2][480/638] Elapsed 4m 41s (remain 1m 31s) Loss: 0.4462(0.4693) Grad: 111000.4297  LR: 0.00001380  \n","Epoch: [2][500/638] Elapsed 4m 49s (remain 1m 19s) Loss: 0.5209(0.4681) Grad: 114451.1016  LR: 0.00001355  \n","Epoch: [2][520/638] Elapsed 4m 57s (remain 1m 6s) Loss: 0.3151(0.4682) Grad: 169997.2188  LR: 0.00001329  \n","Epoch: [2][540/638] Elapsed 5m 4s (remain 0m 54s) Loss: 0.3976(0.4680) Grad: 264919.2188  LR: 0.00001303  \n","Epoch: [2][560/638] Elapsed 5m 11s (remain 0m 42s) Loss: 0.4815(0.4684) Grad: 120189.5625  LR: 0.00001277  \n","Epoch: [2][580/638] Elapsed 5m 16s (remain 0m 31s) Loss: 0.7410(0.4681) Grad: 160742.2500  LR: 0.00001251  \n","Epoch: [2][600/638] Elapsed 5m 22s (remain 0m 19s) Loss: 0.4574(0.4675) Grad: 240378.9375  LR: 0.00001224  \n","EVAL: [0/129] Loss: 0.4446(0.4446) \n","EVAL: [20/129] Loss: 0.4295(0.4975) \n","EVAL: [40/129] Loss: 0.4322(0.4958) \n","EVAL: [60/129] Loss: 0.5641(0.5014) \n","EVAL: [80/129] Loss: 0.5020(0.4986) \n","EVAL: [100/129] Loss: 0.6686(0.4964) \n","EVAL: [120/129] Loss: 0.3842(0.4952) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4675  avg_val_loss: 0.4935\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4675  avg_val_loss: 0.4935\n","Epoch 2 - Score: 0.5037  Scores: [0.4788103880116258, 0.5285355255472397]\n","INFO:__main__:Epoch 2 - Score: 0.5037  Scores: [0.4788103880116258, 0.5285355255472397]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.4283(0.4935) \n","Epoch: [2][620/638] Elapsed 6m 2s (remain 0m 9s) Loss: 0.4159(0.4666) Grad: 152886.3125  LR: 0.00001198  \n","Epoch: [2][637/638] Elapsed 6m 6s (remain 0m 0s) Loss: 0.4644(0.4655) Grad: 207046.4844  LR: 0.00001175  \n","EVAL: [0/129] Loss: 0.3897(0.3897) \n","EVAL: [20/129] Loss: 0.4038(0.4896) \n","EVAL: [40/129] Loss: 0.4890(0.4927) \n","EVAL: [60/129] Loss: 0.5306(0.4990) \n","EVAL: [80/129] Loss: 0.5300(0.4982) \n","EVAL: [100/129] Loss: 0.6298(0.4957) \n","EVAL: [120/129] Loss: 0.3437(0.4938) \n","EVAL: [128/129] Loss: 0.4599(0.4931) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4655  avg_val_loss: 0.4931\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4655  avg_val_loss: 0.4931\n","Epoch 2 - Score: 0.5033  Scores: [0.4575241099856397, 0.5490296930463149]\n","INFO:__main__:Epoch 2 - Score: 0.5033  Scores: [0.4575241099856397, 0.5490296930463149]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/638] Elapsed 0m 0s (remain 7m 55s) Loss: 0.3602(0.3602) Grad: 267878.1875  LR: 0.00001173  \n","Epoch: [3][20/638] Elapsed 0m 6s (remain 3m 12s) Loss: 0.3105(0.4023) Grad: 122301.4062  LR: 0.00001146  \n","Epoch: [3][40/638] Elapsed 0m 11s (remain 2m 47s) Loss: 0.3371(0.3898) Grad: 172562.7188  LR: 0.00001119  \n","Epoch: [3][60/638] Elapsed 0m 18s (remain 2m 51s) Loss: 0.3591(0.3959) Grad: 151809.5312  LR: 0.00001092  \n","Epoch: [3][80/638] Elapsed 0m 24s (remain 2m 47s) Loss: 0.2598(0.4003) Grad: 115617.7344  LR: 0.00001065  \n","Epoch: [3][100/638] Elapsed 0m 30s (remain 2m 44s) Loss: 0.3847(0.4000) Grad: 218284.6406  LR: 0.00001038  \n","Epoch: [3][120/638] Elapsed 0m 37s (remain 2m 39s) Loss: 0.5374(0.3930) Grad: 243861.5312  LR: 0.00001010  \n","Epoch: [3][140/638] Elapsed 0m 42s (remain 2m 30s) Loss: 0.4099(0.3893) Grad: 186670.2812  LR: 0.00000983  \n","EVAL: [0/129] Loss: 0.4027(0.4027) \n","EVAL: [20/129] Loss: 0.4199(0.4755) \n","EVAL: [40/129] Loss: 0.4528(0.4753) \n","EVAL: [60/129] Loss: 0.5420(0.4813) \n","EVAL: [80/129] Loss: 0.4877(0.4775) \n","EVAL: [100/129] Loss: 0.6317(0.4752) \n","EVAL: [120/129] Loss: 0.3670(0.4742) \n","EVAL: [128/129] Loss: 0.4229(0.4728) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3862  avg_val_loss: 0.4728\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3862  avg_val_loss: 0.4728\n","Epoch 3 - Score: 0.4829  Scores: [0.44888039155918763, 0.5168598057578119]\n","INFO:__main__:Epoch 3 - Score: 0.4829  Scores: [0.44888039155918763, 0.5168598057578119]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][160/638] Elapsed 1m 23s (remain 4m 6s) Loss: 0.3949(0.3855) Grad: 122329.5703  LR: 0.00000956  \n","Epoch: [3][180/638] Elapsed 1m 28s (remain 3m 43s) Loss: 0.3744(0.3888) Grad: 163266.3594  LR: 0.00000928  \n","Epoch: [3][200/638] Elapsed 1m 33s (remain 3m 23s) Loss: 0.2304(0.3861) Grad: 136662.1406  LR: 0.00000901  \n","Epoch: [3][220/638] Elapsed 1m 39s (remain 3m 8s) Loss: 0.4519(0.3874) Grad: 108590.8203  LR: 0.00000874  \n","Epoch: [3][240/638] Elapsed 1m 45s (remain 2m 54s) Loss: 0.5996(0.3896) Grad: 169678.7031  LR: 0.00000847  \n","Epoch: [3][260/638] Elapsed 1m 51s (remain 2m 41s) Loss: 0.3151(0.3917) Grad: 235182.8125  LR: 0.00000820  \n","Epoch: [3][280/638] Elapsed 1m 57s (remain 2m 28s) Loss: 0.2845(0.3890) Grad: 131549.8594  LR: 0.00000793  \n","Epoch: [3][300/638] Elapsed 2m 2s (remain 2m 16s) Loss: 0.4042(0.3902) Grad: 155123.9531  LR: 0.00000766  \n","EVAL: [0/129] Loss: 0.3881(0.3881) \n","EVAL: [20/129] Loss: 0.4072(0.4638) \n","EVAL: [40/129] Loss: 0.4625(0.4631) \n","EVAL: [60/129] Loss: 0.4970(0.4708) \n","EVAL: [80/129] Loss: 0.5098(0.4677) \n","EVAL: [100/129] Loss: 0.5830(0.4639) \n","EVAL: [120/129] Loss: 0.3381(0.4621) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Save Best Score: 0.4709 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4709 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.4338(0.4611) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3902  avg_val_loss: 0.4611\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3902  avg_val_loss: 0.4611\n","Epoch 3 - Score: 0.4709  Scores: [0.42018253332841665, 0.5216397471466937]\n","INFO:__main__:Epoch 3 - Score: 0.4709  Scores: [0.42018253332841665, 0.5216397471466937]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][320/638] Elapsed 2m 49s (remain 2m 47s) Loss: 0.2759(0.3893) Grad: 144454.8750  LR: 0.00000740  \n","Epoch: [3][340/638] Elapsed 2m 56s (remain 2m 33s) Loss: 0.3908(0.3885) Grad: 157187.5469  LR: 0.00000714  \n","Epoch: [3][360/638] Elapsed 3m 3s (remain 2m 20s) Loss: 0.5377(0.3900) Grad: 65795.5234  LR: 0.00000688  \n","Epoch: [3][380/638] Elapsed 3m 9s (remain 2m 7s) Loss: 0.3948(0.3894) Grad: 92022.6250  LR: 0.00000662  \n","Epoch: [3][400/638] Elapsed 3m 16s (remain 1m 55s) Loss: 0.3652(0.3906) Grad: 93561.2734  LR: 0.00000636  \n","Epoch: [3][420/638] Elapsed 3m 23s (remain 1m 44s) Loss: 0.4633(0.3915) Grad: 64261.5352  LR: 0.00000611  \n","Epoch: [3][440/638] Elapsed 3m 29s (remain 1m 33s) Loss: 0.2903(0.3928) Grad: 56842.6523  LR: 0.00000586  \n","EVAL: [0/129] Loss: 0.4361(0.4361) \n","EVAL: [20/129] Loss: 0.4207(0.4903) \n","EVAL: [40/129] Loss: 0.4673(0.4925) \n","EVAL: [60/129] Loss: 0.5289(0.4992) \n","EVAL: [80/129] Loss: 0.5160(0.4964) \n","EVAL: [100/129] Loss: 0.6469(0.4933) \n","EVAL: [120/129] Loss: 0.3776(0.4917) \n","EVAL: [128/129] Loss: 0.4488(0.4902) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3932  avg_val_loss: 0.4902\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3932  avg_val_loss: 0.4902\n","Epoch 3 - Score: 0.4998  Scores: [0.48075574078855576, 0.5188476333682893]\n","INFO:__main__:Epoch 3 - Score: 0.4998  Scores: [0.48075574078855576, 0.5188476333682893]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][460/638] Elapsed 4m 9s (remain 1m 35s) Loss: 0.2967(0.3922) Grad: 86579.5391  LR: 0.00000561  \n","Epoch: [3][480/638] Elapsed 4m 14s (remain 1m 23s) Loss: 0.4748(0.3923) Grad: 51718.4805  LR: 0.00000537  \n","Epoch: [3][500/638] Elapsed 4m 19s (remain 1m 11s) Loss: 0.3717(0.3930) Grad: 73468.7500  LR: 0.00000513  \n","Epoch: [3][520/638] Elapsed 4m 26s (remain 0m 59s) Loss: 0.5216(0.3927) Grad: 59399.9922  LR: 0.00000489  \n","Epoch: [3][540/638] Elapsed 4m 31s (remain 0m 48s) Loss: 0.4295(0.3917) Grad: 84837.6484  LR: 0.00000466  \n","Epoch: [3][560/638] Elapsed 4m 37s (remain 0m 38s) Loss: 0.4228(0.3920) Grad: 50379.6016  LR: 0.00000443  \n","Epoch: [3][580/638] Elapsed 4m 43s (remain 0m 27s) Loss: 0.5287(0.3906) Grad: 106837.5781  LR: 0.00000420  \n","Epoch: [3][600/638] Elapsed 4m 48s (remain 0m 17s) Loss: 0.3556(0.3919) Grad: 108060.5625  LR: 0.00000398  \n","EVAL: [0/129] Loss: 0.4220(0.4220) \n","EVAL: [20/129] Loss: 0.4022(0.4685) \n","EVAL: [40/129] Loss: 0.4571(0.4651) \n","EVAL: [60/129] Loss: 0.4839(0.4711) \n","EVAL: [80/129] Loss: 0.4925(0.4674) \n","EVAL: [100/129] Loss: 0.5843(0.4639) \n","EVAL: [120/129] Loss: 0.3610(0.4620) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Save Best Score: 0.4693 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4693 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.4578(0.4599) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3919  avg_val_loss: 0.4599\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3919  avg_val_loss: 0.4599\n","Epoch 3 - Score: 0.4693  Scores: [0.4174328570516981, 0.5211795792755783]\n","INFO:__main__:Epoch 3 - Score: 0.4693  Scores: [0.4174328570516981, 0.5211795792755783]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][620/638] Elapsed 5m 39s (remain 0m 9s) Loss: 0.3350(0.3920) Grad: 60241.5781  LR: 0.00000377  \n","Epoch: [3][637/638] Elapsed 5m 45s (remain 0m 0s) Loss: 0.2069(0.3926) Grad: 97321.3516  LR: 0.00000359  \n","EVAL: [0/129] Loss: 0.3983(0.3983) \n","EVAL: [20/129] Loss: 0.3731(0.4715) \n","EVAL: [40/129] Loss: 0.4600(0.4721) \n","EVAL: [60/129] Loss: 0.4949(0.4788) \n","EVAL: [80/129] Loss: 0.5084(0.4771) \n","EVAL: [100/129] Loss: 0.5763(0.4732) \n","EVAL: [120/129] Loss: 0.3518(0.4712) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3926  avg_val_loss: 0.4692\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3926  avg_val_loss: 0.4692\n","Epoch 3 - Score: 0.4783  Scores: [0.44336048728235733, 0.5132126271838894]\n","INFO:__main__:Epoch 3 - Score: 0.4783  Scores: [0.44336048728235733, 0.5132126271838894]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.4626(0.4692) \n","Epoch: [4][0/638] Elapsed 0m 0s (remain 5m 17s) Loss: 0.3489(0.3489) Grad: 383873.5938  LR: 0.00000358  \n","Epoch: [4][20/638] Elapsed 0m 5s (remain 2m 54s) Loss: 0.2311(0.3523) Grad: 118516.6875  LR: 0.00000337  \n","Epoch: [4][40/638] Elapsed 0m 11s (remain 2m 50s) Loss: 0.3664(0.3381) Grad: 237023.1406  LR: 0.00000317  \n","Epoch: [4][60/638] Elapsed 0m 17s (remain 2m 46s) Loss: 0.3646(0.3432) Grad: 121455.4766  LR: 0.00000297  \n","Epoch: [4][80/638] Elapsed 0m 24s (remain 2m 45s) Loss: 0.3015(0.3356) Grad: 156113.0000  LR: 0.00000278  \n","Epoch: [4][100/638] Elapsed 0m 30s (remain 2m 42s) Loss: 0.3122(0.3326) Grad: 239779.7344  LR: 0.00000259  \n","Epoch: [4][120/638] Elapsed 0m 37s (remain 2m 38s) Loss: 0.4119(0.3371) Grad: 132595.5625  LR: 0.00000241  \n","Epoch: [4][140/638] Elapsed 0m 43s (remain 2m 32s) Loss: 0.1903(0.3344) Grad: 111583.1641  LR: 0.00000224  \n","EVAL: [0/129] Loss: 0.4304(0.4304) \n","EVAL: [20/129] Loss: 0.4032(0.4755) \n","EVAL: [40/129] Loss: 0.4643(0.4748) \n","EVAL: [60/129] Loss: 0.4939(0.4813) \n","EVAL: [80/129] Loss: 0.4996(0.4780) \n","EVAL: [100/129] Loss: 0.5910(0.4742) \n","EVAL: [120/129] Loss: 0.3749(0.4725) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3360  avg_val_loss: 0.4705\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3360  avg_val_loss: 0.4705\n","Epoch 4 - Score: 0.4797  Scores: [0.4386307098170215, 0.5206795506833112]\n","INFO:__main__:Epoch 4 - Score: 0.4797  Scores: [0.4386307098170215, 0.5206795506833112]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.4631(0.4705) \n","Epoch: [4][160/638] Elapsed 1m 22s (remain 4m 5s) Loss: 0.4141(0.3369) Grad: 227161.3281  LR: 0.00000207  \n","Epoch: [4][180/638] Elapsed 1m 27s (remain 3m 41s) Loss: 0.3388(0.3377) Grad: 216342.0781  LR: 0.00000190  \n","Epoch: [4][200/638] Elapsed 1m 34s (remain 3m 24s) Loss: 0.2984(0.3370) Grad: 156204.3125  LR: 0.00000175  \n","Epoch: [4][220/638] Elapsed 1m 39s (remain 3m 8s) Loss: 0.3750(0.3326) Grad: 162478.0469  LR: 0.00000159  \n","Epoch: [4][240/638] Elapsed 1m 45s (remain 2m 54s) Loss: 0.4181(0.3324) Grad: 209777.9844  LR: 0.00000145  \n","Epoch: [4][260/638] Elapsed 1m 51s (remain 2m 41s) Loss: 0.3597(0.3288) Grad: 202782.8438  LR: 0.00000131  \n","Epoch: [4][280/638] Elapsed 1m 57s (remain 2m 28s) Loss: 0.2613(0.3278) Grad: 187794.6094  LR: 0.00000118  \n","Epoch: [4][300/638] Elapsed 2m 3s (remain 2m 17s) Loss: 0.3441(0.3286) Grad: 151072.1094  LR: 0.00000105  \n","EVAL: [0/129] Loss: 0.4206(0.4206) \n","EVAL: [20/129] Loss: 0.4004(0.4748) \n","EVAL: [40/129] Loss: 0.4626(0.4758) \n","EVAL: [60/129] Loss: 0.5064(0.4829) \n","EVAL: [80/129] Loss: 0.4991(0.4799) \n","EVAL: [100/129] Loss: 0.5969(0.4764) \n","EVAL: [120/129] Loss: 0.3685(0.4745) \n","EVAL: [128/129] Loss: 0.4591(0.4730) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3286  avg_val_loss: 0.4730\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3286  avg_val_loss: 0.4730\n","Epoch 4 - Score: 0.4823  Scores: [0.4473229786471676, 0.5171902814341651]\n","INFO:__main__:Epoch 4 - Score: 0.4823  Scores: [0.4473229786471676, 0.5171902814341651]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][320/638] Elapsed 2m 42s (remain 2m 40s) Loss: 0.3195(0.3284) Grad: 147510.4688  LR: 0.00000094  \n","Epoch: [4][340/638] Elapsed 2m 47s (remain 2m 25s) Loss: 0.3087(0.3271) Grad: 144411.7188  LR: 0.00000082  \n","Epoch: [4][360/638] Elapsed 2m 53s (remain 2m 13s) Loss: 0.2964(0.3280) Grad: 209962.8906  LR: 0.00000072  \n","Epoch: [4][380/638] Elapsed 2m 58s (remain 2m 0s) Loss: 0.3512(0.3276) Grad: 130204.2500  LR: 0.00000062  \n","Epoch: [4][400/638] Elapsed 3m 3s (remain 1m 48s) Loss: 0.3546(0.3274) Grad: 334894.5625  LR: 0.00000053  \n","Epoch: [4][420/638] Elapsed 3m 10s (remain 1m 38s) Loss: 0.4645(0.3282) Grad: 196887.7188  LR: 0.00000044  \n","Epoch: [4][440/638] Elapsed 3m 15s (remain 1m 27s) Loss: 0.4085(0.3278) Grad: 126945.7812  LR: 0.00000037  \n","EVAL: [0/129] Loss: 0.4176(0.4176) \n","EVAL: [20/129] Loss: 0.3999(0.4726) \n","EVAL: [40/129] Loss: 0.4636(0.4727) \n","EVAL: [60/129] Loss: 0.5045(0.4799) \n","EVAL: [80/129] Loss: 0.4981(0.4767) \n","EVAL: [100/129] Loss: 0.5925(0.4732) \n","EVAL: [120/129] Loss: 0.3614(0.4712) \n","EVAL: [128/129] Loss: 0.4529(0.4697) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3276  avg_val_loss: 0.4697\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3276  avg_val_loss: 0.4697\n","Epoch 4 - Score: 0.4790  Scores: [0.44135866863940126, 0.5167364695301802]\n","INFO:__main__:Epoch 4 - Score: 0.4790  Scores: [0.44135866863940126, 0.5167364695301802]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][460/638] Elapsed 3m 55s (remain 1m 30s) Loss: 0.3548(0.3278) Grad: 178789.4219  LR: 0.00000030  \n","Epoch: [4][480/638] Elapsed 4m 0s (remain 1m 18s) Loss: 0.5372(0.3277) Grad: 199267.0312  LR: 0.00000024  \n","Epoch: [4][500/638] Elapsed 4m 6s (remain 1m 7s) Loss: 0.3780(0.3260) Grad: 177740.8906  LR: 0.00000018  \n","Epoch: [4][520/638] Elapsed 4m 11s (remain 0m 56s) Loss: 0.2143(0.3262) Grad: 151697.5000  LR: 0.00000013  \n","Epoch: [4][540/638] Elapsed 4m 17s (remain 0m 46s) Loss: 0.2619(0.3255) Grad: 110638.1875  LR: 0.00000009  \n","Epoch: [4][560/638] Elapsed 4m 23s (remain 0m 36s) Loss: 0.2344(0.3250) Grad: 157231.4375  LR: 0.00000006  \n","Epoch: [4][580/638] Elapsed 4m 30s (remain 0m 26s) Loss: 0.2855(0.3254) Grad: 134632.2500  LR: 0.00000003  \n","Epoch: [4][600/638] Elapsed 4m 35s (remain 0m 16s) Loss: 0.3362(0.3252) Grad: 168653.7656  LR: 0.00000001  \n","EVAL: [0/129] Loss: 0.4210(0.4210) \n","EVAL: [20/129] Loss: 0.4010(0.4747) \n","EVAL: [40/129] Loss: 0.4626(0.4750) \n","EVAL: [60/129] Loss: 0.5071(0.4820) \n","EVAL: [80/129] Loss: 0.5003(0.4789) \n","EVAL: [100/129] Loss: 0.5961(0.4753) \n","EVAL: [120/129] Loss: 0.3662(0.4734) \n","EVAL: [128/129] Loss: 0.4540(0.4718) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3252  avg_val_loss: 0.4718\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3252  avg_val_loss: 0.4718\n","Epoch 4 - Score: 0.4811  Scores: [0.4452618195516229, 0.516856274171098]\n","INFO:__main__:Epoch 4 - Score: 0.4811  Scores: [0.4452618195516229, 0.516856274171098]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][620/638] Elapsed 5m 16s (remain 0m 8s) Loss: 0.4295(0.3251) Grad: 205753.0156  LR: 0.00000000  \n","Epoch: [4][637/638] Elapsed 5m 21s (remain 0m 0s) Loss: 0.2315(0.3244) Grad: 114381.2812  LR: 0.00000000  \n","EVAL: [0/129] Loss: 0.4209(0.4209) \n","EVAL: [20/129] Loss: 0.4010(0.4748) \n","EVAL: [40/129] Loss: 0.4626(0.4751) \n","EVAL: [60/129] Loss: 0.5072(0.4821) \n","EVAL: [80/129] Loss: 0.5004(0.4790) \n","EVAL: [100/129] Loss: 0.5962(0.4754) \n","EVAL: [120/129] Loss: 0.3663(0.4735) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3244  avg_val_loss: 0.4719\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3244  avg_val_loss: 0.4719\n","Epoch 4 - Score: 0.4812  Scores: [0.4454609224997959, 0.5168435075180935]\n","INFO:__main__:Epoch 4 - Score: 0.4812  Scores: [0.4454609224997959, 0.5168435075180935]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Loss: 0.4540(0.4719) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.4693  Scores: [0.4174328570516981, 0.5211795792755783]\n","INFO:__main__:Score: 0.4693  Scores: [0.4174328570516981, 0.5211795792755783]\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/644] Elapsed 0m 0s (remain 5m 41s) Loss: 1.2544(1.2544) Grad: 70313.4844  LR: 0.00000008  \n","Epoch: [1][20/644] Elapsed 0m 5s (remain 2m 39s) Loss: 1.3552(1.1102) Grad: 28075.5566  LR: 0.00000163  \n","Epoch: [1][40/644] Elapsed 0m 10s (remain 2m 39s) Loss: 0.8763(1.0310) Grad: 69931.6016  LR: 0.00000319  \n","Epoch: [1][60/644] Elapsed 0m 16s (remain 2m 38s) Loss: 1.0714(1.0447) Grad: 47680.0664  LR: 0.00000475  \n","Epoch: [1][80/644] Elapsed 0m 21s (remain 2m 31s) Loss: 0.7852(1.0269) Grad: 63068.1641  LR: 0.00000630  \n","Epoch: [1][100/644] Elapsed 0m 27s (remain 2m 27s) Loss: 0.7268(0.9827) Grad: 191341.7656  LR: 0.00000786  \n","Epoch: [1][120/644] Elapsed 0m 32s (remain 2m 20s) Loss: 0.6965(0.9355) Grad: 304849.7188  LR: 0.00000942  \n","Epoch: [1][140/644] Elapsed 0m 37s (remain 2m 13s) Loss: 0.4564(0.8894) Grad: 219533.3906  LR: 0.00001097  \n","EVAL: [0/126] Loss: 1.0141(1.0141) \n","EVAL: [20/126] Loss: 0.6749(0.7261) \n","EVAL: [40/126] Loss: 0.7948(0.7285) \n","EVAL: [60/126] Loss: 0.7528(0.7285) \n","EVAL: [80/126] Loss: 0.7101(0.7257) \n","EVAL: [100/126] Loss: 0.6581(0.7229) \n","EVAL: [120/126] Loss: 0.6958(0.7180) \n","EVAL: [125/126] Loss: 0.6041(0.7181) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.7305 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7305 Model\n","Epoch 1 - avg_train_loss: 0.8705  avg_val_loss: 0.7181\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.8705  avg_val_loss: 0.7181\n","Epoch 1 - Score: 0.7305  Scores: [0.699738893649059, 0.7612381857502764]\n","INFO:__main__:Epoch 1 - Score: 0.7305  Scores: [0.699738893649059, 0.7612381857502764]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][160/644] Elapsed 1m 44s (remain 5m 13s) Loss: 0.4744(0.8581) Grad: 219825.4688  LR: 0.00001253  \n","Epoch: [1][180/644] Elapsed 1m 50s (remain 4m 42s) Loss: 0.5436(0.8257) Grad: 199186.6094  LR: 0.00001409  \n","Epoch: [1][200/644] Elapsed 1m 56s (remain 4m 17s) Loss: 0.7050(0.7954) Grad: 197544.1719  LR: 0.00001564  \n","Epoch: [1][220/644] Elapsed 2m 5s (remain 4m 0s) Loss: 0.9675(0.7786) Grad: 184928.1250  LR: 0.00001720  \n","Epoch: [1][240/644] Elapsed 2m 11s (remain 3m 39s) Loss: 0.6461(0.7638) Grad: 268709.1250  LR: 0.00001875  \n","Epoch: [1][260/644] Elapsed 2m 18s (remain 3m 22s) Loss: 0.6520(0.7506) Grad: 236212.1406  LR: 0.00002000  \n","Epoch: [1][280/644] Elapsed 2m 24s (remain 3m 6s) Loss: 0.4979(0.7337) Grad: 294450.8750  LR: 0.00001999  \n","Epoch: [1][300/644] Elapsed 2m 29s (remain 2m 50s) Loss: 0.3393(0.7205) Grad: 93455.2422  LR: 0.00001998  \n","EVAL: [0/126] Loss: 0.9271(0.9271) \n","EVAL: [20/126] Loss: 0.6278(0.6829) \n","EVAL: [40/126] Loss: 0.7622(0.7042) \n","EVAL: [60/126] Loss: 0.6596(0.7017) \n","EVAL: [80/126] Loss: 0.5826(0.7030) \n","EVAL: [100/126] Loss: 0.6154(0.7028) \n","EVAL: [120/126] Loss: 0.7685(0.6993) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.7122 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7122 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.5840(0.6997) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.7205  avg_val_loss: 0.6997\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.7205  avg_val_loss: 0.6997\n","Epoch 1 - Score: 0.7122  Scores: [0.6136114173562237, 0.8107044250630112]\n","INFO:__main__:Epoch 1 - Score: 0.7122  Scores: [0.6136114173562237, 0.8107044250630112]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][320/644] Elapsed 3m 37s (remain 3m 38s) Loss: 0.4236(0.7121) Grad: 322271.1875  LR: 0.00001996  \n","Epoch: [1][340/644] Elapsed 3m 43s (remain 3m 18s) Loss: 0.6326(0.7010) Grad: 162874.2344  LR: 0.00001994  \n","Epoch: [1][360/644] Elapsed 3m 49s (remain 2m 59s) Loss: 0.5027(0.6917) Grad: 216872.2656  LR: 0.00001990  \n","Epoch: [1][380/644] Elapsed 3m 56s (remain 2m 43s) Loss: 0.7110(0.6824) Grad: 304576.7812  LR: 0.00001986  \n","Epoch: [1][400/644] Elapsed 4m 3s (remain 2m 27s) Loss: 0.4124(0.6710) Grad: 170274.1875  LR: 0.00001981  \n","Epoch: [1][420/644] Elapsed 4m 9s (remain 2m 12s) Loss: 0.4815(0.6639) Grad: 152191.6562  LR: 0.00001975  \n","Epoch: [1][440/644] Elapsed 4m 15s (remain 1m 57s) Loss: 0.4400(0.6579) Grad: 75137.9062  LR: 0.00001969  \n","EVAL: [0/126] Loss: 0.9000(0.9000) \n","EVAL: [20/126] Loss: 0.6109(0.6499) \n","EVAL: [40/126] Loss: 0.6917(0.6489) \n","EVAL: [60/126] Loss: 0.6773(0.6513) \n","EVAL: [80/126] Loss: 0.6889(0.6585) \n","EVAL: [100/126] Loss: 0.6050(0.6633) \n","EVAL: [120/126] Loss: 0.7580(0.6584) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.6746 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6746 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.3988(0.6609) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6555  avg_val_loss: 0.6609\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6555  avg_val_loss: 0.6609\n","Epoch 1 - Score: 0.6746  Scores: [0.5916674027175239, 0.7574693092912509]\n","INFO:__main__:Epoch 1 - Score: 0.6746  Scores: [0.5916674027175239, 0.7574693092912509]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][460/644] Elapsed 5m 21s (remain 2m 7s) Loss: 0.4497(0.6503) Grad: 200949.3750  LR: 0.00001962  \n","Epoch: [1][480/644] Elapsed 5m 26s (remain 1m 50s) Loss: 0.3962(0.6453) Grad: 138465.1406  LR: 0.00001954  \n","Epoch: [1][500/644] Elapsed 5m 33s (remain 1m 35s) Loss: 0.5575(0.6379) Grad: 156530.9844  LR: 0.00001946  \n","Epoch: [1][520/644] Elapsed 5m 39s (remain 1m 20s) Loss: 0.3910(0.6341) Grad: 206816.9219  LR: 0.00001937  \n","Epoch: [1][540/644] Elapsed 5m 47s (remain 1m 6s) Loss: 0.4740(0.6285) Grad: 212093.9062  LR: 0.00001927  \n","Epoch: [1][560/644] Elapsed 5m 54s (remain 0m 52s) Loss: 0.5464(0.6226) Grad: 279676.2500  LR: 0.00001917  \n","Epoch: [1][580/644] Elapsed 6m 0s (remain 0m 39s) Loss: 0.6767(0.6181) Grad: 128851.4922  LR: 0.00001905  \n","Epoch: [1][600/644] Elapsed 6m 6s (remain 0m 26s) Loss: 0.2893(0.6126) Grad: 185976.8594  LR: 0.00001894  \n","EVAL: [0/126] Loss: 0.8751(0.8751) \n","EVAL: [20/126] Loss: 0.5932(0.6366) \n","EVAL: [40/126] Loss: 0.6965(0.6379) \n","EVAL: [60/126] Loss: 0.6524(0.6382) \n","EVAL: [80/126] Loss: 0.6871(0.6455) \n","EVAL: [100/126] Loss: 0.5636(0.6508) \n","EVAL: [120/126] Loss: 0.6936(0.6455) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.6635 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6635 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.3336(0.6480) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6126  avg_val_loss: 0.6480\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6126  avg_val_loss: 0.6480\n","Epoch 1 - Score: 0.6635  Scores: [0.5379346931412189, 0.7890929141731438]\n","INFO:__main__:Epoch 1 - Score: 0.6635  Scores: [0.5379346931412189, 0.7890929141731438]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][620/644] Elapsed 7m 9s (remain 0m 15s) Loss: 0.4717(0.6086) Grad: 130746.8438  LR: 0.00001881  \n","Epoch: [1][640/644] Elapsed 7m 14s (remain 0m 2s) Loss: 0.9365(0.6065) Grad: 166043.4062  LR: 0.00001868  \n","Epoch: [1][643/644] Elapsed 7m 15s (remain 0m 0s) Loss: 0.4865(0.6059) Grad: 219392.2344  LR: 0.00001866  \n","EVAL: [0/126] Loss: 1.0235(1.0235) \n","EVAL: [20/126] Loss: 0.7382(0.7809) \n","EVAL: [40/126] Loss: 0.8173(0.7751) \n","EVAL: [60/126] Loss: 0.7871(0.7787) \n","EVAL: [80/126] Loss: 0.8209(0.7844) \n","EVAL: [100/126] Loss: 0.7535(0.7906) \n","EVAL: [120/126] Loss: 0.7942(0.7865) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6059  avg_val_loss: 0.7891\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6059  avg_val_loss: 0.7891\n","Epoch 1 - Score: 0.8034  Scores: [0.7427957561518197, 0.8640835581598195]\n","INFO:__main__:Epoch 1 - Score: 0.8034  Scores: [0.7427957561518197, 0.8640835581598195]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.5110(0.7891) \n","Epoch: [2][0/644] Elapsed 0m 0s (remain 5m 17s) Loss: 0.6724(0.6724) Grad: 278332.2812  LR: 0.00001865  \n","Epoch: [2][20/644] Elapsed 0m 5s (remain 2m 56s) Loss: 0.4696(0.4895) Grad: 250184.3438  LR: 0.00001851  \n","Epoch: [2][40/644] Elapsed 0m 11s (remain 2m 55s) Loss: 0.5207(0.4803) Grad: 149277.0156  LR: 0.00001837  \n","Epoch: [2][60/644] Elapsed 0m 16s (remain 2m 41s) Loss: 0.4995(0.4737) Grad: 138273.0625  LR: 0.00001822  \n","Epoch: [2][80/644] Elapsed 0m 22s (remain 2m 36s) Loss: 0.3552(0.4753) Grad: 301491.0938  LR: 0.00001806  \n","Epoch: [2][100/644] Elapsed 0m 28s (remain 2m 32s) Loss: 0.5497(0.4839) Grad: 176653.7188  LR: 0.00001790  \n","Epoch: [2][120/644] Elapsed 0m 33s (remain 2m 25s) Loss: 0.3589(0.4854) Grad: 171819.6250  LR: 0.00001773  \n","Epoch: [2][140/644] Elapsed 0m 39s (remain 2m 20s) Loss: 0.4413(0.4769) Grad: 121422.9062  LR: 0.00001755  \n","EVAL: [0/126] Loss: 0.9050(0.9050) \n","EVAL: [20/126] Loss: 0.5862(0.6427) \n","EVAL: [40/126] Loss: 0.6720(0.6405) \n","EVAL: [60/126] Loss: 0.6209(0.6438) \n","EVAL: [80/126] Loss: 0.7045(0.6521) \n","EVAL: [100/126] Loss: 0.5493(0.6573) \n","EVAL: [120/126] Loss: 0.6781(0.6518) \n","EVAL: [125/126] Loss: 0.3491(0.6545) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4713  avg_val_loss: 0.6545\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4713  avg_val_loss: 0.6545\n","Epoch 2 - Score: 0.6706  Scores: [0.5534654463961347, 0.7877261355815686]\n","INFO:__main__:Epoch 2 - Score: 0.6706  Scores: [0.5534654463961347, 0.7877261355815686]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][160/644] Elapsed 1m 34s (remain 4m 43s) Loss: 0.4897(0.4704) Grad: 268606.2812  LR: 0.00001737  \n","Epoch: [2][180/644] Elapsed 1m 39s (remain 4m 15s) Loss: 0.2903(0.4671) Grad: 191797.3906  LR: 0.00001719  \n","Epoch: [2][200/644] Elapsed 1m 45s (remain 3m 51s) Loss: 0.3851(0.4638) Grad: 146775.7188  LR: 0.00001700  \n","Epoch: [2][220/644] Elapsed 1m 50s (remain 3m 32s) Loss: 0.5021(0.4671) Grad: 175602.7031  LR: 0.00001680  \n","Epoch: [2][240/644] Elapsed 1m 55s (remain 3m 13s) Loss: 0.4389(0.4676) Grad: 105796.0781  LR: 0.00001660  \n","Epoch: [2][260/644] Elapsed 2m 1s (remain 2m 57s) Loss: 0.3610(0.4644) Grad: 153484.9844  LR: 0.00001639  \n","Epoch: [2][280/644] Elapsed 2m 6s (remain 2m 43s) Loss: 0.5480(0.4596) Grad: 205072.1562  LR: 0.00001618  \n","Epoch: [2][300/644] Elapsed 2m 11s (remain 2m 29s) Loss: 0.5035(0.4594) Grad: 169828.5000  LR: 0.00001597  \n","EVAL: [0/126] Loss: 0.8744(0.8744) \n","EVAL: [20/126] Loss: 0.5349(0.6025) \n","EVAL: [40/126] Loss: 0.6497(0.6113) \n","EVAL: [60/126] Loss: 0.6112(0.6129) \n","EVAL: [80/126] Loss: 0.6157(0.6219) \n","EVAL: [100/126] Loss: 0.5266(0.6254) \n","EVAL: [120/126] Loss: 0.7198(0.6225) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Save Best Score: 0.6393 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.6393 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.4195(0.6253) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4594  avg_val_loss: 0.6253\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4594  avg_val_loss: 0.6253\n","Epoch 2 - Score: 0.6393  Scores: [0.5476821499364519, 0.7308481354734092]\n","INFO:__main__:Epoch 2 - Score: 0.6393  Scores: [0.5476821499364519, 0.7308481354734092]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][320/644] Elapsed 3m 15s (remain 3m 16s) Loss: 0.4892(0.4615) Grad: 334017.6562  LR: 0.00001575  \n","Epoch: [2][340/644] Elapsed 3m 22s (remain 2m 59s) Loss: 0.3187(0.4601) Grad: 171475.8750  LR: 0.00001553  \n","Epoch: [2][360/644] Elapsed 3m 29s (remain 2m 44s) Loss: 0.2036(0.4600) Grad: 123875.8281  LR: 0.00001530  \n","Epoch: [2][380/644] Elapsed 3m 36s (remain 2m 29s) Loss: 0.4152(0.4595) Grad: 146060.6562  LR: 0.00001507  \n","Epoch: [2][400/644] Elapsed 3m 43s (remain 2m 15s) Loss: 0.4215(0.4596) Grad: 233781.6562  LR: 0.00001483  \n","Epoch: [2][420/644] Elapsed 3m 49s (remain 2m 1s) Loss: 0.3139(0.4573) Grad: 86421.1562  LR: 0.00001459  \n","Epoch: [2][440/644] Elapsed 3m 55s (remain 1m 48s) Loss: 0.4245(0.4555) Grad: 105242.4219  LR: 0.00001435  \n","EVAL: [0/126] Loss: 0.8853(0.8853) \n","EVAL: [20/126] Loss: 0.5513(0.6167) \n","EVAL: [40/126] Loss: 0.6519(0.6205) \n","EVAL: [60/126] Loss: 0.6442(0.6255) \n","EVAL: [80/126] Loss: 0.6851(0.6371) \n","EVAL: [100/126] Loss: 0.5499(0.6439) \n","EVAL: [120/126] Loss: 0.7155(0.6389) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4552  avg_val_loss: 0.6427\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4552  avg_val_loss: 0.6427\n","Epoch 2 - Score: 0.6606  Scores: [0.5169565232167656, 0.8042010608040524]\n","INFO:__main__:Epoch 2 - Score: 0.6606  Scores: [0.5169565232167656, 0.8042010608040524]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.3465(0.6427) \n","Epoch: [2][460/644] Elapsed 4m 50s (remain 1m 55s) Loss: 0.7949(0.4548) Grad: 196447.7812  LR: 0.00001410  \n","Epoch: [2][480/644] Elapsed 4m 56s (remain 1m 40s) Loss: 0.4832(0.4553) Grad: 146946.9844  LR: 0.00001386  \n","Epoch: [2][500/644] Elapsed 5m 2s (remain 1m 26s) Loss: 0.4351(0.4535) Grad: 144308.2656  LR: 0.00001361  \n","Epoch: [2][520/644] Elapsed 5m 6s (remain 1m 12s) Loss: 0.3972(0.4507) Grad: 196463.2656  LR: 0.00001335  \n","Epoch: [2][540/644] Elapsed 5m 11s (remain 0m 59s) Loss: 0.4439(0.4512) Grad: 89986.3281  LR: 0.00001310  \n","Epoch: [2][560/644] Elapsed 5m 17s (remain 0m 46s) Loss: 0.2664(0.4500) Grad: 148754.2344  LR: 0.00001284  \n","Epoch: [2][580/644] Elapsed 5m 22s (remain 0m 35s) Loss: 0.4018(0.4497) Grad: 356174.5000  LR: 0.00001258  \n","Epoch: [2][600/644] Elapsed 5m 28s (remain 0m 23s) Loss: 0.2916(0.4502) Grad: 127771.4141  LR: 0.00001231  \n","EVAL: [0/126] Loss: 0.8866(0.8866) \n","EVAL: [20/126] Loss: 0.5868(0.6489) \n","EVAL: [40/126] Loss: 0.6839(0.6455) \n","EVAL: [60/126] Loss: 0.6788(0.6494) \n","EVAL: [80/126] Loss: 0.7231(0.6603) \n","EVAL: [100/126] Loss: 0.5972(0.6677) \n","EVAL: [120/126] Loss: 0.7511(0.6636) \n","EVAL: [125/126] Loss: 0.3530(0.6669) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4502  avg_val_loss: 0.6669\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4502  avg_val_loss: 0.6669\n","Epoch 2 - Score: 0.6834  Scores: [0.5325717604391035, 0.8341766637637938]\n","INFO:__main__:Epoch 2 - Score: 0.6834  Scores: [0.5325717604391035, 0.8341766637637938]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][620/644] Elapsed 6m 24s (remain 0m 14s) Loss: 0.4375(0.4504) Grad: 261261.4531  LR: 0.00001205  \n","Epoch: [2][640/644] Elapsed 6m 29s (remain 0m 1s) Loss: 0.3930(0.4485) Grad: 210251.4062  LR: 0.00001178  \n","Epoch: [2][643/644] Elapsed 6m 29s (remain 0m 0s) Loss: 0.3606(0.4480) Grad: 205165.3750  LR: 0.00001174  \n","EVAL: [0/126] Loss: 0.8328(0.8328) \n","EVAL: [20/126] Loss: 0.5343(0.5926) \n","EVAL: [40/126] Loss: 0.6719(0.5964) \n","EVAL: [60/126] Loss: 0.6021(0.5959) \n","EVAL: [80/126] Loss: 0.6067(0.6033) \n","EVAL: [100/126] Loss: 0.5334(0.6095) \n","EVAL: [120/126] Loss: 0.6910(0.6080) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Save Best Score: 0.6240 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.6240 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.3636(0.6101) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4480  avg_val_loss: 0.6101\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4480  avg_val_loss: 0.6101\n","Epoch 2 - Score: 0.6240  Scores: [0.5202253493055398, 0.727857144998899]\n","INFO:__main__:Epoch 2 - Score: 0.6240  Scores: [0.5202253493055398, 0.727857144998899]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/644] Elapsed 0m 0s (remain 5m 40s) Loss: 0.2273(0.2273) Grad: 470721.4375  LR: 0.00001173  \n","Epoch: [3][20/644] Elapsed 0m 5s (remain 2m 57s) Loss: 0.5040(0.3934) Grad: 101481.6797  LR: 0.00001146  \n","Epoch: [3][40/644] Elapsed 0m 11s (remain 2m 54s) Loss: 0.5037(0.4169) Grad: 154271.9375  LR: 0.00001120  \n","Epoch: [3][60/644] Elapsed 0m 18s (remain 3m 1s) Loss: 0.2836(0.4040) Grad: 119447.9844  LR: 0.00001093  \n","Epoch: [3][80/644] Elapsed 0m 24s (remain 2m 49s) Loss: 0.4698(0.4039) Grad: 197460.7500  LR: 0.00001066  \n","Epoch: [3][100/644] Elapsed 0m 31s (remain 2m 51s) Loss: 0.3586(0.4049) Grad: 124253.1016  LR: 0.00001039  \n","Epoch: [3][120/644] Elapsed 0m 37s (remain 2m 41s) Loss: 0.5016(0.4074) Grad: 130812.6250  LR: 0.00001012  \n","Epoch: [3][140/644] Elapsed 0m 42s (remain 2m 31s) Loss: 0.4042(0.4063) Grad: 175054.9219  LR: 0.00000984  \n","EVAL: [0/126] Loss: 0.8442(0.8442) \n","EVAL: [20/126] Loss: 0.5144(0.5873) \n","EVAL: [40/126] Loss: 0.6306(0.5886) \n","EVAL: [60/126] Loss: 0.5920(0.5918) \n","EVAL: [80/126] Loss: 0.6125(0.6017) \n","EVAL: [100/126] Loss: 0.5106(0.6077) \n","EVAL: [120/126] Loss: 0.6732(0.6041) \n","EVAL: [125/126] Loss: 0.3338(0.6074) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Save Best Score: 0.6240 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.6240 Model\n","Epoch 3 - avg_train_loss: 0.4057  avg_val_loss: 0.6074\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4057  avg_val_loss: 0.6074\n","Epoch 3 - Score: 0.6240  Scores: [0.500910605875325, 0.7470747147430271]\n","INFO:__main__:Epoch 3 - Score: 0.6240  Scores: [0.500910605875325, 0.7470747147430271]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][160/644] Elapsed 1m 45s (remain 5m 17s) Loss: 0.4629(0.4012) Grad: 135013.8438  LR: 0.00000957  \n","Epoch: [3][180/644] Elapsed 1m 52s (remain 4m 47s) Loss: 0.5559(0.3980) Grad: 194367.8906  LR: 0.00000930  \n","Epoch: [3][200/644] Elapsed 1m 58s (remain 4m 21s) Loss: 0.4387(0.3950) Grad: 116969.4766  LR: 0.00000903  \n","Epoch: [3][220/644] Elapsed 2m 5s (remain 4m 0s) Loss: 0.2924(0.3920) Grad: 103425.1484  LR: 0.00000876  \n","Epoch: [3][240/644] Elapsed 2m 12s (remain 3m 41s) Loss: 0.4652(0.3901) Grad: 223707.1406  LR: 0.00000850  \n","Epoch: [3][260/644] Elapsed 2m 17s (remain 3m 22s) Loss: 0.4586(0.3875) Grad: 152684.1094  LR: 0.00000823  \n","Epoch: [3][280/644] Elapsed 2m 25s (remain 3m 7s) Loss: 0.1926(0.3892) Grad: 166573.9844  LR: 0.00000796  \n","Epoch: [3][300/644] Elapsed 2m 30s (remain 2m 51s) Loss: 0.4968(0.3890) Grad: 134518.4219  LR: 0.00000770  \n","EVAL: [0/126] Loss: 0.8630(0.8630) \n","EVAL: [20/126] Loss: 0.5729(0.6221) \n","EVAL: [40/126] Loss: 0.6748(0.6259) \n","EVAL: [60/126] Loss: 0.6245(0.6281) \n","EVAL: [80/126] Loss: 0.6898(0.6381) \n","EVAL: [100/126] Loss: 0.5629(0.6450) \n","EVAL: [120/126] Loss: 0.6799(0.6423) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3890  avg_val_loss: 0.6453\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3890  avg_val_loss: 0.6453\n","Epoch 3 - Score: 0.6626  Scores: [0.5088533111542981, 0.8164421095183444]\n","INFO:__main__:Epoch 3 - Score: 0.6626  Scores: [0.5088533111542981, 0.8164421095183444]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.3436(0.6453) \n","Epoch: [3][320/644] Elapsed 3m 24s (remain 3m 25s) Loss: 0.4303(0.3887) Grad: 189668.6406  LR: 0.00000744  \n","Epoch: [3][340/644] Elapsed 3m 30s (remain 3m 6s) Loss: 0.3441(0.3883) Grad: 97379.3672  LR: 0.00000718  \n","Epoch: [3][360/644] Elapsed 3m 35s (remain 2m 49s) Loss: 0.4140(0.3887) Grad: 144713.8594  LR: 0.00000692  \n","Epoch: [3][380/644] Elapsed 3m 40s (remain 2m 32s) Loss: 0.3366(0.3855) Grad: 183825.1094  LR: 0.00000666  \n","Epoch: [3][400/644] Elapsed 3m 46s (remain 2m 17s) Loss: 0.3745(0.3847) Grad: 148548.4219  LR: 0.00000641  \n","Epoch: [3][420/644] Elapsed 3m 52s (remain 2m 2s) Loss: 0.2244(0.3841) Grad: 151607.5000  LR: 0.00000616  \n","Epoch: [3][440/644] Elapsed 3m 57s (remain 1m 49s) Loss: 0.4928(0.3821) Grad: 216096.1094  LR: 0.00000591  \n","EVAL: [0/126] Loss: 0.9136(0.9136) \n","EVAL: [20/126] Loss: 0.5764(0.6356) \n","EVAL: [40/126] Loss: 0.6724(0.6372) \n","EVAL: [60/126] Loss: 0.6415(0.6418) \n","EVAL: [80/126] Loss: 0.7118(0.6541) \n","EVAL: [100/126] Loss: 0.5648(0.6631) \n","EVAL: [120/126] Loss: 0.7250(0.6584) \n","EVAL: [125/126] Loss: 0.3763(0.6628) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3821  avg_val_loss: 0.6628\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3821  avg_val_loss: 0.6628\n","Epoch 3 - Score: 0.6826  Scores: [0.5001234004737923, 0.8650570745727458]\n","INFO:__main__:Epoch 3 - Score: 0.6826  Scores: [0.5001234004737923, 0.8650570745727458]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][460/644] Elapsed 4m 52s (remain 1m 56s) Loss: 0.4532(0.3834) Grad: 233002.2500  LR: 0.00000566  \n","Epoch: [3][480/644] Elapsed 4m 57s (remain 1m 40s) Loss: 0.4454(0.3825) Grad: 178108.6250  LR: 0.00000542  \n","Epoch: [3][500/644] Elapsed 5m 2s (remain 1m 26s) Loss: 0.3461(0.3824) Grad: 107764.1172  LR: 0.00000518  \n","Epoch: [3][520/644] Elapsed 5m 8s (remain 1m 12s) Loss: 0.3272(0.3824) Grad: 191048.6562  LR: 0.00000495  \n","Epoch: [3][540/644] Elapsed 5m 14s (remain 0m 59s) Loss: 0.5466(0.3825) Grad: 198112.0312  LR: 0.00000471  \n","Epoch: [3][560/644] Elapsed 5m 19s (remain 0m 47s) Loss: 0.4100(0.3814) Grad: 209209.2969  LR: 0.00000449  \n","Epoch: [3][580/644] Elapsed 5m 25s (remain 0m 35s) Loss: 0.3205(0.3807) Grad: 144787.9219  LR: 0.00000426  \n","Epoch: [3][600/644] Elapsed 5m 30s (remain 0m 23s) Loss: 0.4776(0.3804) Grad: 135097.3281  LR: 0.00000404  \n","EVAL: [0/126] Loss: 0.9130(0.9130) \n","EVAL: [20/126] Loss: 0.5774(0.6340) \n","EVAL: [40/126] Loss: 0.6714(0.6361) \n","EVAL: [60/126] Loss: 0.6374(0.6390) \n","EVAL: [80/126] Loss: 0.7046(0.6484) \n","EVAL: [100/126] Loss: 0.5722(0.6554) \n","EVAL: [120/126] Loss: 0.7005(0.6522) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3804  avg_val_loss: 0.6555\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3804  avg_val_loss: 0.6555\n","Epoch 3 - Score: 0.6725  Scores: [0.5240496618069295, 0.8209164666767678]\n","INFO:__main__:Epoch 3 - Score: 0.6725  Scores: [0.5240496618069295, 0.8209164666767678]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.3263(0.6555) \n","Epoch: [3][620/644] Elapsed 6m 25s (remain 0m 14s) Loss: 0.3464(0.3810) Grad: 162427.5781  LR: 0.00000383  \n","Epoch: [3][640/644] Elapsed 6m 30s (remain 0m 1s) Loss: 0.3891(0.3803) Grad: 126692.9766  LR: 0.00000362  \n","Epoch: [3][643/644] Elapsed 6m 31s (remain 0m 0s) Loss: 0.3865(0.3798) Grad: 162131.6719  LR: 0.00000359  \n","EVAL: [0/126] Loss: 0.9002(0.9002) \n","EVAL: [20/126] Loss: 0.5310(0.5993) \n","EVAL: [40/126] Loss: 0.6265(0.6026) \n","EVAL: [60/126] Loss: 0.5967(0.6052) \n","EVAL: [80/126] Loss: 0.6605(0.6143) \n","EVAL: [100/126] Loss: 0.5251(0.6201) \n","EVAL: [120/126] Loss: 0.6720(0.6168) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3798  avg_val_loss: 0.6198\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3798  avg_val_loss: 0.6198\n","Epoch 3 - Score: 0.6370  Scores: [0.5064597010406201, 0.7674587478276101]\n","INFO:__main__:Epoch 3 - Score: 0.6370  Scores: [0.5064597010406201, 0.7674587478276101]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.3258(0.6198) \n","Epoch: [4][0/644] Elapsed 0m 0s (remain 5m 34s) Loss: 0.4280(0.4280) Grad: 402150.4062  LR: 0.00000358  \n","Epoch: [4][20/644] Elapsed 0m 5s (remain 2m 38s) Loss: 0.2260(0.3479) Grad: 371091.1562  LR: 0.00000337  \n","Epoch: [4][40/644] Elapsed 0m 11s (remain 2m 50s) Loss: 0.3672(0.3196) Grad: 115652.3594  LR: 0.00000317  \n","Epoch: [4][60/644] Elapsed 0m 16s (remain 2m 36s) Loss: 0.2340(0.3152) Grad: 179772.2500  LR: 0.00000297  \n","Epoch: [4][80/644] Elapsed 0m 21s (remain 2m 27s) Loss: 0.4506(0.3185) Grad: 131153.3125  LR: 0.00000278  \n","Epoch: [4][100/644] Elapsed 0m 27s (remain 2m 27s) Loss: 0.3202(0.3204) Grad: 118387.9609  LR: 0.00000260  \n","Epoch: [4][120/644] Elapsed 0m 32s (remain 2m 20s) Loss: 0.3426(0.3217) Grad: 177536.8750  LR: 0.00000242  \n","Epoch: [4][140/644] Elapsed 0m 37s (remain 2m 12s) Loss: 0.4156(0.3230) Grad: 170061.6562  LR: 0.00000225  \n","EVAL: [0/126] Loss: 0.8963(0.8963) \n","EVAL: [20/126] Loss: 0.5494(0.6150) \n","EVAL: [40/126] Loss: 0.6593(0.6193) \n","EVAL: [60/126] Loss: 0.6098(0.6221) \n","EVAL: [80/126] Loss: 0.6817(0.6324) \n","EVAL: [100/126] Loss: 0.5496(0.6395) \n","EVAL: [120/126] Loss: 0.6785(0.6364) \n","EVAL: [125/126] Loss: 0.3339(0.6399) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3216  avg_val_loss: 0.6399\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3216  avg_val_loss: 0.6399\n","Epoch 4 - Score: 0.6577  Scores: [0.5079750266077823, 0.8075207334421656]\n","INFO:__main__:Epoch 4 - Score: 0.6577  Scores: [0.5079750266077823, 0.8075207334421656]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][160/644] Elapsed 1m 32s (remain 4m 36s) Loss: 0.3037(0.3202) Grad: 151549.5156  LR: 0.00000208  \n","Epoch: [4][180/644] Elapsed 1m 37s (remain 4m 8s) Loss: 0.2462(0.3199) Grad: 116890.8125  LR: 0.00000192  \n","Epoch: [4][200/644] Elapsed 1m 42s (remain 3m 45s) Loss: 0.3508(0.3212) Grad: 255915.4062  LR: 0.00000176  \n","Epoch: [4][220/644] Elapsed 1m 48s (remain 3m 27s) Loss: 0.3785(0.3232) Grad: 129130.0703  LR: 0.00000161  \n","Epoch: [4][240/644] Elapsed 1m 53s (remain 3m 9s) Loss: 0.3577(0.3247) Grad: 171348.3438  LR: 0.00000147  \n","Epoch: [4][260/644] Elapsed 1m 58s (remain 2m 53s) Loss: 0.2718(0.3246) Grad: 206861.1719  LR: 0.00000133  \n","Epoch: [4][280/644] Elapsed 2m 4s (remain 2m 40s) Loss: 0.2985(0.3237) Grad: 147276.4219  LR: 0.00000120  \n","Epoch: [4][300/644] Elapsed 2m 9s (remain 2m 27s) Loss: 0.3250(0.3245) Grad: 253012.9688  LR: 0.00000107  \n","EVAL: [0/126] Loss: 0.9068(0.9068) \n","EVAL: [20/126] Loss: 0.5626(0.6250) \n","EVAL: [40/126] Loss: 0.6739(0.6304) \n","EVAL: [60/126] Loss: 0.6191(0.6328) \n","EVAL: [80/126] Loss: 0.6948(0.6427) \n","EVAL: [100/126] Loss: 0.5648(0.6498) \n","EVAL: [120/126] Loss: 0.6807(0.6469) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3245  avg_val_loss: 0.6503\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3245  avg_val_loss: 0.6503\n","Epoch 4 - Score: 0.6682  Scores: [0.5079637423313558, 0.8284540324753071]\n","INFO:__main__:Epoch 4 - Score: 0.6682  Scores: [0.5079637423313558, 0.8284540324753071]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.3276(0.6503) \n","Epoch: [4][320/644] Elapsed 3m 4s (remain 3m 5s) Loss: 0.2494(0.3232) Grad: 144379.3125  LR: 0.00000095  \n","Epoch: [4][340/644] Elapsed 3m 9s (remain 2m 48s) Loss: 0.2118(0.3230) Grad: 167812.6406  LR: 0.00000084  \n","Epoch: [4][360/644] Elapsed 3m 14s (remain 2m 32s) Loss: 0.2608(0.3228) Grad: 99971.0547  LR: 0.00000073  \n","Epoch: [4][380/644] Elapsed 3m 20s (remain 2m 18s) Loss: 0.3001(0.3226) Grad: 118594.2188  LR: 0.00000064  \n","Epoch: [4][400/644] Elapsed 3m 25s (remain 2m 4s) Loss: 0.4296(0.3219) Grad: 248918.2344  LR: 0.00000054  \n","Epoch: [4][420/644] Elapsed 3m 30s (remain 1m 51s) Loss: 0.3368(0.3202) Grad: 170361.7656  LR: 0.00000046  \n","Epoch: [4][440/644] Elapsed 3m 36s (remain 1m 39s) Loss: 0.3443(0.3194) Grad: 146586.6719  LR: 0.00000038  \n","EVAL: [0/126] Loss: 0.8950(0.8950) \n","EVAL: [20/126] Loss: 0.5474(0.6145) \n","EVAL: [40/126] Loss: 0.6652(0.6197) \n","EVAL: [60/126] Loss: 0.6082(0.6220) \n","EVAL: [80/126] Loss: 0.6790(0.6318) \n","EVAL: [100/126] Loss: 0.5566(0.6388) \n","EVAL: [120/126] Loss: 0.6814(0.6361) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3202  avg_val_loss: 0.6394\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3202  avg_val_loss: 0.6394\n","Epoch 4 - Score: 0.6569  Scores: [0.5058966803104886, 0.8078853958786153]\n","INFO:__main__:Epoch 4 - Score: 0.6569  Scores: [0.5058966803104886, 0.8078853958786153]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Loss: 0.3219(0.6394) \n","Epoch: [4][460/644] Elapsed 4m 30s (remain 1m 47s) Loss: 0.4470(0.3197) Grad: 77983.2500  LR: 0.00000031  \n","Epoch: [4][480/644] Elapsed 4m 35s (remain 1m 33s) Loss: 0.3271(0.3185) Grad: 87095.3906  LR: 0.00000025  \n","Epoch: [4][500/644] Elapsed 4m 42s (remain 1m 20s) Loss: 0.2740(0.3185) Grad: 105069.0391  LR: 0.00000019  \n","Epoch: [4][520/644] Elapsed 4m 48s (remain 1m 8s) Loss: 0.3510(0.3177) Grad: 57797.2695  LR: 0.00000014  \n","Epoch: [4][540/644] Elapsed 4m 54s (remain 0m 56s) Loss: 0.2567(0.3170) Grad: 104474.2734  LR: 0.00000010  \n","Epoch: [4][560/644] Elapsed 4m 59s (remain 0m 44s) Loss: 0.3681(0.3170) Grad: 84193.3438  LR: 0.00000007  \n","Epoch: [4][580/644] Elapsed 5m 4s (remain 0m 33s) Loss: 0.4419(0.3176) Grad: 112914.7344  LR: 0.00000004  \n","Epoch: [4][600/644] Elapsed 5m 9s (remain 0m 22s) Loss: 0.4620(0.3171) Grad: 62149.9922  LR: 0.00000002  \n","EVAL: [0/126] Loss: 0.8981(0.8981) \n","EVAL: [20/126] Loss: 0.5546(0.6229) \n","EVAL: [40/126] Loss: 0.6700(0.6265) \n","EVAL: [60/126] Loss: 0.6181(0.6294) \n","EVAL: [80/126] Loss: 0.6931(0.6396) \n","EVAL: [100/126] Loss: 0.5635(0.6470) \n","EVAL: [120/126] Loss: 0.6906(0.6437) \n","EVAL: [125/126] Loss: 0.3306(0.6471) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3171  avg_val_loss: 0.6471\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3171  avg_val_loss: 0.6471\n","Epoch 4 - Score: 0.6649  Scores: [0.5034612065339279, 0.8263858019754161]\n","INFO:__main__:Epoch 4 - Score: 0.6649  Scores: [0.5034612065339279, 0.8263858019754161]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][620/644] Elapsed 6m 4s (remain 0m 13s) Loss: 0.4378(0.3179) Grad: 103890.6719  LR: 0.00000001  \n","Epoch: [4][640/644] Elapsed 6m 9s (remain 0m 1s) Loss: 0.3585(0.3181) Grad: 98777.0938  LR: 0.00000000  \n","Epoch: [4][643/644] Elapsed 6m 10s (remain 0m 0s) Loss: 0.2625(0.3181) Grad: 57529.7305  LR: 0.00000000  \n","EVAL: [0/126] Loss: 0.8980(0.8980) \n","EVAL: [20/126] Loss: 0.5543(0.6226) \n","EVAL: [40/126] Loss: 0.6697(0.6262) \n","EVAL: [60/126] Loss: 0.6178(0.6292) \n","EVAL: [80/126] Loss: 0.6927(0.6393) \n","EVAL: [100/126] Loss: 0.5632(0.6467) \n","EVAL: [120/126] Loss: 0.6905(0.6434) \n","EVAL: [125/126] Loss: 0.3305(0.6468) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3181  avg_val_loss: 0.6468\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3181  avg_val_loss: 0.6468\n","Epoch 4 - Score: 0.6646  Scores: [0.5034708762384914, 0.8258184180747492]\n","INFO:__main__:Epoch 4 - Score: 0.6646  Scores: [0.5034708762384914, 0.8258184180747492]\n","========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.6240  Scores: [0.500910605875325, 0.7470747147430271]\n","INFO:__main__:Score: 0.6240  Scores: [0.500910605875325, 0.7470747147430271]\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/646] Elapsed 0m 0s (remain 5m 44s) Loss: 1.0962(1.0962) Grad: 47916.9062  LR: 0.00000008  \n","Epoch: [1][20/646] Elapsed 0m 6s (remain 3m 26s) Loss: 1.2837(1.0538) Grad: 78961.2891  LR: 0.00000163  \n","Epoch: [1][40/646] Elapsed 0m 12s (remain 3m 0s) Loss: 1.6603(1.0511) Grad: 98001.7422  LR: 0.00000318  \n","Epoch: [1][60/646] Elapsed 0m 17s (remain 2m 51s) Loss: 0.8157(1.0731) Grad: 33516.6680  LR: 0.00000473  \n","Epoch: [1][80/646] Elapsed 0m 24s (remain 2m 47s) Loss: 1.2855(1.0652) Grad: 88941.4453  LR: 0.00000628  \n","Epoch: [1][100/646] Elapsed 0m 28s (remain 2m 35s) Loss: 0.7740(1.0236) Grad: 142109.5781  LR: 0.00000783  \n","Epoch: [1][120/646] Elapsed 0m 34s (remain 2m 30s) Loss: 1.0339(0.9793) Grad: 126441.9297  LR: 0.00000938  \n","Epoch: [1][140/646] Elapsed 0m 40s (remain 2m 26s) Loss: 0.7559(0.9359) Grad: 145182.1250  LR: 0.00001093  \n","EVAL: [0/125] Loss: 0.8294(0.8294) \n","EVAL: [20/125] Loss: 0.6167(0.6496) \n","EVAL: [40/125] Loss: 0.7366(0.6669) \n","EVAL: [60/125] Loss: 0.6140(0.6492) \n","EVAL: [80/125] Loss: 0.5260(0.6495) \n","EVAL: [100/125] Loss: 0.8926(0.6427) \n","EVAL: [120/125] Loss: 0.6963(0.6448) \n","EVAL: [124/125] Loss: 0.7647(0.6446) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.6557 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6557 Model\n","Epoch 1 - avg_train_loss: 0.9148  avg_val_loss: 0.6446\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.9148  avg_val_loss: 0.6446\n","Epoch 1 - Score: 0.6557  Scores: [0.5886382048350085, 0.7227743773237063]\n","INFO:__main__:Epoch 1 - Score: 0.6557  Scores: [0.5886382048350085, 0.7227743773237063]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][160/646] Elapsed 1m 37s (remain 4m 52s) Loss: 0.5670(0.8991) Grad: 152394.2812  LR: 0.00001248  \n","Epoch: [1][180/646] Elapsed 1m 43s (remain 4m 26s) Loss: 0.6746(0.8715) Grad: 70379.7891  LR: 0.00001403  \n","Epoch: [1][200/646] Elapsed 1m 50s (remain 4m 3s) Loss: 0.5211(0.8421) Grad: 80435.0781  LR: 0.00001558  \n","Epoch: [1][220/646] Elapsed 1m 57s (remain 3m 45s) Loss: 0.5829(0.8144) Grad: 108135.8672  LR: 0.00001713  \n","Epoch: [1][240/646] Elapsed 2m 4s (remain 3m 29s) Loss: 0.6666(0.7978) Grad: 76557.0781  LR: 0.00001868  \n","Epoch: [1][260/646] Elapsed 2m 10s (remain 3m 12s) Loss: 0.4963(0.7865) Grad: 55098.8203  LR: 0.00002000  \n","Epoch: [1][280/646] Elapsed 2m 17s (remain 2m 58s) Loss: 0.6697(0.7725) Grad: 71810.0781  LR: 0.00002000  \n","Epoch: [1][300/646] Elapsed 2m 23s (remain 2m 43s) Loss: 0.5706(0.7552) Grad: 125539.5469  LR: 0.00001998  \n","EVAL: [0/125] Loss: 0.8444(0.8444) \n","EVAL: [20/125] Loss: 0.5404(0.6135) \n","EVAL: [40/125] Loss: 0.6112(0.6184) \n","EVAL: [60/125] Loss: 0.5469(0.6040) \n","EVAL: [80/125] Loss: 0.5286(0.6058) \n","EVAL: [100/125] Loss: 0.7568(0.5974) \n","EVAL: [120/125] Loss: 0.6297(0.5998) \n","EVAL: [124/125] Loss: 0.7238(0.6007) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.6121 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6121 Model\n","Epoch 1 - avg_train_loss: 0.7552  avg_val_loss: 0.6007\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.7552  avg_val_loss: 0.6007\n","Epoch 1 - Score: 0.6121  Scores: [0.624001513153704, 0.6001852025165643]\n","INFO:__main__:Epoch 1 - Score: 0.6121  Scores: [0.624001513153704, 0.6001852025165643]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][320/646] Elapsed 3m 19s (remain 3m 21s) Loss: 0.5761(0.7468) Grad: 60163.6094  LR: 0.00001996  \n","Epoch: [1][340/646] Elapsed 3m 27s (remain 3m 5s) Loss: 0.2853(0.7335) Grad: 81945.2500  LR: 0.00001994  \n","Epoch: [1][360/646] Elapsed 3m 34s (remain 2m 49s) Loss: 0.8642(0.7279) Grad: 142182.9062  LR: 0.00001990  \n","Epoch: [1][380/646] Elapsed 3m 42s (remain 2m 34s) Loss: 0.3910(0.7206) Grad: 95507.7812  LR: 0.00001986  \n","Epoch: [1][400/646] Elapsed 3m 48s (remain 2m 19s) Loss: 0.5011(0.7131) Grad: 77260.2734  LR: 0.00001981  \n","Epoch: [1][420/646] Elapsed 3m 54s (remain 2m 5s) Loss: 0.6568(0.7066) Grad: 68078.5391  LR: 0.00001976  \n","Epoch: [1][440/646] Elapsed 4m 0s (remain 1m 51s) Loss: 0.4703(0.7006) Grad: 89752.0078  LR: 0.00001970  \n","EVAL: [0/125] Loss: 0.7205(0.7205) \n","EVAL: [20/125] Loss: 0.5894(0.5125) \n","EVAL: [40/125] Loss: 0.5855(0.5590) \n","EVAL: [60/125] Loss: 0.5989(0.5411) \n","EVAL: [80/125] Loss: 0.4057(0.5329) \n","EVAL: [100/125] Loss: 0.6081(0.5212) \n","EVAL: [120/125] Loss: 0.4465(0.5249) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.5374 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5374 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.5282(0.5239) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6972  avg_val_loss: 0.5239\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6972  avg_val_loss: 0.5239\n","Epoch 1 - Score: 0.5374  Scores: [0.455906037936632, 0.618852152160471]\n","INFO:__main__:Epoch 1 - Score: 0.5374  Scores: [0.455906037936632, 0.618852152160471]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][460/646] Elapsed 5m 0s (remain 2m 0s) Loss: 0.4948(0.6941) Grad: 94346.6172  LR: 0.00001963  \n","Epoch: [1][480/646] Elapsed 5m 6s (remain 1m 45s) Loss: 0.7969(0.6880) Grad: 72203.4453  LR: 0.00001955  \n","Epoch: [1][500/646] Elapsed 5m 13s (remain 1m 30s) Loss: 0.5343(0.6806) Grad: 91829.5000  LR: 0.00001947  \n","Epoch: [1][520/646] Elapsed 5m 20s (remain 1m 16s) Loss: 0.5269(0.6745) Grad: 141303.1719  LR: 0.00001938  \n","Epoch: [1][540/646] Elapsed 5m 27s (remain 1m 3s) Loss: 0.5199(0.6682) Grad: 53925.6016  LR: 0.00001928  \n","Epoch: [1][560/646] Elapsed 5m 34s (remain 0m 50s) Loss: 0.6751(0.6625) Grad: 70926.7969  LR: 0.00001917  \n","Epoch: [1][580/646] Elapsed 5m 39s (remain 0m 37s) Loss: 0.4018(0.6588) Grad: 51239.4766  LR: 0.00001906  \n","Epoch: [1][600/646] Elapsed 5m 44s (remain 0m 25s) Loss: 0.6027(0.6540) Grad: 77705.4531  LR: 0.00001895  \n","EVAL: [0/125] Loss: 0.7392(0.7392) \n","EVAL: [20/125] Loss: 0.4881(0.5187) \n","EVAL: [40/125] Loss: 0.5481(0.5412) \n","EVAL: [60/125] Loss: 0.5222(0.5249) \n","EVAL: [80/125] Loss: 0.4384(0.5224) \n","EVAL: [100/125] Loss: 0.6103(0.5125) \n","EVAL: [120/125] Loss: 0.5052(0.5171) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.5281 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5281 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.6019(0.5167) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6540  avg_val_loss: 0.5167\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6540  avg_val_loss: 0.5167\n","Epoch 1 - Score: 0.5281  Scores: [0.4885089334396162, 0.567701852213978]\n","INFO:__main__:Epoch 1 - Score: 0.5281  Scores: [0.4885089334396162, 0.567701852213978]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][620/646] Elapsed 6m 43s (remain 0m 16s) Loss: 0.4883(0.6492) Grad: 72952.7734  LR: 0.00001882  \n","Epoch: [1][640/646] Elapsed 6m 49s (remain 0m 3s) Loss: 0.4744(0.6442) Grad: 53018.6328  LR: 0.00001869  \n","Epoch: [1][645/646] Elapsed 6m 51s (remain 0m 0s) Loss: 0.4116(0.6433) Grad: 86240.8828  LR: 0.00001866  \n","EVAL: [0/125] Loss: 0.6464(0.6464) \n","EVAL: [20/125] Loss: 0.5004(0.4887) \n","EVAL: [40/125] Loss: 0.5415(0.5196) \n","EVAL: [60/125] Loss: 0.5628(0.5045) \n","EVAL: [80/125] Loss: 0.3900(0.5010) \n","EVAL: [100/125] Loss: 0.5763(0.4912) \n","EVAL: [120/125] Loss: 0.4403(0.4947) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - Save Best Score: 0.5047 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5047 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.5380(0.4937) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6433  avg_val_loss: 0.4937\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6433  avg_val_loss: 0.4937\n","Epoch 1 - Score: 0.5047  Scores: [0.4467090605459824, 0.5626574941705766]\n","INFO:__main__:Epoch 1 - Score: 0.5047  Scores: [0.4467090605459824, 0.5626574941705766]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/646] Elapsed 0m 0s (remain 5m 53s) Loss: 0.4394(0.4394) Grad: 358165.5938  LR: 0.00001865  \n","Epoch: [2][20/646] Elapsed 0m 5s (remain 2m 39s) Loss: 0.4013(0.4735) Grad: 170311.3750  LR: 0.00001851  \n","Epoch: [2][40/646] Elapsed 0m 11s (remain 2m 56s) Loss: 0.6144(0.4591) Grad: 262518.2188  LR: 0.00001837  \n","Epoch: [2][60/646] Elapsed 0m 19s (remain 3m 5s) Loss: 0.4490(0.4593) Grad: 258470.2500  LR: 0.00001822  \n","Epoch: [2][80/646] Elapsed 0m 25s (remain 2m 59s) Loss: 0.2344(0.4690) Grad: 192557.5312  LR: 0.00001806  \n","Epoch: [2][100/646] Elapsed 0m 33s (remain 2m 59s) Loss: 0.2629(0.4664) Grad: 378235.7188  LR: 0.00001790  \n","Epoch: [2][120/646] Elapsed 0m 38s (remain 2m 47s) Loss: 0.4292(0.4573) Grad: 488521.1250  LR: 0.00001773  \n","Epoch: [2][140/646] Elapsed 0m 44s (remain 2m 39s) Loss: 0.4581(0.4592) Grad: 93417.2656  LR: 0.00001755  \n","EVAL: [0/125] Loss: 0.6097(0.6097) \n","EVAL: [20/125] Loss: 0.4644(0.4895) \n","EVAL: [40/125] Loss: 0.5369(0.5074) \n","EVAL: [60/125] Loss: 0.5068(0.4936) \n","EVAL: [80/125] Loss: 0.4157(0.4923) \n","EVAL: [100/125] Loss: 0.5619(0.4842) \n","EVAL: [120/125] Loss: 0.4448(0.4882) \n","EVAL: [124/125] Loss: 0.5220(0.4878) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Save Best Score: 0.4969 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4969 Model\n","Epoch 2 - avg_train_loss: 0.4561  avg_val_loss: 0.4878\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4561  avg_val_loss: 0.4878\n","Epoch 2 - Score: 0.4969  Scores: [0.4474487113858622, 0.5462712075963629]\n","INFO:__main__:Epoch 2 - Score: 0.4969  Scores: [0.4474487113858622, 0.5462712075963629]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][160/646] Elapsed 1m 40s (remain 5m 3s) Loss: 0.3386(0.4542) Grad: 100419.2500  LR: 0.00001737  \n","Epoch: [2][180/646] Elapsed 1m 46s (remain 4m 33s) Loss: 0.4023(0.4575) Grad: 172166.9375  LR: 0.00001719  \n","Epoch: [2][200/646] Elapsed 1m 53s (remain 4m 11s) Loss: 0.4606(0.4608) Grad: 153383.1719  LR: 0.00001700  \n","Epoch: [2][220/646] Elapsed 1m 59s (remain 3m 49s) Loss: 0.4814(0.4627) Grad: 179743.8438  LR: 0.00001680  \n","Epoch: [2][240/646] Elapsed 2m 6s (remain 3m 33s) Loss: 0.6661(0.4648) Grad: 266664.5312  LR: 0.00001660  \n","Epoch: [2][260/646] Elapsed 2m 12s (remain 3m 15s) Loss: 0.4795(0.4631) Grad: 166480.0781  LR: 0.00001640  \n","Epoch: [2][280/646] Elapsed 2m 20s (remain 3m 1s) Loss: 0.4511(0.4625) Grad: 213865.6094  LR: 0.00001619  \n","Epoch: [2][300/646] Elapsed 2m 26s (remain 2m 47s) Loss: 0.7329(0.4608) Grad: 115206.7969  LR: 0.00001597  \n","EVAL: [0/125] Loss: 0.6938(0.6938) \n","EVAL: [20/125] Loss: 0.5205(0.4876) \n","EVAL: [40/125] Loss: 0.4754(0.5124) \n","EVAL: [60/125] Loss: 0.5673(0.5004) \n","EVAL: [80/125] Loss: 0.3554(0.4971) \n","EVAL: [100/125] Loss: 0.5462(0.4878) \n","EVAL: [120/125] Loss: 0.4480(0.4927) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4608  avg_val_loss: 0.4920\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4608  avg_val_loss: 0.4920\n","Epoch 2 - Score: 0.5038  Scores: [0.4521954623152759, 0.5553484396229437]\n","INFO:__main__:Epoch 2 - Score: 0.5038  Scores: [0.4521954623152759, 0.5553484396229437]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.5222(0.4920) \n","Epoch: [2][320/646] Elapsed 3m 14s (remain 3m 17s) Loss: 0.4794(0.4610) Grad: 161034.2969  LR: 0.00001575  \n","Epoch: [2][340/646] Elapsed 3m 19s (remain 2m 58s) Loss: 0.6256(0.4620) Grad: 125263.1406  LR: 0.00001553  \n","Epoch: [2][360/646] Elapsed 3m 24s (remain 2m 41s) Loss: 0.4242(0.4626) Grad: 145416.9219  LR: 0.00001530  \n","Epoch: [2][380/646] Elapsed 3m 30s (remain 2m 26s) Loss: 0.4823(0.4635) Grad: 130756.7422  LR: 0.00001507  \n","Epoch: [2][400/646] Elapsed 3m 36s (remain 2m 12s) Loss: 0.6108(0.4637) Grad: 243166.6250  LR: 0.00001484  \n","Epoch: [2][420/646] Elapsed 3m 42s (remain 1m 58s) Loss: 0.4186(0.4634) Grad: 172509.4531  LR: 0.00001460  \n","Epoch: [2][440/646] Elapsed 3m 48s (remain 1m 46s) Loss: 0.4685(0.4662) Grad: 159485.3125  LR: 0.00001436  \n","EVAL: [0/125] Loss: 0.6551(0.6551) \n","EVAL: [20/125] Loss: 0.5057(0.4912) \n","EVAL: [40/125] Loss: 0.5048(0.5188) \n","EVAL: [60/125] Loss: 0.5510(0.5057) \n","EVAL: [80/125] Loss: 0.3936(0.4997) \n","EVAL: [100/125] Loss: 0.5721(0.4908) \n","EVAL: [120/125] Loss: 0.4419(0.4957) \n","EVAL: [124/125] Loss: 0.5301(0.4949) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4668  avg_val_loss: 0.4949\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4668  avg_val_loss: 0.4949\n","Epoch 2 - Score: 0.5047  Scores: [0.4294810656480067, 0.5798986449598834]\n","INFO:__main__:Epoch 2 - Score: 0.5047  Scores: [0.4294810656480067, 0.5798986449598834]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][460/646] Elapsed 4m 36s (remain 1m 50s) Loss: 0.5381(0.4687) Grad: 264298.3438  LR: 0.00001412  \n","Epoch: [2][480/646] Elapsed 4m 41s (remain 1m 36s) Loss: 0.3525(0.4669) Grad: 117266.2969  LR: 0.00001387  \n","Epoch: [2][500/646] Elapsed 4m 47s (remain 1m 23s) Loss: 0.5017(0.4682) Grad: 172950.8438  LR: 0.00001362  \n","Epoch: [2][520/646] Elapsed 4m 53s (remain 1m 10s) Loss: 0.3333(0.4670) Grad: 111377.5781  LR: 0.00001336  \n","Epoch: [2][540/646] Elapsed 4m 58s (remain 0m 57s) Loss: 0.5052(0.4656) Grad: 213337.7344  LR: 0.00001311  \n","Epoch: [2][560/646] Elapsed 5m 4s (remain 0m 46s) Loss: 0.3842(0.4646) Grad: 90014.6719  LR: 0.00001285  \n","Epoch: [2][580/646] Elapsed 5m 9s (remain 0m 34s) Loss: 0.4134(0.4639) Grad: 110919.6016  LR: 0.00001259  \n","Epoch: [2][600/646] Elapsed 5m 14s (remain 0m 23s) Loss: 0.4933(0.4618) Grad: 152137.9844  LR: 0.00001233  \n","EVAL: [0/125] Loss: 0.5970(0.5970) \n","EVAL: [20/125] Loss: 0.4598(0.4584) \n","EVAL: [40/125] Loss: 0.4953(0.4790) \n","EVAL: [60/125] Loss: 0.5287(0.4685) \n","EVAL: [80/125] Loss: 0.3608(0.4640) \n","EVAL: [100/125] Loss: 0.4787(0.4530) \n","EVAL: [120/125] Loss: 0.4287(0.4583) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - Save Best Score: 0.4680 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4680 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.4585(0.4574) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4618  avg_val_loss: 0.4574\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4618  avg_val_loss: 0.4574\n","Epoch 2 - Score: 0.4680  Scores: [0.42087563608646067, 0.5151692791295484]\n","INFO:__main__:Epoch 2 - Score: 0.4680  Scores: [0.42087563608646067, 0.5151692791295484]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][620/646] Elapsed 6m 11s (remain 0m 14s) Loss: 0.8022(0.4620) Grad: 227595.3438  LR: 0.00001207  \n","Epoch: [2][640/646] Elapsed 6m 16s (remain 0m 2s) Loss: 0.4345(0.4608) Grad: 130811.2812  LR: 0.00001180  \n","Epoch: [2][645/646] Elapsed 6m 18s (remain 0m 0s) Loss: 0.4861(0.4616) Grad: 133433.6250  LR: 0.00001173  \n","EVAL: [0/125] Loss: 0.7387(0.7387) \n","EVAL: [20/125] Loss: 0.5762(0.5260) \n","EVAL: [40/125] Loss: 0.6019(0.5632) \n","EVAL: [60/125] Loss: 0.6094(0.5524) \n","EVAL: [80/125] Loss: 0.4210(0.5438) \n","EVAL: [100/125] Loss: 0.6077(0.5360) \n","EVAL: [120/125] Loss: 0.4630(0.5412) \n","EVAL: [124/125] Loss: 0.5478(0.5397) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.4616  avg_val_loss: 0.5397\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.4616  avg_val_loss: 0.5397\n","Epoch 2 - Score: 0.5518  Scores: [0.450931078948441, 0.6525706505960777]\n","INFO:__main__:Epoch 2 - Score: 0.5518  Scores: [0.450931078948441, 0.6525706505960777]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/646] Elapsed 0m 1s (remain 10m 47s) Loss: 0.5518(0.5518) Grad: 240411.9375  LR: 0.00001172  \n","Epoch: [3][20/646] Elapsed 0m 6s (remain 3m 21s) Loss: 0.3406(0.3847) Grad: 212907.9375  LR: 0.00001145  \n","Epoch: [3][40/646] Elapsed 0m 12s (remain 3m 0s) Loss: 0.5748(0.4096) Grad: 171135.1250  LR: 0.00001119  \n","Epoch: [3][60/646] Elapsed 0m 18s (remain 3m 1s) Loss: 0.4619(0.4057) Grad: 138248.3438  LR: 0.00001092  \n","Epoch: [3][80/646] Elapsed 0m 24s (remain 2m 54s) Loss: 0.4946(0.4163) Grad: 202905.7344  LR: 0.00001065  \n","Epoch: [3][100/646] Elapsed 0m 30s (remain 2m 46s) Loss: 0.3675(0.4131) Grad: 141487.9844  LR: 0.00001038  \n","Epoch: [3][120/646] Elapsed 0m 37s (remain 2m 41s) Loss: 0.4888(0.4116) Grad: 167706.4375  LR: 0.00001011  \n","Epoch: [3][140/646] Elapsed 0m 42s (remain 2m 32s) Loss: 0.4381(0.4098) Grad: 186384.1094  LR: 0.00000984  \n","EVAL: [0/125] Loss: 0.6695(0.6695) \n","EVAL: [20/125] Loss: 0.4636(0.4920) \n","EVAL: [40/125] Loss: 0.4786(0.5018) \n","EVAL: [60/125] Loss: 0.4962(0.4942) \n","EVAL: [80/125] Loss: 0.3891(0.4923) \n","EVAL: [100/125] Loss: 0.5621(0.4823) \n","EVAL: [120/125] Loss: 0.4604(0.4870) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4055  avg_val_loss: 0.4866\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4055  avg_val_loss: 0.4866\n","Epoch 3 - Score: 0.4966  Scores: [0.46829856461866387, 0.5248880434056509]\n","INFO:__main__:Epoch 3 - Score: 0.4966  Scores: [0.46829856461866387, 0.5248880434056509]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.4931(0.4866) \n","Epoch: [3][160/646] Elapsed 1m 29s (remain 4m 30s) Loss: 0.3226(0.4020) Grad: 164429.3594  LR: 0.00000957  \n","Epoch: [3][180/646] Elapsed 1m 35s (remain 4m 4s) Loss: 0.4227(0.4011) Grad: 206457.5000  LR: 0.00000930  \n","Epoch: [3][200/646] Elapsed 1m 41s (remain 3m 44s) Loss: 0.4578(0.4013) Grad: 223139.0938  LR: 0.00000903  \n","Epoch: [3][220/646] Elapsed 1m 46s (remain 3m 24s) Loss: 0.2774(0.3978) Grad: 104725.4219  LR: 0.00000876  \n","Epoch: [3][240/646] Elapsed 1m 51s (remain 3m 7s) Loss: 0.5042(0.3985) Grad: 145764.5312  LR: 0.00000849  \n","Epoch: [3][260/646] Elapsed 1m 57s (remain 2m 53s) Loss: 0.5632(0.3972) Grad: 129514.9688  LR: 0.00000823  \n","Epoch: [3][280/646] Elapsed 2m 2s (remain 2m 38s) Loss: 0.4646(0.3960) Grad: 284230.7188  LR: 0.00000796  \n","Epoch: [3][300/646] Elapsed 2m 8s (remain 2m 26s) Loss: 0.3709(0.3955) Grad: 90721.6641  LR: 0.00000770  \n","EVAL: [0/125] Loss: 0.6669(0.6669) \n","EVAL: [20/125] Loss: 0.4571(0.4804) \n","EVAL: [40/125] Loss: 0.4736(0.4913) \n","EVAL: [60/125] Loss: 0.4863(0.4843) \n","EVAL: [80/125] Loss: 0.3512(0.4827) \n","EVAL: [100/125] Loss: 0.5936(0.4722) \n","EVAL: [120/125] Loss: 0.5096(0.4771) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3955  avg_val_loss: 0.4772\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3955  avg_val_loss: 0.4772\n","Epoch 3 - Score: 0.4879  Scores: [0.45439314290966437, 0.5213998833490485]\n","INFO:__main__:Epoch 3 - Score: 0.4879  Scores: [0.45439314290966437, 0.5213998833490485]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.5141(0.4772) \n","Epoch: [3][320/646] Elapsed 2m 56s (remain 2m 58s) Loss: 0.3538(0.3954) Grad: 114272.5391  LR: 0.00000744  \n","Epoch: [3][340/646] Elapsed 3m 1s (remain 2m 42s) Loss: 0.4535(0.3966) Grad: 144127.0000  LR: 0.00000718  \n","Epoch: [3][360/646] Elapsed 3m 6s (remain 2m 27s) Loss: 0.3164(0.3955) Grad: 121962.2109  LR: 0.00000692  \n","Epoch: [3][380/646] Elapsed 3m 12s (remain 2m 13s) Loss: 0.5833(0.3956) Grad: 211415.1875  LR: 0.00000666  \n","Epoch: [3][400/646] Elapsed 3m 18s (remain 2m 1s) Loss: 0.2830(0.3944) Grad: 135041.2188  LR: 0.00000641  \n","Epoch: [3][420/646] Elapsed 3m 23s (remain 1m 48s) Loss: 0.3746(0.3949) Grad: 108763.6719  LR: 0.00000616  \n","Epoch: [3][440/646] Elapsed 3m 29s (remain 1m 37s) Loss: 0.3837(0.3939) Grad: 115788.5859  LR: 0.00000591  \n","EVAL: [0/125] Loss: 0.6986(0.6986) \n","EVAL: [20/125] Loss: 0.4650(0.4902) \n","EVAL: [40/125] Loss: 0.4757(0.4985) \n","EVAL: [60/125] Loss: 0.4602(0.4905) \n","EVAL: [80/125] Loss: 0.3695(0.4893) \n","EVAL: [100/125] Loss: 0.5511(0.4785) \n","EVAL: [120/125] Loss: 0.4676(0.4831) \n","EVAL: [124/125] Loss: 0.5304(0.4832) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3931  avg_val_loss: 0.4832\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3931  avg_val_loss: 0.4832\n","Epoch 3 - Score: 0.4940  Scores: [0.46297780883026296, 0.5249372436043055]\n","INFO:__main__:Epoch 3 - Score: 0.4940  Scores: [0.46297780883026296, 0.5249372436043055]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][460/646] Elapsed 4m 18s (remain 1m 43s) Loss: 0.3092(0.3939) Grad: 116548.8516  LR: 0.00000566  \n","Epoch: [3][480/646] Elapsed 4m 25s (remain 1m 31s) Loss: 0.3653(0.3950) Grad: 151933.8906  LR: 0.00000542  \n","Epoch: [3][500/646] Elapsed 4m 30s (remain 1m 18s) Loss: 0.2543(0.3947) Grad: 192943.1406  LR: 0.00000518  \n","Epoch: [3][520/646] Elapsed 4m 36s (remain 1m 6s) Loss: 0.4637(0.3957) Grad: 143102.7344  LR: 0.00000495  \n","Epoch: [3][540/646] Elapsed 4m 42s (remain 0m 54s) Loss: 0.2579(0.3957) Grad: 155838.0938  LR: 0.00000472  \n","Epoch: [3][560/646] Elapsed 4m 47s (remain 0m 43s) Loss: 0.2925(0.3952) Grad: 161342.2344  LR: 0.00000449  \n","Epoch: [3][580/646] Elapsed 4m 53s (remain 0m 32s) Loss: 0.3934(0.3945) Grad: 108192.3438  LR: 0.00000427  \n","Epoch: [3][600/646] Elapsed 4m 58s (remain 0m 22s) Loss: 0.2906(0.3938) Grad: 110536.9922  LR: 0.00000405  \n","EVAL: [0/125] Loss: 0.6540(0.6540) \n","EVAL: [20/125] Loss: 0.4663(0.4876) \n","EVAL: [40/125] Loss: 0.4834(0.4908) \n","EVAL: [60/125] Loss: 0.4405(0.4861) \n","EVAL: [80/125] Loss: 0.3936(0.4864) \n","EVAL: [100/125] Loss: 0.5389(0.4772) \n","EVAL: [120/125] Loss: 0.4810(0.4818) \n","EVAL: [124/125] Loss: 0.5005(0.4818) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3938  avg_val_loss: 0.4818\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3938  avg_val_loss: 0.4818\n","Epoch 3 - Score: 0.4912  Scores: [0.4650794722202968, 0.5173539115245985]\n","INFO:__main__:Epoch 3 - Score: 0.4912  Scores: [0.4650794722202968, 0.5173539115245985]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][620/646] Elapsed 5m 46s (remain 0m 13s) Loss: 0.3653(0.3927) Grad: 131454.5469  LR: 0.00000383  \n","Epoch: [3][640/646] Elapsed 5m 52s (remain 0m 2s) Loss: 0.3774(0.3924) Grad: 140182.8281  LR: 0.00000362  \n","Epoch: [3][645/646] Elapsed 5m 54s (remain 0m 0s) Loss: 0.4371(0.3924) Grad: 228142.0625  LR: 0.00000357  \n","EVAL: [0/125] Loss: 0.6598(0.6598) \n","EVAL: [20/125] Loss: 0.4601(0.4697) \n","EVAL: [40/125] Loss: 0.4631(0.4809) \n","EVAL: [60/125] Loss: 0.4635(0.4753) \n","EVAL: [80/125] Loss: 0.3742(0.4739) \n","EVAL: [100/125] Loss: 0.5236(0.4638) \n","EVAL: [120/125] Loss: 0.4479(0.4691) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3924  avg_val_loss: 0.4689\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3924  avg_val_loss: 0.4689\n","Epoch 3 - Score: 0.4790  Scores: [0.4476808844544515, 0.5103217582307262]\n","INFO:__main__:Epoch 3 - Score: 0.4790  Scores: [0.4476808844544515, 0.5103217582307262]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.4689(0.4689) \n","Epoch: [4][0/646] Elapsed 0m 0s (remain 6m 50s) Loss: 0.3712(0.3712) Grad: 265871.8750  LR: 0.00000356  \n","Epoch: [4][20/646] Elapsed 0m 8s (remain 3m 58s) Loss: 0.4884(0.3354) Grad: 407046.7188  LR: 0.00000336  \n","Epoch: [4][40/646] Elapsed 0m 13s (remain 3m 13s) Loss: 0.3603(0.3332) Grad: 137864.5938  LR: 0.00000316  \n","Epoch: [4][60/646] Elapsed 0m 19s (remain 3m 2s) Loss: 0.3982(0.3371) Grad: 140777.2500  LR: 0.00000296  \n","Epoch: [4][80/646] Elapsed 0m 25s (remain 2m 55s) Loss: 0.2669(0.3365) Grad: 162075.2031  LR: 0.00000277  \n","Epoch: [4][100/646] Elapsed 0m 30s (remain 2m 43s) Loss: 0.2784(0.3309) Grad: 126510.3203  LR: 0.00000259  \n","Epoch: [4][120/646] Elapsed 0m 35s (remain 2m 32s) Loss: 0.2899(0.3321) Grad: 306173.0625  LR: 0.00000241  \n","Epoch: [4][140/646] Elapsed 0m 41s (remain 2m 27s) Loss: 0.3571(0.3311) Grad: 187321.2969  LR: 0.00000224  \n","EVAL: [0/125] Loss: 0.6465(0.6465) \n","EVAL: [20/125] Loss: 0.4641(0.4708) \n","EVAL: [40/125] Loss: 0.4643(0.4803) \n","EVAL: [60/125] Loss: 0.4647(0.4749) \n","EVAL: [80/125] Loss: 0.3791(0.4739) \n","EVAL: [100/125] Loss: 0.5429(0.4638) \n","EVAL: [120/125] Loss: 0.4514(0.4691) \n","EVAL: [124/125] Loss: 0.4625(0.4689) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3291  avg_val_loss: 0.4689\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3291  avg_val_loss: 0.4689\n","Epoch 4 - Score: 0.4792  Scores: [0.4460660499704673, 0.5122674560184581]\n","INFO:__main__:Epoch 4 - Score: 0.4792  Scores: [0.4460660499704673, 0.5122674560184581]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][160/646] Elapsed 1m 29s (remain 4m 28s) Loss: 0.3420(0.3295) Grad: 241021.7344  LR: 0.00000207  \n","Epoch: [4][180/646] Elapsed 1m 34s (remain 4m 1s) Loss: 0.3374(0.3309) Grad: 202847.3906  LR: 0.00000191  \n","Epoch: [4][200/646] Elapsed 1m 39s (remain 3m 39s) Loss: 0.3659(0.3292) Grad: 232438.1562  LR: 0.00000175  \n","Epoch: [4][220/646] Elapsed 1m 45s (remain 3m 21s) Loss: 0.2917(0.3255) Grad: 180956.1094  LR: 0.00000160  \n","Epoch: [4][240/646] Elapsed 1m 50s (remain 3m 5s) Loss: 0.2843(0.3279) Grad: 158148.2344  LR: 0.00000146  \n","Epoch: [4][260/646] Elapsed 1m 56s (remain 2m 51s) Loss: 0.3276(0.3276) Grad: 214479.6562  LR: 0.00000132  \n","Epoch: [4][280/646] Elapsed 2m 3s (remain 2m 40s) Loss: 0.4298(0.3290) Grad: 331310.5000  LR: 0.00000119  \n","Epoch: [4][300/646] Elapsed 2m 9s (remain 2m 28s) Loss: 0.3300(0.3293) Grad: 176918.3281  LR: 0.00000107  \n","EVAL: [0/125] Loss: 0.6587(0.6587) \n","EVAL: [20/125] Loss: 0.4624(0.4754) \n","EVAL: [40/125] Loss: 0.4701(0.4833) \n","EVAL: [60/125] Loss: 0.4579(0.4788) \n","EVAL: [80/125] Loss: 0.3791(0.4780) \n","EVAL: [100/125] Loss: 0.5445(0.4683) \n","EVAL: [120/125] Loss: 0.4537(0.4733) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3293  avg_val_loss: 0.4731\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3293  avg_val_loss: 0.4731\n","Epoch 4 - Score: 0.4831  Scores: [0.4510254137924777, 0.5152574774005733]\n","INFO:__main__:Epoch 4 - Score: 0.4831  Scores: [0.4510254137924777, 0.5152574774005733]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.4632(0.4731) \n","Epoch: [4][320/646] Elapsed 2m 56s (remain 2m 59s) Loss: 0.2879(0.3292) Grad: 332253.7500  LR: 0.00000095  \n","Epoch: [4][340/646] Elapsed 3m 1s (remain 2m 42s) Loss: 0.3371(0.3288) Grad: 136939.1562  LR: 0.00000084  \n","Epoch: [4][360/646] Elapsed 3m 7s (remain 2m 28s) Loss: 0.2690(0.3273) Grad: 135702.6875  LR: 0.00000073  \n","Epoch: [4][380/646] Elapsed 3m 13s (remain 2m 14s) Loss: 0.2238(0.3286) Grad: 139253.4688  LR: 0.00000063  \n","Epoch: [4][400/646] Elapsed 3m 18s (remain 2m 1s) Loss: 0.3357(0.3290) Grad: 115266.4141  LR: 0.00000054  \n","Epoch: [4][420/646] Elapsed 3m 24s (remain 1m 49s) Loss: 0.3051(0.3285) Grad: 104681.0156  LR: 0.00000046  \n","Epoch: [4][440/646] Elapsed 3m 29s (remain 1m 37s) Loss: 0.2944(0.3284) Grad: 195250.5781  LR: 0.00000038  \n","EVAL: [0/125] Loss: 0.6512(0.6512) \n","EVAL: [20/125] Loss: 0.4617(0.4771) \n","EVAL: [40/125] Loss: 0.4750(0.4847) \n","EVAL: [60/125] Loss: 0.4562(0.4799) \n","EVAL: [80/125] Loss: 0.3848(0.4792) \n","EVAL: [100/125] Loss: 0.5522(0.4696) \n","EVAL: [120/125] Loss: 0.4565(0.4747) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3283  avg_val_loss: 0.4746\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3283  avg_val_loss: 0.4746\n","Epoch 4 - Score: 0.4844  Scores: [0.45692892973597954, 0.5118266667464544]\n","INFO:__main__:Epoch 4 - Score: 0.4844  Scores: [0.45692892973597954, 0.5118266667464544]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.4664(0.4746) \n","Epoch: [4][460/646] Elapsed 4m 17s (remain 1m 43s) Loss: 0.2348(0.3281) Grad: 201474.3594  LR: 0.00000031  \n","Epoch: [4][480/646] Elapsed 4m 22s (remain 1m 30s) Loss: 0.4347(0.3278) Grad: 293634.8438  LR: 0.00000025  \n","Epoch: [4][500/646] Elapsed 4m 28s (remain 1m 17s) Loss: 0.4025(0.3271) Grad: 153521.8594  LR: 0.00000019  \n","Epoch: [4][520/646] Elapsed 4m 34s (remain 1m 5s) Loss: 0.4736(0.3273) Grad: 163064.0156  LR: 0.00000014  \n","Epoch: [4][540/646] Elapsed 4m 40s (remain 0m 54s) Loss: 0.3252(0.3272) Grad: 145172.1562  LR: 0.00000010  \n","Epoch: [4][560/646] Elapsed 4m 46s (remain 0m 43s) Loss: 0.3205(0.3285) Grad: 226732.8906  LR: 0.00000007  \n","Epoch: [4][580/646] Elapsed 4m 51s (remain 0m 32s) Loss: 0.2345(0.3276) Grad: 188870.2500  LR: 0.00000004  \n","Epoch: [4][600/646] Elapsed 4m 57s (remain 0m 22s) Loss: 0.4551(0.3279) Grad: 144283.2344  LR: 0.00000002  \n","EVAL: [0/125] Loss: 0.6532(0.6532) \n","EVAL: [20/125] Loss: 0.4590(0.4772) \n","EVAL: [40/125] Loss: 0.4716(0.4839) \n","EVAL: [60/125] Loss: 0.4553(0.4793) \n","EVAL: [80/125] Loss: 0.3834(0.4786) \n","EVAL: [100/125] Loss: 0.5536(0.4690) \n","EVAL: [120/125] Loss: 0.4597(0.4740) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3279  avg_val_loss: 0.4738\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3279  avg_val_loss: 0.4738\n","Epoch 4 - Score: 0.4837  Scores: [0.4529382240131592, 0.5144553599667427]\n","INFO:__main__:Epoch 4 - Score: 0.4837  Scores: [0.4529382240131592, 0.5144553599667427]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Loss: 0.4667(0.4738) \n","Epoch: [4][620/646] Elapsed 5m 46s (remain 0m 13s) Loss: 0.3257(0.3284) Grad: 187685.0938  LR: 0.00000001  \n","Epoch: [4][640/646] Elapsed 5m 51s (remain 0m 2s) Loss: 0.3813(0.3283) Grad: 153730.6719  LR: 0.00000000  \n","Epoch: [4][645/646] Elapsed 5m 52s (remain 0m 0s) Loss: 0.3118(0.3285) Grad: 138919.6875  LR: 0.00000000  \n","EVAL: [0/125] Loss: 0.6532(0.6532) \n","EVAL: [20/125] Loss: 0.4590(0.4772) \n","EVAL: [40/125] Loss: 0.4717(0.4839) \n","EVAL: [60/125] Loss: 0.4552(0.4793) \n","EVAL: [80/125] Loss: 0.3834(0.4787) \n","EVAL: [100/125] Loss: 0.5536(0.4690) \n","EVAL: [120/125] Loss: 0.4597(0.4740) \n","EVAL: [124/125] Loss: 0.4667(0.4739) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3285  avg_val_loss: 0.4739\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3285  avg_val_loss: 0.4739\n","Epoch 4 - Score: 0.4837  Scores: [0.4529650366650152, 0.5144514909948328]\n","INFO:__main__:Epoch 4 - Score: 0.4837  Scores: [0.4529650366650152, 0.5144514909948328]\n","========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.4680  Scores: [0.42087563608646067, 0.5151692791295484]\n","INFO:__main__:Score: 0.4680  Scores: [0.42087563608646067, 0.5151692791295484]\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n","Score: 0.5334  Scores: [0.4532268327730023, 0.6136549960452997]\n","INFO:__main__:Score: 0.5334  Scores: [0.4532268327730023, 0.6136549960452997]\n"]}],"source":["if __name__ == '__main__':\n","\n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target_cols].values\n","        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","        score, scores = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n","\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                if CFG.save_strategy=='epoch':\n","                  _oof_df = train_loop(train, fold)\n","                elif CFG.save_strategy=='step':\n","                  _oof_df = train_loop_steps(train,fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","\n","    if CFG.wandb:\n","        wandb.finish()\n","    runtime.unassign()"],"id":"fde1c8af"},{"cell_type":"code","execution_count":25,"metadata":{"id":"a08b7051","executionInfo":{"status":"ok","timestamp":1693422465383,"user_tz":-540,"elapsed":14,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"a08b7051"},{"cell_type":"code","execution_count":25,"metadata":{"id":"eeb952c6","executionInfo":{"status":"ok","timestamp":1693422465383,"user_tz":-540,"elapsed":9,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"eeb952c6"},{"cell_type":"code","execution_count":25,"metadata":{"id":"04d58baa","executionInfo":{"status":"ok","timestamp":1693422465554,"user_tz":-540,"elapsed":6602880,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"04d58baa"},{"cell_type":"code","execution_count":25,"metadata":{"id":"d3ca03db","executionInfo":{"status":"ok","timestamp":1693422465555,"user_tz":-540,"elapsed":6602879,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"d3ca03db"}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"papermill":{"default_parameters":{},"duration":null,"end_time":null,"environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-25T10:25:22.661613","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"970d8c5b78dc4076be3d91210070b429":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b693e8b01404caaafd4a593c55a3f5e","IPY_MODEL_f2401886a7aa4d289069b31733da362b","IPY_MODEL_4100b4c4a589455d8452f5d04e2f5a9b"],"layout":"IPY_MODEL_b27b10311ef84260856401cb78513b27"}},"6b693e8b01404caaafd4a593c55a3f5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2c26584d1a64a98ab6b8e74e834c100","placeholder":"​","style":"IPY_MODEL_a66373e5a04343faaddc2370c49e0888","value":"Downloading (…)okenizer_config.json: 100%"}},"f2401886a7aa4d289069b31733da362b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2161f31626834a48a98e0e481a171fbf","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b6658a042d443e4ab22975c05f6223c","value":52}},"4100b4c4a589455d8452f5d04e2f5a9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e823013101bd41d58b471eae7ec64ac0","placeholder":"​","style":"IPY_MODEL_c652c3e57ce0491da727b113559ac56e","value":" 52.0/52.0 [00:00&lt;00:00, 2.16kB/s]"}},"b27b10311ef84260856401cb78513b27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2c26584d1a64a98ab6b8e74e834c100":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a66373e5a04343faaddc2370c49e0888":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2161f31626834a48a98e0e481a171fbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b6658a042d443e4ab22975c05f6223c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e823013101bd41d58b471eae7ec64ac0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c652c3e57ce0491da727b113559ac56e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"824ecf25aa3f4821a6a030e87b77d078":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1bf6f15204fa475abccef37cf3bbfce4","IPY_MODEL_5416efcd5f424f769f838bec59fdaa96","IPY_MODEL_cadb7617ad8848b0a6d691427aa662da"],"layout":"IPY_MODEL_4c4529e05bda4fcaac9bc576fb90c41b"}},"1bf6f15204fa475abccef37cf3bbfce4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a08eedc3d5b047cc9751344f2327d0e0","placeholder":"​","style":"IPY_MODEL_4be09f4c339c41d6a00045939b4c97b0","value":"Downloading (…)lve/main/config.json: 100%"}},"5416efcd5f424f769f838bec59fdaa96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_550f62cbb327447e88ff3df1fc532b0e","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d9634e9011ad457ba7d79edc7f6ddb60","value":580}},"cadb7617ad8848b0a6d691427aa662da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7975e9f7da5488ab04f22cf81efa487","placeholder":"​","style":"IPY_MODEL_73637274def04540b5b29f1fd1954df3","value":" 580/580 [00:00&lt;00:00, 15.0kB/s]"}},"4c4529e05bda4fcaac9bc576fb90c41b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a08eedc3d5b047cc9751344f2327d0e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4be09f4c339c41d6a00045939b4c97b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"550f62cbb327447e88ff3df1fc532b0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9634e9011ad457ba7d79edc7f6ddb60":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7975e9f7da5488ab04f22cf81efa487":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73637274def04540b5b29f1fd1954df3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df2bebecf8a342f4b2410c95e34f2a7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fcabfa77050e41c2be39bf5ca6a5a0ab","IPY_MODEL_fb614279031f429487ff938324463804","IPY_MODEL_7b7c215743a741348a666431dc69af5c"],"layout":"IPY_MODEL_9a51ff9a9a764a708ee256deca6a7395"}},"fcabfa77050e41c2be39bf5ca6a5a0ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2d9d8a45bea4613b38bc131b221ffe6","placeholder":"​","style":"IPY_MODEL_358f112dc2e6485f97a849d1a2e51038","value":"Downloading spm.model: 100%"}},"fb614279031f429487ff938324463804":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b59a417aa3d48f0a4d9df8e5f5f8168","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0a2d95e2253f4f20a2d810502a57a72c","value":2464616}},"7b7c215743a741348a666431dc69af5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73340313eb5d4fb0b43c7731108ce90c","placeholder":"​","style":"IPY_MODEL_f5c25e16c58a46a6b0e7f7eceaf7f4f5","value":" 2.46M/2.46M [00:00&lt;00:00, 44.0MB/s]"}},"9a51ff9a9a764a708ee256deca6a7395":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2d9d8a45bea4613b38bc131b221ffe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"358f112dc2e6485f97a849d1a2e51038":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b59a417aa3d48f0a4d9df8e5f5f8168":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a2d95e2253f4f20a2d810502a57a72c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"73340313eb5d4fb0b43c7731108ce90c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5c25e16c58a46a6b0e7f7eceaf7f4f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e42cfbe8031149d7be4706d6c79d341a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5492217d3e740d8adb79bbe0d8b5fb7","IPY_MODEL_187bc0145bd2401bb070ec61a2036108","IPY_MODEL_309870e0369846a4987e81fc45ff567b"],"layout":"IPY_MODEL_e1282c70acee4f4081bef6c1a9adfb59"}},"b5492217d3e740d8adb79bbe0d8b5fb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15ff975eef914f8b865fc09e350e864a","placeholder":"​","style":"IPY_MODEL_590a2db7e98742af80e471777df78bf2","value":"100%"}},"187bc0145bd2401bb070ec61a2036108":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4602034f95b34b0a92fd46ffd0b58691","max":7165,"min":0,"orientation":"horizontal","style":"IPY_MODEL_479cb19f52d148ffa240d25e1e1eaa8a","value":7165}},"309870e0369846a4987e81fc45ff567b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3652fb1849804b0b975b317e5bf0c717","placeholder":"​","style":"IPY_MODEL_2179ce3c34d44799b2477159e8b655a6","value":" 7165/7165 [00:03&lt;00:00, 2406.72it/s]"}},"e1282c70acee4f4081bef6c1a9adfb59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15ff975eef914f8b865fc09e350e864a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"590a2db7e98742af80e471777df78bf2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4602034f95b34b0a92fd46ffd0b58691":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"479cb19f52d148ffa240d25e1e1eaa8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3652fb1849804b0b975b317e5bf0c717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2179ce3c34d44799b2477159e8b655a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92dc721976cf4affb90482e46fe3ce8f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8ace65c55af453d88e70a3d0724cbea","IPY_MODEL_cf9c4ab0d5f34e4ab17e777ce2f2da19","IPY_MODEL_8ef20d7c436f435ea320768acc81e166"],"layout":"IPY_MODEL_8433d5c02ee34dab9647a1e7c825ab2e"}},"f8ace65c55af453d88e70a3d0724cbea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abb5171e19454e9ba593470fe9ca7cc2","placeholder":"​","style":"IPY_MODEL_7ee3947ad13c43639df1d72b255cf2b7","value":"Downloading pytorch_model.bin: 100%"}},"cf9c4ab0d5f34e4ab17e777ce2f2da19":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41e0608784a6414196dfe07f5e5907a5","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2820e38bcd654b509c44172ad30529d7","value":873673253}},"8ef20d7c436f435ea320768acc81e166":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3058ef9afc334329b737e551c3e4181a","placeholder":"​","style":"IPY_MODEL_dfc044c84f8544fcb434c2efa9e90b1f","value":" 874M/874M [00:17&lt;00:00, 54.0MB/s]"}},"8433d5c02ee34dab9647a1e7c825ab2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abb5171e19454e9ba593470fe9ca7cc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ee3947ad13c43639df1d72b255cf2b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41e0608784a6414196dfe07f5e5907a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2820e38bcd654b509c44172ad30529d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3058ef9afc334329b737e551c3e4181a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfc044c84f8544fcb434c2efa9e90b1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}