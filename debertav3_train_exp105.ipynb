{"cells":[{"cell_type":"markdown","metadata":{"id":"7aa1693d"},"source":["# About this notebook\n","- This notebook is a modified version of the PyTorch pipeline from Y.Nakama's starter NLP notebook from Feedback Prize 3 competition [here](https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train). Don't forget to upvote his work!\n","- Inference notebook is [here](https://www.kaggle.com/mohammad2012191/debertav3-pytorch-baseline-inference-cv-0-467)"],"id":"7aa1693d"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1709448300126,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"VAH4GU3udQLE","outputId":"9828bcd6-3700-4079-f4bd-bcf5f4087cce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Mar  3 06:44:59 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   56C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"],"id":"VAH4GU3udQLE"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27805,"status":"ok","timestamp":1709448327921,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"y7YWu2B1dPO_","outputId":"6c21d802-af72-498d-c914-b1047896b765"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"y7YWu2B1dPO_"},{"cell_type":"code","execution_count":3,"metadata":{"id":"QniqU23EOe1O","executionInfo":{"status":"ok","timestamp":1709448327922,"user_tz":-540,"elapsed":10,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["from google.colab import runtime\n","\n"],"id":"QniqU23EOe1O"},{"cell_type":"code","execution_count":3,"metadata":{"id":"16c51a23","executionInfo":{"status":"ok","timestamp":1709448327922,"user_tz":-540,"elapsed":8,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"16c51a23"},{"cell_type":"markdown","metadata":{"id":"d2e3dae0"},"source":["# CFG"],"id":"d2e3dae0"},{"cell_type":"code","execution_count":4,"metadata":{"id":"d22dfc09","executionInfo":{"status":"ok","timestamp":1709448327922,"user_tz":-540,"elapsed":7,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    exp='exp105'\n","    is_exp=False\n","    wandb=False\n","    competition='FB3'\n","    _wandb_kernel='nakama'\n","    debug=True\n","    apex=True\n","    print_freq=20\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-large\"\n","    gradient_checkpointing=True\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps_rate=0.1\n","    epochs=3\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.98)\n","    batch_size=8\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    target_cols=['content', 'wording']\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    awp=False\n","    nth_awp_start_epoch= 3\n","    adv_lr = 1e-4\n","    adv_eps = 1e-2\n","    eval_steps =70\n","    save_strategy='epoch'\n","    pooling='ConcatPooling'\n","    n_layers=8\n","    freeze=True\n","    freeze_top_num_layer=16\n","    lr_weight_decay=0.95\n","    reinit=False\n","\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"],"id":"d22dfc09"},{"cell_type":"markdown","metadata":{"id":"NhFDBpBR3vGg"},"source":["# Directory settings"],"id":"NhFDBpBR3vGg"},{"cell_type":"code","execution_count":5,"metadata":{"id":"NJYVrhufgVPh","executionInfo":{"status":"ok","timestamp":1709448328426,"user_tz":-540,"elapsed":511,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# Directory settings\n","# ====================================================\n","import os\n","\n","OUTPUT_DIR = f'/content/drive/MyDrive/Kaggle/outputs/{CFG.exp}/'\n","\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n"],"id":"NJYVrhufgVPh"},{"cell_type":"code","execution_count":6,"metadata":{"id":"eedc45a5","executionInfo":{"status":"ok","timestamp":1709448328426,"user_tz":-540,"elapsed":2,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","\n","    import wandb\n","\n","    try:\n","        from kaggle_secrets import UserSecretsClient\n","        user_secrets = UserSecretsClient()\n","        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        wandb.login(key=secret_value_0)\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","\n","    run = wandb.init(project='FB3-Public',\n","                     name=CFG.model,\n","                     config=class2dict(CFG),\n","                     group=CFG.model,\n","                     job_type=\"train\",\n","                     anonymous=anony)"],"id":"eedc45a5"},{"cell_type":"markdown","metadata":{"id":"bec24bf5"},"source":["# Library"],"id":"bec24bf5"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40280,"status":"ok","timestamp":1709448368704,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"f72fdd29","outputId":"89e4e505-59cc-40c1-b17c-ec5e41d80924"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.31.0\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2024.2.2)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.15.2\n","    Uninstalling tokenizers-0.15.2:\n","      Successfully uninstalled tokenizers-0.15.2\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.38.1\n","    Uninstalling transformers-4.38.1:\n","      Successfully uninstalled transformers-4.38.1\n","Successfully installed tokenizers-0.13.3 transformers-4.31.0\n","Requirement already satisfied: tokenizers==0.13.3 in /usr/local/lib/python3.10/dist-packages (0.13.3)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","tokenizers.__version__: 0.13.3\n","transformers.__version__: 4.31.0\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","os.system('pip install iterative-stratification==0.1.7')\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","#os.system('pip install -q transformers')\n","!pip install transformers==4.31.0\n","os.system('pip install -q tokenizers')\n","!pip install tokenizers==0.13.3\n","!pip install sentencepiece\n","\n","\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"id":"f72fdd29"},{"cell_type":"markdown","metadata":{"id":"179b542c"},"source":["# Utils"],"id":"179b542c"},{"cell_type":"code","execution_count":8,"metadata":{"id":"f9795dd2","executionInfo":{"status":"ok","timestamp":1709448368705,"user_tz":-540,"elapsed":25,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=42)"],"id":"f9795dd2"},{"cell_type":"markdown","metadata":{"id":"fac79d7b"},"source":["# Data Loading"],"id":"fac79d7b"},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"elapsed":23,"status":"error","timestamp":1709448368705,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"add36693","outputId":"70d1ad87-2847-4924-c222-4262fffc05c3"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Kaggle/inputs/summaries_train.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-0a5543d88938>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ====================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Kaggle/inputs/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'summaries_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'summaries_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Kaggle/inputs/summaries_train.csv'"]}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","input_path = '/content/drive/MyDrive/Kaggle/inputs/'\n","train = pd.read_csv(input_path+'summaries_train.csv')\n","test = pd.read_csv(input_path+'summaries_test.csv')\n","submission = pd.read_csv(input_path+'sample_submission.csv')\n","prompt_train = pd.read_csv(input_path+'prompts_train.csv')\n","prompt_test = pd.read_csv(input_path+'prompts_test.csv')\n","train = pd.merge(train,prompt_train,how='left',on='prompt_id')\n","test = pd.merge(test,prompt_test,how='left',on='prompt_id')\n","print(f\"train.shape: {train.shape}\")\n","display(train.head())\n","print(f\"test.shape: {test.shape}\")\n","display(test.head())\n","print(f\"submission.shape: {submission.shape}\")\n","display(submission.head())"],"id":"add36693"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2KzAhY4R3zRK","executionInfo":{"status":"aborted","timestamp":1709448368705,"user_tz":-540,"elapsed":20,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# oof_df=pd.read_pickle(input_path+'oof_df.pkl')"],"id":"2KzAhY4R3zRK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a37a56e4","executionInfo":{"status":"aborted","timestamp":1709448368706,"user_tz":-540,"elapsed":21,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["train['text'] = ' question: '+train['prompt_question'] + ' [SEP] summary: '+ train['text']+' [SEP] source: '+train['prompt_text'].str[:6000]\n","test['text'] =  ' question: '+test['prompt_question'] + ' [SEP] summary:  '+ test['text']+' [SEP] source: '+test['prompt_text'].str[:6000]\n","\n","#################################################\n","# prompt_textも\n","#################################################\n","\n","# # \"text\"列の長さを計算して新しい列\"length\"に追加\n","# train['length'] = train['text'].apply(len)\n","# # \"text\"列の先頭に\"length\"列の値を結合\n","# train['text'] = train['length'].astype(str) + '[SEP]' + train['prompt_question'] + '[SEP]' +train['prompt_title'] + 'summary(' + train['text'] +') [SEP] source of summary('+train['prompt_text']+')'\n","\n","# # \"text\"列の長さを計算して新しい列\"length\"に追加\n","# test['length'] = test['text'].apply(len)\n","# # \"text\"列の先頭に\"length\"列の値を結合\n","# test['text'] = test['length'].astype(str) + '[SEP]' + test['prompt_question'] + '[SEP]' +test['prompt_title'] + 'summary(' + test['text'] +') [SEP] source of summary('+test['prompt_text']+')'\n"],"id":"a37a56e4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTjtOHdZERdZ","executionInfo":{"status":"aborted","timestamp":1709448368706,"user_tz":-540,"elapsed":20,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"OTjtOHdZERdZ"},{"cell_type":"markdown","metadata":{"id":"bfcf2f21"},"source":["# CV split"],"id":"bfcf2f21"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1709448368706,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"fe773f94"},"outputs":[],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","# Fold = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_cols])):\n","#     train.loc[val_index, 'fold'] = int(n)\n","id2fold = {\n","    \"814d6b\": 0,\n","    \"39c16e\": 1,\n","    \"3b9047\": 2,\n","    \"ebad26\": 3,\n","}\n","\n","train[\"fold\"] = train[\"prompt_id\"].map(id2fold)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"],"id":"fe773f94"},{"cell_type":"code","execution_count":null,"metadata":{"id":"26ece1cd","executionInfo":{"status":"aborted","timestamp":1709448368707,"user_tz":-540,"elapsed":21,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=3000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"],"id":"26ece1cd"},{"cell_type":"markdown","metadata":{"id":"478fb80d"},"source":["# tokenizer"],"id":"478fb80d"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1709448368707,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"GLyHNCkSh0CG"},"outputs":[],"source":["CFG.model"],"id":"GLyHNCkSh0CG"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1709448368707,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"1a9ff4aa"},"outputs":[],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"id":"1a9ff4aa"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1709448368708,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"cQZWV8VaE0xO"},"outputs":[],"source":["train['text'].iloc[2]"],"id":"cQZWV8VaE0xO"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1709448368708,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"36zvorT0EVVA"},"outputs":[],"source":["# テキストをエンコード\n","text = 'unnko'\n","encoded = tokenizer(text, return_tensors='pt')\n","\n","# デコードして元のテキストを取得\n","\n","decoded_tokens = tokenizer.convert_ids_to_tokens(encoded['input_ids'][0])\n","decoded_text = \" \".join(decoded_tokens)\n","\n","print(f\"Original text: {text}\")\n","print(f\"Encoded: {encoded}\")\n","print(f\"Decoded text: {decoded_text}\")"],"id":"36zvorT0EVVA"},{"cell_type":"markdown","metadata":{"id":"0e4568b4"},"source":["# Dataset"],"id":"0e4568b4"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1709448368708,"user":{"displayName":"たかいです","userId":"08363226705441905685"},"user_tz":-540},"id":"5d1060ed"},"outputs":[],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['text'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 2 # cls & sep\n","CFG.max_len=1024\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"],"id":"5d1060ed"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2bd231fe","executionInfo":{"status":"aborted","timestamp":1709448368708,"user_tz":-540,"elapsed":21,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text,\n","        return_tensors=None,\n","        add_special_tokens=True,\n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df[cfg.target_cols].values\n","        print(self.texts)\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","\n","        return inputs, label\n","\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs"],"id":"2bd231fe"},{"cell_type":"markdown","metadata":{"id":"694f45ea"},"source":["# Model"],"id":"694f45ea"},{"cell_type":"code","execution_count":null,"metadata":{"id":"be0cf2ca","executionInfo":{"status":"aborted","timestamp":1709448368709,"user_tz":-540,"elapsed":22,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["#ref:https://github.com/shu421/kagglib/blob/main/nlp/model.py\n","# ====================================================\n","# Model\n","# ====================================================\n","\n","def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","\n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","# =====================================================\n","# Pooling\n","# =====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","\n","\n","class AttentionPooling(nn.Module):\n","    \"\"\"\n","    Usage:\n","        self.pool = AttentionPooling(self.config.hidden_size)\n","    \"\"\"\n","    def __init__(self, in_dim):\n","        super().__init__()\n","        self.attention = nn.Sequential(\n","            nn.Linear(in_dim, in_dim),\n","            nn.LayerNorm(in_dim),\n","            nn.GELU(),\n","            nn.Linear(in_dim, 1),\n","        )\n","\n","        self._init_weights(self.attention)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        w = self.attention(last_hidden_state).float()\n","        w[attention_mask == 0] = float(\"-inf\")\n","        w = torch.softmax(w, 1)\n","        attention_embeddings = torch.sum(w * last_hidden_state, dim=1)\n","        return attention_embeddings\n","\n","\n","\n","class WeightedLayerPooling(nn.Module):\n","    def __init__(self, num_hidden_layers, layer_start: int = 4, layer_weights=None):\n","        super(WeightedLayerPooling, self).__init__()\n","        self.layer_start = layer_start\n","        self.num_hidden_layers = num_hidden_layers\n","        self.layer_weights = layer_weights if layer_weights is not None \\\n","            else nn.Parameter(\n","            torch.tensor([1] * (num_hidden_layers + 1 - layer_start), dtype=torch.float)\n","        )\n","\n","    def forward(self, all_hidden_states):\n","        all_layer_embedding = all_hidden_states[self.layer_start:, :, :, :]\n","        weight_factor = self.layer_weights.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(all_layer_embedding.size())\n","        weighted_average = (weight_factor * all_layer_embedding).sum(dim=0) / self.layer_weights.sum()\n","        return weighted_average[:, 0]\n","\n","class LSTMPooling(nn.Module):\n","    def __init__(self, num_layers, hidden_size, hiddendim_lstm, dropout_rate, is_lstm=True):\n","        super(LSTMPooling, self).__init__()\n","        self.num_hidden_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.hiddendim_lstm = hiddendim_lstm\n","\n","        if is_lstm:\n","            self.lstm = nn.LSTM(self.hidden_size, self.hiddendim_lstm, batch_first=True)\n","        else:\n","            self.lstm = nn.GRU(self.hidden_size, self.hiddendim_lstm, batch_first=True, bidirectional=True)\n","\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","    def forward(self, all_hidden_states):\n","        hidden_states = torch.stack([all_hidden_states[layer_i][:, 0].squeeze()\n","                                     for layer_i in range(1, self.num_hidden_layers + 1)], dim=-1)\n","        hidden_states = hidden_states.view(-1, self.num_hidden_layers, self.hidden_size)\n","        out, _ = self.lstm(hidden_states, None)\n","        out = self.dropout(out[:, -1, :])\n","        return out\n","\n","class ConcatPooling(nn.Module):\n","    def __init__(self, n_layers=4):\n","        super(ConcatPooling, self, ).__init__()\n","\n","        self.n_layers = n_layers\n","\n","    def forward(self, all_hidden_states):\n","        concatenate_pooling = torch.cat([all_hidden_states[-(i + 1)] for i in range(self.n_layers)], -1)\n","        concatenate_pooling = concatenate_pooling[:, 0]\n","        return concatenate_pooling\n","\n","# GeM\n","class GeMText(nn.Module):\n","    def __init__(self, dim=1, cfg=None, p=3, eps=1e-6):\n","        super(GeMText, self).__init__()\n","        self.dim = dim\n","        self.p = Parameter(torch.ones(1) * p)\n","        self.eps = eps\n","        self.feat_mult = 1\n","        # x seeems last hidden state\n","\n","    def forward(self, x, attention_mask):\n","        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(x.shape)\n","        x = (x.clamp(min=self.eps) * attention_mask_expanded).pow(self.p).sum(self.dim)\n","        ret = x / attention_mask_expanded.sum(self.dim).clip(min=self.eps)\n","        ret = ret.pow(1 / self.p)\n","        return ret\n","\n","# ===========================================\n","# custom Model\n","# ===========================================\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        if cfg.pooling =='LSTMPooling':\n","            self.pool =  LSTMPooling(self.config.num_hidden_layers,\n","                                       self.config.hidden_size,\n","                                       self.cfg.hidden_size,\n","                                       0.1,\n","                                       is_lstm=True\n","                           )\n","            self.fc = nn.Linear(self.cfg.hidden_size, 2)\n","        elif cfg.pooling == \"GeM\":\n","            self.pool = GeMText()\n","            self.fc = nn.Linear(self.config.hidden_size, 2)\n","        elif cfg.pooling=='ConcatPooling':\n","            self.pool = ConcatPooling(n_layers=cfg.n_layers)\n","            self.fc = nn.Linear(cfg.n_layers*self.config.hidden_size, 2)\n","        elif cfg.pooling=='WeightedLayerPooling':\n","            self.pool = WeightedLayerPooling(self.config.num_hidden_layers)\n","            self.fc = nn.Linear(self.config.hidden_size, 2)\n","\n","\n","        self._init_weights(self.fc)\n","\n","\n","        # Freeze\n","        if self.cfg.freeze:\n","            freeze(self.model.encoder.layer[:self.cfg.freeze_top_num_layer])\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        if self.cfg.pooling=='MeanPooling':\n","          feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        elif self.cfg.pooling in ['GRUPooling', 'LSTMPooling']:\n","            all_hidden_states = torch.stack(outputs[1])\n","            feature = self.pool(all_hidden_states)\n","        elif self.cfg.pooling=='GeM':\n","          feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        elif self.cfg.pooling == 'ConcatPooling':\n","            all_hidden_states = torch.stack(outputs[1])\n","            feature = self.pool(all_hidden_states)\n","        elif self.cfg.pooling == 'WeightedLayerPooling':\n","            all_hidden_states = torch.stack(outputs[1])\n","            feature = self.pool(all_hidden_states)\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output\n","\n","\n","# initialize layer\n","def reinit_bert(model):\n","    \"\"\"_summary_\n","\n","    Args:\n","        model (AutoModel): _description_\n","\n","    Returns:\n","        model (AutoModel): _description_\n","\n","    Usage:\n","        model = reinit_bert(model)\n","    \"\"\"\n","    for layer in model.model.encoder.layer[-1:]:\n","        for module in layer.modules():\n","            if isinstance(module, nn.Linear):\n","                module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                if module.bias is not None:\n","                    module.bias.data.zero_()\n","            elif isinstance(module, nn.Embedding):\n","                module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                if module.padding_idx is not None:\n","                    module.weight.data[module.padding_idx].zero_()\n","            elif isinstance(module, nn.LayerNorm):\n","                module.bias.data.zero_()\n","                module.weight.data.fill_(1.0)\n","    return model"],"id":"be0cf2ca"},{"cell_type":"markdown","metadata":{"id":"31b35d08"},"source":["# Loss"],"id":"31b35d08"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ac3909be","executionInfo":{"status":"aborted","timestamp":1709448368709,"user_tz":-540,"elapsed":22,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# Loss\n","# ====================================================\n","class RMSELoss(nn.Module):\n","    def __init__(self, reduction='mean', eps=1e-9):\n","        super().__init__()\n","        self.mse = nn.MSELoss(reduction='none')\n","        self.reduction = reduction\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true):\n","        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss\n","\n","\n","\n","class WeightedSmoothL1Loss(nn.Module):\n","    def __init__(self,weights = torch.tensor([1.2, 0.8], device = device )):\n","        super(WeightedSmoothL1Loss, self).__init__()\n","        self.weights=weights\n","\n","    def forward(self, inputs, targets):\n","        \"\"\"\n","        inputs: ネットワークの出力 (予測値)\n","        targets: 正解ラベル\n","        weights: 各サンプルに対する重み\n","        \"\"\"\n","        # Smooth L1 損失を計算\n","        loss = nn.SmoothL1Loss(reduction='none')(inputs, targets)\n","\n","        # 重みを適用して損失を計算\n","        weighted_loss = torch.mean(loss * self.weights)\n","\n","        return weighted_loss\n","\n","\n","class MCRMSELoss(nn.Module):\n","    def __init__(self):\n","        super(MCRMSELoss, self).__init__()\n","\n","    def forward(self, y_true, y_pred):\n","        colwise_mse = torch.mean(torch.square(y_true - y_pred), dim=0)\n","        return torch.mean(torch.sqrt(colwise_mse), dim=0)\n","\n","\n","class WeightedMCRMSELoss(nn.Module):\n","    def __init__(self):\n","        super(WeightedMCRMSELoss, self).__init__()\n","\n","    def forward(self, y_true, y_pred):\n","        colwise_mse = torch.mean(torch.square(y_true - y_pred), dim=0)\n","        weights = torch.tensor([0.8, 1.2], device = device )\n","        weighted_colwise_mse = colwise_mse * weights  # Apply weights\n","        return torch.mean(torch.sqrt(weighted_colwise_mse), dim=0)"],"id":"ac3909be"},{"cell_type":"markdown","metadata":{"id":"lKO48EXzL8mV"},"source":["# AWP"],"id":"lKO48EXzL8mV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zMdI9u5L-HP","executionInfo":{"status":"aborted","timestamp":1709448368709,"user_tz":-540,"elapsed":21,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["from torch import Tensor\n","from torch.nn import Module\n","from torch.optim import Optimizer\n","from torch.nn.modules.loss import _Loss\n","\n","class AWP:\n","    def __init__(\n","        self,\n","        model: Module,\n","        criterion: _Loss,\n","        optimizer: Optimizer,\n","        apex: bool,\n","        adv_param: str=\"weight\",\n","        adv_lr: float=1.0,\n","        adv_eps: float=0.01\n","    ) -> None:\n","        self.model = model\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.apex = apex\n","        self.backup = {}\n","        self.backup_eps = {}\n","\n","    def attack_backward(self, inputs: dict, label: Tensor) -> Tensor:\n","        with torch.cuda.amp.autocast(enabled=self.apex):\n","            self._save()\n","            self._attack_step() # モデルを近傍の悪い方へ改変\n","            y_preds = self.model(inputs)\n","            adv_loss = self.criterion(\n","                y_preds.view(-1, 1), label.view(-1, 1))\n","            mask = (label.view(-1, 1) != -1)\n","            adv_loss = torch.masked_select(adv_loss, mask).mean()\n","            self.optimizer.zero_grad()\n","        return adv_loss\n","\n","    def _attack_step(self) -> None:\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                norm1 = torch.norm(param.grad)\n","                norm2 = torch.norm(param.data.detach())\n","                if norm1 != 0 and not torch.isnan(norm1):\n","                    # 直前に損失関数に通してパラメータの勾配を取得できるようにしておく必要あり\n","                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n","                    param.data.add_(r_at)\n","                    param.data = torch.min(\n","                        torch.max(\n","                            param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n","                    )\n","\n","    def _save(self) -> None:\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.data.clone()\n","                    grad_eps = self.adv_eps * param.abs().detach()\n","                    self.backup_eps[name] = (\n","                        self.backup[name] - grad_eps,\n","                        self.backup[name] + grad_eps,\n","                    )\n","\n","    def _restore(self) -> None:\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data = self.backup[name]\n","        self.backup = {}\n","        self.backup_eps = {}"],"id":"1zMdI9u5L-HP"},{"cell_type":"markdown","metadata":{"id":"d6344760"},"source":["# Helpler functions"],"id":"d6344760"},{"cell_type":"code","execution_count":null,"metadata":{"id":"978896ec","executionInfo":{"status":"aborted","timestamp":1709448368709,"user_tz":-540,"elapsed":21,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","\n","    if CFG.awp and epoch+1 >= CFG.nth_awp_start_epoch:\n","        LOGGER.info(f'AWP training with epoch {epoch+1}')\n","    model.train()\n","    awp = AWP(\n","            model,\n","            criterion,\n","            optimizer,\n","            CFG.apex,\n","            adv_lr=CFG.adv_lr,\n","            adv_eps=CFG.adv_eps\n","        )\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","        if CFG.awp and CFG.nth_awp_start_epoch <= epoch+1:\n","            loss = awp.attack_backward(inputs, labels)\n","            scaler.scale(loss).backward()\n","            awp._restore()\n","\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader),\n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions\n","\n","\n","\n","\n","\n","# def train_fn_by_step(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, now_step):\n","\n","#     # if CFG.awp and epoch+1 >= CFG.nth_awp_start_epoch:\n","#     #     LOGGER.info(f'AWP training with epoch {epoch+1}')\n","#     model.train()\n","#     # awp = AWP(\n","#     #         model,\n","#     #         criterion,\n","#     #         optimizer,\n","#     #         CFG.apex,\n","#     #         adv_lr=CFG.adv_lr,\n","#     #         adv_eps=CFG.adv_eps\n","#     #     )\n","#     if now_step==0:\n","#       scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","#       losses = AverageMeter()\n","#       start = end = time.time()\n","#       global_step = 0\n","#     for step, (inputs, labels) in enumerate(train_loader):\n","#         if now_step>step:\n","#           continue\n","#         inputs = collate(inputs)\n","#         for k, v in inputs.items():\n","#             inputs[k] = v.to(device)\n","#         labels = labels.to(device)\n","#         batch_size = labels.size(0)\n","#         with torch.cuda.amp.autocast(enabled=CFG.apex):\n","#             y_preds = model(inputs)\n","#             loss = criterion(y_preds, labels)\n","#         if CFG.gradient_accumulation_steps > 1:\n","#             loss = loss / CFG.gradient_accumulation_steps\n","#         losses.update(loss.item(), batch_size)\n","#         scaler.scale(loss).backward()\n","#         grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","\n","#         # if CFG.awp and CFG.nth_awp_start_epoch <= epoch+1:\n","#         #     loss = awp.attack_backward(inputs, labels)\n","#         #     scaler.scale(loss).backward()\n","#         #     awp._restore()\n","\n","#         if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","#             scaler.step(optimizer)\n","#             scaler.update()\n","#             optimizer.zero_grad()\n","#             global_step += 1\n","#             if CFG.batch_scheduler:\n","#                 scheduler.step()\n","#         end = time.time()\n","#         if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","#             print('Epoch: [{0}][{1}/{2}] '\n","#                   'Elapsed {remain:s} '\n","#                   'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","#                   'Grad: {grad_norm:.4f}  '\n","#                   'LR: {lr:.8f}  '\n","#                   .format(epoch+1, step, len(train_loader),\n","#                           remain=timeSince(start, float(step+1)/len(train_loader)),\n","#                           loss=losses,\n","#                           grad_norm=grad_norm,\n","#                           lr=scheduler.get_lr()[0]))\n","\n","#         if CFG.wandb:\n","#             wandb.log({f\"[fold{fold}] loss\": losses.val,\n","#                        f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","#         if step%CFG.eval_steps==0:\n","#           return losses.avg, step+1 ,epoch\n","\n","#     return losses.avg, step+1 ,epoch+1\n","\n","\n"],"id":"978896ec"},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUz1bDR9nNsa","executionInfo":{"status":"aborted","timestamp":1709448368709,"user_tz":-540,"elapsed":21,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"rUz1bDR9nNsa"},{"cell_type":"markdown","metadata":{"id":"fdb6b5d6"},"source":["# train loop"],"id":"fdb6b5d6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9088253a","executionInfo":{"status":"aborted","timestamp":1709448368710,"user_tz":-540,"elapsed":22,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size * 2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    def get_optimizer_grouped_parameters(cfg, model):\n","        \"\"\"Layerwise Learning Rate Decay\"\"\"\n","        model_type = \"model\"\n","        no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in model.named_parameters() if model_type not in n],\n","                \"lr\": cfg.decoder_lr,\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        num_layers = model.config.num_hidden_layers\n","        layers = [getattr(model, model_type).embeddings] + list(\n","            getattr(model, model_type).encoder.layer\n","        )\n","        layers.reverse()\n","        lr = cfg.encoder_lr\n","        for layer in layers:\n","            optimizer_grouped_parameters += [\n","                {\n","                    \"params\": [\n","                        p\n","                        for n, p in layer.named_parameters()\n","                        if not any(nd in n for nd in no_decay)\n","                    ],\n","                    \"weight_decay\": cfg.weight_decay,\n","                    \"lr\": lr,\n","                },\n","                {\n","                    \"params\": [\n","                        p\n","                        for n, p in layer.named_parameters()\n","                        if any(nd in n for nd in no_decay)\n","                    ],\n","                    \"weight_decay\": 0.0,\n","                    \"lr\": lr,\n","                },\n","            ]\n","\n","            lr *= cfg.lr_weight_decay\n","        return optimizer_grouped_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr,\n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    # optimizer_parameters = get_optimizer_grouped_parameters(CFG,model)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=int(cfg.num_warmup_steps_rate*num_train_steps), num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=int(cfg.num_warmup_steps_rate*num_train_steps), num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = WeightedMCRMSELoss()\n","    #nn.SmoothL1Loss(reduction='mean')\n","    # WeightedSmoothL1Loss(reduction='mean') #\n","\n","    best_score = np.inf\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","\n","        # scoring\n","        score, scores = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1,\n","                       f\"[fold{fold}] avg_train_loss\": avg_loss,\n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","\n","        if best_score > score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","# ====================================================\n","# train loop by steps\n","# ====================================================\n","def train_loop_steps(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size * 2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    if CFG.reinit:\n","      model=reinit_bert(model)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr,\n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=int(cfg.num_warmup_steps_rate*num_train_steps), num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=int(cfg.num_warmup_steps_rate*num_train_steps), num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = MCRMSELoss()\n","    #nn.SmoothL1Loss(reduction='mean')\n","    # WeightedSmoothL1Loss(reduction='mean') #\n","\n","    best_score = np.inf\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        model.train()\n","        # if CFG.awp and epoch+1 >= CFG.nth_awp_start_epoch:\n","        #   LOGGER.info(f'AWP training with epoch {epoch+1}')\n","\n","        # awp = AWP(\n","        #     model,\n","        #     criterion,\n","        #     optimizer,\n","        #     CFG.apex,\n","        #     adv_lr=CFG.adv_lr,\n","        #     adv_eps=CFG.adv_eps\n","        #     )\n","        scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","        losses = AverageMeter()\n","        start = end = time.time()\n","        global_step = 0\n","        for step, (inputs, labels) in enumerate(tqdm(train_loader)):\n","\n","            inputs = collate(inputs)\n","            for k, v in inputs.items():\n","                inputs[k] = v.to(device)\n","            labels = labels.to(device)\n","            batch_size = labels.size(0)\n","            with torch.cuda.amp.autocast(enabled=CFG.apex):\n","                y_preds = model(inputs)\n","                loss = criterion(y_preds, labels)\n","            if CFG.gradient_accumulation_steps > 1:\n","                loss = loss / CFG.gradient_accumulation_steps\n","            losses.update(loss.item(), batch_size)\n","            scaler.scale(loss).backward()\n","            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","                global_step += 1\n","                if CFG.batch_scheduler:\n","                    scheduler.step()\n","            end = time.time()\n","            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","                print('Epoch: [{0}][{1}/{2}] '\n","                      'Elapsed {remain:s} '\n","                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                      'Grad: {grad_norm:.4f}  '\n","                      'LR: {lr:.8f}  '\n","                      .format(epoch+1, step, len(train_loader),\n","                              remain=timeSince(start, float(step+1)/len(train_loader)),\n","                              loss=losses,\n","                              grad_norm=grad_norm,\n","                              lr=scheduler.get_lr()[0]))\n","            if CFG.wandb:\n","                wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                          f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","\n","            if (step % CFG.eval_steps==0 and step!=0) or step == (len(train_loader)-1):\n","\n","                  # valid\n","                  losses_val = AverageMeter()\n","                  model.eval()\n","                  preds = []\n","\n","                  for val_step, (inputs, labels) in enumerate(valid_loader):\n","\n","                      inputs = collate(inputs)\n","                      for k, v in inputs.items():\n","                          inputs[k] = v.to(device)\n","                      labels = labels.to(device)\n","                      batch_size = labels.size(0)\n","                      with torch.no_grad():\n","                          y_preds = model(inputs)\n","                          loss = criterion(y_preds, labels)\n","                      if CFG.gradient_accumulation_steps > 1:\n","                          loss = loss / CFG.gradient_accumulation_steps\n","                      losses_val.update(loss.item(), batch_size)\n","                      preds.append(y_preds.to('cpu').numpy())\n","\n","                      if val_step % CFG.print_freq == 0 or val_step == (len(valid_loader)-1):\n","                          print('EVAL: [{0}/{1}] '\n","                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                                .format(val_step, len(valid_loader),\n","                                        loss=losses_val))\n","                  predictions = np.concatenate(preds)\n","\n","                  # scoring\n","                  score, scores = get_score(valid_labels, predictions)\n","\n","                  elapsed = time.time() - start_time\n","\n","\n","\n","                  if best_score > score:\n","                      best_score = score\n","                      LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","                      torch.save({'model': model.state_dict(),\n","                                  'predictions': predictions},\n","                                  OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","\n","                  LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {losses.avg:.4f}  avg_val_loss: {losses_val.avg:.4f}')\n","                  LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","                  # if CFG.wandb:\n","                  #     wandb.log({f\"[fold{fold}] epoch\": epoch+1,\n","                  #                f\"[fold{fold}] avg_train_loss\": avg_loss,\n","                  #                f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                  #                f\"[fold{fold}] score\": score})\n","                  model.train()\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds\n","\n","\n","\n","\n","\n","\n","# ====================================================\n","# train loop by steps\n","# ====================================================\n","def prediction(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size * 2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    if CFG.reinit:\n","      model=reinit_bert(model)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","    model.eval()\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds"],"id":"9088253a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fde1c8af","executionInfo":{"status":"aborted","timestamp":1709448368710,"user_tz":-540,"elapsed":22,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":["if __name__ == '__main__':\n","\n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target_cols].values\n","        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","        score, scores = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n","\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                if CFG.save_strategy=='epoch':\n","                  _oof_df = train_loop(train, fold)\n","                elif CFG.save_strategy=='step':\n","                  _oof_df = train_loop_steps(train,fold)\n","                elif CFG.save_strategy=='prediction':\n","                  _oof_df = prediction(train,fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","\n","    if CFG.wandb:\n","        wandb.finish()\n","    runtime.unassign()"],"id":"fde1c8af"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a08b7051","executionInfo":{"status":"aborted","timestamp":1709448368710,"user_tz":-540,"elapsed":22,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"a08b7051"},{"cell_type":"code","execution_count":null,"metadata":{"id":"eeb952c6","executionInfo":{"status":"aborted","timestamp":1709448368710,"user_tz":-540,"elapsed":22,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"eeb952c6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"04d58baa","executionInfo":{"status":"aborted","timestamp":1709448368710,"user_tz":-540,"elapsed":22,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"04d58baa"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d3ca03db","executionInfo":{"status":"aborted","timestamp":1709448368710,"user_tz":-540,"elapsed":22,"user":{"displayName":"たかいです","userId":"08363226705441905685"}}},"outputs":[],"source":[],"id":"d3ca03db"}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"papermill":{"default_parameters":{},"duration":null,"end_time":null,"environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-25T10:25:22.661613","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}